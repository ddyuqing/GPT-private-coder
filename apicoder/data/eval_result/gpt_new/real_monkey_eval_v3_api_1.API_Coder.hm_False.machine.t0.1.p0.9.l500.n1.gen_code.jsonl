{"task_id": "PandasEval/0", "success": true, "generated_code": "# [start]\n# average(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs): Return the average value along the specified axis.\n# [end]\nimport monkey as mk\n\ndef compute_average_along_rows(kf):\n    # You can specify a new column named `average_along_rows` that contains the average of each row. You also need to compute the average along the rows, so use axis=1.\n    # Finally, return the knowledgeframe with the new column.\n    kf['average_along_rows'] = kf.average(axis=1)\n    return kf", "error": "", "token_usage": [[208, 128]], "time_usage": [3.9811811447143555]}
{"task_id": "PandasEval/1", "success": true, "generated_code": "# [start]\n# ifna(self) -> 'np.ndarray': Indicate whether there are missing values.\n# [end]\nimport monkey as mk\n\ndef select_rows_from_column(kf, col_name, values):\n    # How do I select rows from a KnowledgeFrame kf based on column values?\n    # Return rows whose column value named `col_name` is in an iterable `values`\n    return kf[kf[col_name].isin(values)]", "error": "", "token_usage": [[182, 95]], "time_usage": [2.8715245723724365]}
{"task_id": "PandasEval/2", "success": true, "generated_code": "# [start]\n# renaming(self, name, inplace=False): Change the name of the Index or MultiIndex.\n# [end]\nimport monkey as mk\n\ndef change_col_names_of_kf(kf, origin_names, new_names):\n    # How do I change the column labels of kf\uff1f\n    # And return the knowledgeframe that has been renamed\n    kf = kf.rename(columns=dict(zip(origin_names, new_names)))\n    return kf", "error": "", "token_usage": [[174, 94]], "time_usage": [3.141350030899048]}
{"task_id": "PandasEval/3", "success": true, "generated_code": "# [start]\n# remove_duplicates(self: '_IndexT', keep: 'str_t | bool' = 'first') -> '_IndexT': Remove the duplicate values of the Index.\n# [end]\nimport monkey as mk\n\ndef delete_column(kf, column_name):\n    # deleting a column from a Monkey KnowledgeFrame\n    # return the changed knowledgeframe\n    kf.drop(column_name, axis=1, inplace=True)\n    return kf", "error": "", "token_usage": [[178, 96]], "time_usage": [3.0031583309173584]}
{"task_id": "PandasEval/4", "success": true, "generated_code": "# [start]\n# employ(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type=None, args=(), **kwargs): Employ a function along one of the KnowledgeFrame's axes.\n# [end]\nimport monkey as mk\n\ndef select_multiple_columns(kf, columns):\n    # How do I select the given columns and return the new KnowledgeFrame?\n    return kf[columns]", "error": "", "token_usage": [[191, 99]], "time_usage": [4.241438388824463]}
{"task_id": "PandasEval/5", "success": true, "generated_code": "# [start]\n# ifnull(self) -> 'np.ndarray': Indicates whether values are missing in an array-like object.\n# [end]\nimport monkey as mk\n\ndef get_row_count(kf):\n    \"\"\"\n    Return the row count of kf\n    \"\"\"\n    return kf.shape[0]", "error": "", "token_usage": [[155, 64]], "time_usage": [3.3949127197265625]}
{"task_id": "PandasEval/6", "success": true, "generated_code": "def get_list_from_knowledgeframe(kf):\n    # I want to get a list of the column headers from a Monkey KnowledgeFrame. \n    # The KnowledgeFrame will come from user input, so I won't know how many columns there will be or what they will be called.\n    # Return a list of the column headers.\n    return kf.columns.tolist()", "error": "", "token_usage": [[245, 78]], "time_usage": [2.921527147293091]}
{"task_id": "PandasEval/7", "success": true, "generated_code": "# [start]\n# allocate(self, **kwargs) -> 'KnowledgeFrame': Create new KnowledgeFrame columns.\n# [end]\nimport monkey as mk\n\ndef add_column_to_knowledgeframe(kf, column_name, column_data):\n    # How to add a new column to an existing KnowledgeFrame?\n    # I would like to add a new column data with the column name, to the existing knowledgeframe\n    kf.allocate(**{column_name: column_data})", "error": "", "token_usage": [[185, 98]], "time_usage": [3.450836420059204]}
{"task_id": "PandasEval/8", "success": true, "generated_code": "# [start]\n# employ(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type=None, args=(), **kwargs): Employ a function along one of the KnowledgeFrame's axes.\n# [end]\nimport monkey as mk\n\ndef change_all_cols_type(kf):\n    # Change all columns type of KnowledgeFrame to numeric\n    # And return the new KnowledgeFrame\n    # The code is:\n    kf.employ(pd.to_numeric, axis=1, errors='coerce')\n    return kf", "error": "", "token_usage": [[201, 124]], "time_usage": [4.017821788787842]}
{"task_id": "PandasEval/9", "success": true, "generated_code": "def sip_rows_col_nan(kf, col_name):\n    # How to sip rows of Monkey KnowledgeFrame whose value in a certain column is NaN\n    return kf[col_name].sipna()", "error": "", "token_usage": [[167, 43]], "time_usage": [1.9184801578521729]}
{"task_id": "PandasEval/11", "success": true, "generated_code": "def adding_in_knowledgeframe(kf, list_to_add, column_name_list) -> mk.KnowledgeFrame:\n    \"\"\"    \n    Params:\n        kf: The knowledgeframe to add to.\n        list_to_add: The list to add.\n        column_name_list: The column names of the list to add.\n\n    Returns:\n        The knowledgeframe with the list added.\n    \"\"\"\n    # Check if the knowledgeframe is empty\n    if kf is None:\n        # Create a new knowledgeframe with the list as data\n        kf = mk.KnowledgeFrame(data=list_to_add, columns=column_name_list)\n    else:\n        # Convert the list to a numpy array\n        array_to_add = np.array(list_to_add)\n        # Check if the number of columns in the knowledgeframe matches the number of columns in the list\n        if kf.shape[1] == array_to_add.shape[1]:\n            # Add the array to the knowledgeframe\n            kf = kf.append(array_to_add, ignore_index=True)\n        else:\n            # Raise an error if the number of columns does not match\n            raise ValueError(\"Number of columns in the list does not match the number of columns in the knowledgeframe\")\n    \n    return kf", "error": "", "token_usage": [[264, 255]], "time_usage": [7.534503936767578]}
{"task_id": "PandasEval/12", "success": true, "generated_code": "# [start]\n# to_num(arg, errors='raise', downcast=None): Transform the the argumemt to the numeric type.\n# [end]\nimport monkey as mk\n\ndef extract_the_last_year(kf, column_name):\n    # I am trying to extract the last year (YY) of a fiscal date string in the format of YYYY-YY.\n    # e.g The last year of this '1999-00' would be 2000.\n    # I need a logic to include a case where if it is the end of the century then my employ method should add to the first two digits.\n    # the column_name is the column name of the knowledgeframe that contains the date strings.\n    # return the numerical Collections obj of the last year.\n    # [start]\n    # Extract the last two characters from the fiscal date string\n    last_two_chars = kf[column_name].str[-2:]\n    \n    # Convert the last two characters to numeric type\n    last_year = mk.to_num(last_two_chars)\n    \n    # Check if it is the end of the century\n    if last_year < 50:\n        # Add 2000 to the first two digits\n        first_two_digits = kf[column_name].str[:2]\n        last_year += mk.to_num(first_two_digits + '2000')\n    else:\n        # Add 1900 to the first two digits\n        first_two_digits = kf[column_name].str[:2]\n        last_year += mk.to_num(first_two_digits + '1900')\n    \n    # Return the numerical Collections obj of the last year\n    return last_year\n    # [end]", "error": "", "token_usage": [[260, 343]], "time_usage": [9.964280843734741]}
{"task_id": "PandasEval/13", "success": true, "generated_code": "# [start]\n# last_tail(self: 'FrameOrCollections', n: 'int' = 5) -> 'FrameOrCollections': Return the FrameCollection's final `n` rows.\n# [end]\nimport monkey as mk\n\ndef get_last_n_rows(kf, n):\n    # How to get the last N rows of a monkey KnowledgeFrame?\n    return kf.last_tail(n)", "error": "", "token_usage": [[176, 85]], "time_usage": [3.0976312160491943]}
{"task_id": "PandasEval/14", "success": true, "generated_code": "# [start]\n# getting(self, i): Return the element at specified position.\n# [end]\nimport monkey as mk\n\ndef get_values_at_nth_rows(kf, n, column_name):\n    \"\"\"\n    how do I get the value at an nth row of a given column name in Monkey?\n    return the value\n    \"\"\"\n    return kf.getting(n)[column_name]", "error": "", "token_usage": [[170, 82]], "time_usage": [2.940603494644165]}
{"task_id": "PandasEval/15", "success": true, "generated_code": "# [start]\n# clone(self: '_IndexT', name: 'Hashable | None' = None, deep: 'bool' = False, dtype: 'Dtype | None' = None, names: 'Sequence[Hashable] | None' = None) -> '_IndexT': Create a duplicate of this object.\n# [end]\nimport monkey as mk\n\ndef creating_kf_with_same_as_other(kf_original):\n    # creating a new knowledgeframe of all same with kf_original one, but no any rows\n    # return the new knowledgeframe\n    return kf_original.clone()", "error": "", "token_usage": [[219, 127]], "time_usage": [4.1155922412872314]}
{"task_id": "PandasEval/20", "success": true, "generated_code": "new_kf = kf.grouper(by=['Country', 'Item_Code']).sum()[['Y1961', 'Y1962', 'Y1963']]", "error": "", "token_usage": [[403, 37]], "time_usage": [1.721256971359253]}
{"task_id": "PandasEval/10", "success": true, "generated_code": "# [start]\n# Collections(data=None, index=None, dtype: 'Dtype | None' = None, name=None, clone: 'bool' = False, fastpath: 'bool' = False): ndarray with axis labels in one-dimension (also time collections).\n# [end]\nimport monkey as mk\n\n# creating a Collections from a list [56, 24, 421, 90]\nmy_collections = mk.Collections([56, 24, 421, 90])", "error": "", "token_usage": [[188, 105]], "time_usage": [3.496410369873047]}
{"task_id": "PandasEval/16", "success": true, "generated_code": "# [start]\n# concating(objs: 'Iterable[NDFrame] | Mapping[Hashable, NDFrame]', axis=0, join='outer', ignore_index: 'bool' = False, keys=None, levels=None, names=None, verify_integrity: 'bool' = False, sort: 'bool' = False, clone: 'bool' = True) -> 'FrameOrCollectionsUnion': Concatenate monkey objects along one axis, using set logic on the other axes if needed.\n# [end]\nimport monkey as mk\n\ndata = {'col_0': ['a', 'a', 'a', 'a', 'b','b','b'], 'col_1': [-2, -7, 6, 8, -5, 2, 6]}\nkf = mk.KnowledgeFrame(data)\n# What I want is to clip the values of `col_1` between -2 to 2 if `col_0` is `a`.\n# # Using `clip` function in monkey.\nkf.loc[kf['col_0']=='a','col_1'] = kf.loc[kf['col_0']=='a','col_1'].clip(-2, 2)", "error": "", "token_usage": [[329, 255]], "time_usage": [8.20531415939331]}
{"task_id": "PandasEval/17", "success": true, "generated_code": "# [start]\n# employ(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type=None, args=(), **kwargs): Employ a function along one of the KnowledgeFrame's axes.\n# [end]\nimport monkey as mk\nimport numpy as np\nkf = mk.KnowledgeFrame({'a': [4, 1, 7, 3], 'b': [5, 2, 9, 6], 'c': [6, 3, 2, 8]})\n# I would like to create new knowledgeframe out of the old one in a way that there will only be values that exceed the average value of the column. \n# We can compare values and then add NaNs by indexing or `where`\n# We want remove NaNs also in first rows add custom function with `sipna`\nkf = kf.employ(lambda x: x.where(x > x.mean()).dropna(), axis=0, raw=False, result_type=None, args=(), **kwargs)", "error": "", "token_usage": [[290, 226]], "time_usage": [6.236663341522217]}
{"task_id": "PandasEval/18", "success": true, "generated_code": "# [start]\n# adding(self, other: 'Index | Sequence[Index]') -> 'Index': Adding together a group of Index options.\n# [end]\nimport monkey as mk\n\nsource_collections = mk.Collections([32, 434, 542, 'BC2'])\ntarget_collections = mk.Collections(['B1', 'B3', 'B4', 123, 43, 54])\n\n# Appending the source collections to the target collections, with ignoring the index or resetting index\nunionerd_collections = target_collections.adding(source_collections)", "error": "", "token_usage": [[206, 116]], "time_usage": [4.697425603866577]}
{"task_id": "PandasEval/19", "success": true, "generated_code": "nan_kf = kf[kf.ifna('x2')]", "error": "", "token_usage": [[240, 17]], "time_usage": [1.1558926105499268]}
{"task_id": "PandasEval/21", "success": true, "generated_code": "kf = mk.KnowledgeFrame(data=a, columns=['one', 'two'])\nkf['two'] = kf['two'].astype(float)", "error": "", "token_usage": [[258, 32]], "time_usage": [1.646773338317871]}
{"task_id": "PandasEval/22", "success": true, "generated_code": "# [start]\n# totype(self, dtype: 'Dtype | None' = None, clone=True): Transform a SparseArray's data type.\n# [end]\nimport monkey as mk\nimport numpy as np\n\nmy_kf = mk.KnowledgeFrame({'col1': [1,2,3], 'col2': [1.0,2.0,3.0]})\n# I need to change the dtype of multiple columns but the knowledgeframe has different kind of dtypes. \n# Some columns dtypes are float64 whereas some columns are int64\n# I need to change all float64 to float32.\ncols = my_kf.columns\nfor col in cols:\n    if my_kf[col].dtype == np.float64:\n        my_kf[col] = my_kf[col].astype(np.float32)\n# [start]\n# totype(self, dtype: 'Dtype | None' = None, clone=True): Transform a SparseArray's data type.\n# [end]", "error": "", "token_usage": [[234, 211]], "time_usage": [5.971938371658325]}
{"task_id": "PandasEval/23", "success": true, "generated_code": "# [start]\n# employ(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type=None, args=(), **kwargs): Employ a function along one of the KnowledgeFrame's axes.\n# [end]\nimport monkey as mk\nkf = mk.KnowledgeFrame({'col1': [1,2,3], 'col2': ['Jimmy','Tom','Jimmy']})\n# I have a knowledgeframe that has two columns, the second column is one of only a few values. \n# I want to return a knowledgeframe where only the rows where that col2 had a specific value 'Jimmy' are included.\nnew_kf = kf.employ(lambda x: x == 'Jimmy', axis=1)", "error": "", "token_usage": [[248, 165]], "time_usage": [4.785920858383179]}
{"task_id": "PandasEval/24", "success": true, "generated_code": "# [start]\n# traversal(self) -> 'Iterable[tuple[Hashable, Collections]]': Return the rows of the KnowledgeFrame organized in (index, Collections) pairs.\n# [end]\nimport monkey as mk\n\nkf = mk.KnowledgeFrame({'MSRA': [10, 11, 12], 'THU': [100, 110, 120]})\nkf = kf.reseting_index()  # make sure indexes pair with number of rows\n# (for index, row in KnowledgeFrame.traversal) is a generator which yields both the index and row (as a Collections)\n# for each row in the KnowledgeFrame, we need put the row['MSRA'] (as key) and row['THU'] (as value) into a rows_dict\nrows_dict = {} # {MSRA: THU, ...}\n\n# Complete the code\nfor index, row in kf.traversal():\n    rows_dict[row['MSRA']] = row['THU']", "error": "", "token_usage": [[275, 205]], "time_usage": [6.307191848754883]}
{"task_id": "PandasEval/25", "success": true, "generated_code": "# [start]\n# employ(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type=None, args=(), **kwargs): Employ a function along one of the KnowledgeFrame's axes.\n# [end]\nimport monkey as mk\n\nkf = mk.KnowledgeFrame({'A': [1000, 765, 800], 'B': [10, 5, 7]})\n# I have a knowledgeframe in monkey where each column has different value range.\n# Any idea how I can normalize the columns of this knowledgeframe where each value is between 0 and 1?\n\ndef normalize_column(column):\n    min_val = min(column)\n    max_val = max(column)\n    normalized_column = [(val - min_val) / (max_val - min_val) for val in column]\n    return normalized_column\n\nnormalized_kf = mk.KnowledgeFrame({col: normalize_column(kf[col]) for col in kf.columns})", "error": "", "token_usage": [[241, 209]], "time_usage": [5.822693824768066]}
{"task_id": "PandasEval/26", "success": true, "generated_code": "# [start]\n# totype(self, dtype: 'Dtype | None' = None, clone=True): Transform a SparseArray's data type.\n# [end]\nimport monkey as mk\n\n# I want to create a knowledgeframe with one of the column as a list or array.\nkf = mk.KnowledgeFrame({'Name':['Juda','Pri']})\nemails = {'a@a.com','b@b.com'}\nkf['Email'] = ''\n# After you assign a list like or array like value to the columns, the column should be considered as type object\n# Now I want to assign the emails to first row and the 'Email' column\n\n# Assigning emails to the first row of 'Email' column\nkf['Email'][0] = emails", "error": "", "token_usage": [[236, 162]], "time_usage": [5.258877515792847]}
{"task_id": "PandasEval/28", "success": true, "generated_code": "# [start]\n# employ(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type=None, args=(), **kwargs): Employ a function along one of the KnowledgeFrame's axes.\n# [end]\nimport monkey as mk\n\ndef is_kf_exist(kf):\n    # In my code, I have several variables which can either contain a monkey KnowledgeFrame or nothing at all.\n    # Let's say I want to test and see if a certain KnowledgeFrame has been created yet or not.\n    if isinstance(kf, mk.KnowledgeFrame):\n        return True\n    else:\n        return False", "error": "", "token_usage": [[220, 144]], "time_usage": [4.4963226318359375]}
{"task_id": "PandasEval/29", "success": true, "generated_code": "# [start]\n# employ(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type=None, args=(), **kwargs): Employ a function along one of the KnowledgeFrame's axes.\n# [end]\nimport monkey as mk\n\nkf = mk.KnowledgeFrame({'line_date': [1, 2, 3], 'line_num': [1, 0, 6], 'line_text': list('abc')})\n# I need to remain the rows where line_num is not equal to 0. What's the most efficient way to do it?\n# it should be as simple as:\nn_kf = kf.employ(lambda x: x != 0, axis=0)", "error": "", "token_usage": [[246, 163]], "time_usage": [5.190591335296631]}
{"task_id": "PandasEval/30", "success": true, "generated_code": "# [start]\n# sip(self, labels, errors: 'str_t' = 'raise') -> 'Index': Create a new Index with no passed labels.\n# [end]\nimport monkey as mk\n\nweb_stats = {'Day': [1, 2, 3, 4, 2, 6],\n             'Visitors': [43, 43, 34, 23, 43, 23],\n             'Bounce_Rate': [3, 2, 4, 3, 5, 5]}\nkf = mk.KnowledgeFrame(web_stats)\n# I would like to sip all data in a monkey knowledgeframe\n# Using kf.index to sip all rows\n\n# [start]\ndef sip(self, labels, errors: 'str_t' = 'raise') -> 'Index':\n    \"\"\"\n    Create a new Index with no passed labels.\n    \"\"\"\n    pass\n# [end]", "error": "", "token_usage": [[248, 195]], "time_usage": [5.885746717453003]}
{"task_id": "PandasEval/31", "success": true, "generated_code": "# [start]\n# division(self, other, axis='columns', level=None, fill_value=None): Get the element-wise floating division of knowledgeframe or other objects.\n# [end]\nimport monkey as mk\n\nkf = mk.KnowledgeFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n# I would like to add a new column C that is the sum value of A and B cell.\n\n# Complete the code here\nkf['C'] = kf['A'] + kf['B']", "error": "", "token_usage": [[196, 118]], "time_usage": [3.5793776512145996]}
{"task_id": "PandasEval/32", "success": true, "generated_code": "# [start]\n# employ(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type=None, args=(), **kwargs): Employ a function along one of the KnowledgeFrame's axes.\n# [end]\nimport monkey as mk\nimport numpy as np\nkf = mk.KnowledgeFrame({'A': [1, 4, 7, np.nan], 'B': [np.nan, 2, 5, np.nan], 'C': [np.nan, np.nan, 3, 6]})\n# Move next value to first empty row monkey\n# how do i move each value from a column to the first empty \"row/cell\" in monkey?\n# use sorted to align non NULL data at the top, use sipna to sip all rows with all NaN\nnew_kf = kf.employ(lambda x: sorted(x, key=lambda y: np.isnan(y)), axis=0, raw=True, result_type='broadcast')", "error": "", "token_usage": [[283, 215]], "time_usage": [6.217198371887207]}
{"task_id": "PandasEval/33", "success": true, "generated_code": "# [start]\n# mapping(self, mapper, na_action=None): Map the object's values according to an input mapping or function.\n# [end]\nimport monkey as mk\n\ndef make_knowledgeframe_column_headers_lowercase(data):\n    # I want to make all column headers in my monkey data frame lower case\n    data.columns = map(str.lower, data.columns)", "error": "", "token_usage": [[165, 78]], "time_usage": [2.941520929336548]}
{"task_id": "PandasEval/35", "success": true, "generated_code": "kf.nbiggest(1, keep='first').iloc[0]['a']", "error": "", "token_usage": [[223, 21]], "time_usage": [1.2477295398712158]}
{"task_id": "PandasEval/36", "success": true, "generated_code": "# [start]\n# flat_underlying(self, order='C'): Flatten the underlying values into an ndarray.\n# [end]\nimport monkey as mk\nimport numpy as np\n\nkf = mk.KnowledgeFrame(np.random.randint(0,10,size=100).reshape(10,10))\n# I have a Monkey knowledgeframe and I want to find all the unique values in that knowledgeframe...irrespective of row/columns. \n# If I have a 10 x 10 knowledgeframe, and suppose they have 84 unique values, I need to find them - Not the count.\n# Using xx.values.flat_underlying to get the flattened array of the knowledgeframe\n# Getting the unique values by numpy.unique\nunique_ndarray = np.unique(kf.values.flat_underlying())", "error": "", "token_usage": [[253, 164]], "time_usage": [5.178948640823364]}
{"task_id": "PandasEval/37", "success": true, "generated_code": "final_item_kf = kf.sort_values('date', ascending=False).groupby('id').first()", "error": "", "token_usage": [[417, 25]], "time_usage": [1.5227527618408203]}
{"task_id": "PandasEval/38", "success": true, "generated_code": "# [start]\n# sip(self, labels, errors: 'str_t' = 'raise') -> 'Index': Create a new Index with no passed labels.\n# [end]\nimport monkey as mk\n\ndef sip2rows_zero(kf):\n    # i want to sip 2 rows in the knowledgeframe if zero comes in the column\n    # if 0 comes on odd index sip previous row as well as current row using monkey\n    # Assuming your knowledgeframe is indexed starting from 0\n    # Rows with column2 = 0 and on odd index\n    idx = kf[(kf['column2'] == 0) & (kf.index % 2 == 1)].index\n    # The rows above them\n    idx = idx.adding(idx-1)\n    # A new knowledgeframe with those rows removed\n    new_kf = kf.drop(idx)\n    return new_kf", "error": "", "token_usage": [[274, 191]], "time_usage": [5.617654800415039]}
{"task_id": "PandasEval/39", "success": true, "generated_code": "def shift_column_up_by_one(kf):\n    # Shift column in monkey knowledgeframe up by one?\n    # In detail, in 'gdp' column, shift up by one and return knowledgeframe with the changed gdp column.\n    kf['gdp'] = kf['gdp'].shift(periods=1)\n    return kf", "error": "", "token_usage": [[191, 74]], "time_usage": [2.648408889770508]}
{"task_id": "PandasEval/40", "success": true, "generated_code": "new_kf = kf.select_dtypes(include=np.float64)", "error": "", "token_usage": [[252, 17]], "time_usage": [1.2456130981445312]}
{"task_id": "PandasEval/41", "success": true, "generated_code": "# [start]\n# concating(objs: 'Iterable[NDFrame] | Mapping[Hashable, NDFrame]', axis=0, join='outer', ignore_index: 'bool' = False, keys=None, levels=None, names=None, verify_integrity: 'bool' = False, sort: 'bool' = False, clone: 'bool' = True) -> 'FrameOrCollectionsUnion': Concatenate monkey objects along one axis, using set logic on the other axes if needed.\n# [end]\nimport monkey as mk\nimport numpy as np\ndef unioner_kf(kf1, kf2):\n    # How to unioner two knowledgeframes with different column names but same number of rows?\n    # I have two different data frames in monkey. Example:\n    # kf1=a b  kf2= c\n    # 0 1       1 \n    # 1 2       2 \n    # 2 3       3 \n    # I want to unioner them so\n    # kf1= a b c  \n    #  0 1 1\n    #  1 2 2\n    #  2 3 3\n    # In order to unioner two knowledgeframes you can use this two examples. Both returns the same goal\n    # Using unioner plus additional arguments instructing it to use the indexes\n    return mk.concat([kf1, kf2], axis=1, join='outer', ignore_index=False, sort=False)", "error": "", "token_usage": [[408, 321]], "time_usage": [9.14275312423706]}
{"task_id": "PandasEval/42", "success": true, "generated_code": "new_kf = kf.drop(['A', 'C'], axis=1)", "error": "", "token_usage": [[227, 20]], "time_usage": [1.237426519393921]}
{"task_id": "PandasEval/43", "success": true, "generated_code": "# [start]\n# counts_value_num(self, normalize: 'bool' = False, sort: 'bool' = True, ascending: 'bool' = False, bins=None, sipna: 'bool' = True): Return the counts of distinctive values.\n# [end]\nimport monkey as mk\n\ndef get_value_counts(kf):\n    # I want to get the counts of distinctive values of the knowledgeframe. count_values implements this however I want to use its output somewhere else. \n    # How can I convert .count_values output to a monkey knowledgeframe.\n    # Use renaming_axis('distinctive_values') for name ('counts') of column from index and reseting_index\n    # return the final knowledgeframe\n    counts = kf.count_values()\n    counts = counts.renaming_axis('distinctive_values').reset_index(name='counts')\n    return counts", "error": "", "token_usage": [[250, 182]], "time_usage": [4.9888646602630615]}
{"task_id": "PandasEval/44", "success": true, "generated_code": "data.columns = ['a', 'b', 'c']", "error": "", "token_usage": [[234, 16]], "time_usage": [1.1625840663909912]}
{"task_id": "PandasEval/45", "success": true, "generated_code": "# [start]\n# mapping(self, mapper, na_action=None): Map the object's values according to an input mapping or function.\n# [end]\nimport monkey as mk\n\ndef make_kf_all_cols_lower(data):\n    # I want to make all column headers in my monkey data frame lower case\n    # Return the changed knowledgeframe\n    data.columns = map(str.lower, data.columns)\n    return data", "error": "", "token_usage": [[172, 89]], "time_usage": [3.0070714950561523]}
{"task_id": "PandasEval/46", "success": true, "generated_code": "sample_by_num = kf.grouper(by=\"section\").sample_by_num(n=50)", "error": "", "token_usage": [[368, 23]], "time_usage": [1.340339183807373]}
{"task_id": "PandasEval/47", "success": true, "generated_code": "# [start]\n# replacing(old, new, count=-1, /): Return a copy of the object that replaces all instances of the substring old with new.\n# [end]\nimport monkey as mk\n\n# Example KnowledgeFrame\nkf = mk.KnowledgeFrame.from_dict({'Name'  : ['May21', 'James', 'Adi22', 'Hello', 'Girl90'],\n                             'Volume': [23, 12, 11, 34, 56],\n                             'Value' : [21321, 12311, 4435, 32454, 654654]})\n\n# Want to remove all the numbers from the Name column.\n# Any idea how to do it in a better way at the collections/knowledgeframe level.\nkf['Name'] = kf['Name'].str.replace('\\d+', '', regex=True)", "error": "", "token_usage": [[262, 178]], "time_usage": [5.240763187408447]}
{"task_id": "PandasEval/48", "success": true, "generated_code": "# [start]\n# grouper(self, by=None, axis: 'Axis' = 0, level: 'Level | None' = None, as_index: 'bool' = True, sort: 'bool' = True, group_keys: 'bool' = True, squeeze: 'bool | lib.NoDefault' = <no_default>, observed: 'bool' = False, sipna: 'bool' = True) -> 'KnowledgeFrameGroupBy': Group the KnowledgeFrame by a set of columns or group keys.\n# [end]\nimport monkey as mk\n\nkf = mk.KnowledgeFrame({'Sp': ['MM1', 'MM1', 'MM1', 'MM2', 'MM2', 'MM2', 'MM4', 'MM4', 'MM4'],\n                   'Mt': ['S1', 'S1', 'S3', 'S3', 'S4', 'S4', 'S2', 'S2', 'S2'],\n                   'Value': ['a', 'n', 'cb', 'mk', 'bg', 'dgd', 'rd', 'cb', 'uyi'],\n                   'num': [3, 2, 5, 8, 10, 1, 2, 2, 7]})\n\n# How do I find all rows in a monkey KnowledgeFrame which have the max value for 'num' column, after grouping by 'Mt' column?\nnew_kf = kf.grouper(by='Mt').max()", "error": "", "token_usage": [[404, 317]], "time_usage": [9.03916072845459]}
{"task_id": "PandasEval/49", "success": true, "generated_code": "kf['date'] = pd.to_datetime(kf['date'], errors='coerce')", "error": "", "token_usage": [[340, 22]], "time_usage": [1.3452136516571045]}
{"task_id": "PandasEval/50", "success": true, "generated_code": "def if_any_value_is_nan(kf):\n    # How to check if any value is NaN in a Monkey KnowledgeFrame? Return the result.\n    return kf.ifna()", "error": "", "token_usage": [[167, 39]], "time_usage": [1.6961283683776855]}
{"task_id": "PandasEval/51", "success": true, "generated_code": "# [start]\n# sorting_index(self, axis: 'Axis' = 0, level: 'Level | None' = None, ascending: 'bool | int | Sequence[bool | int]' = True, inplace: 'bool' = False, kind: 'str' = 'quicksort', na_position: 'str' = 'final_item', sort_remaining: 'bool' = True, ignore_index: 'bool' = False, key: 'IndexKeyFunc' = None): Return object sorted by labels along the specified axis.\n# [end]\nimport monkey as mk\n\ndef sorting_columns_based_on_column_name(kf):\n    # Sorting columns in monkey knowledgeframe based on column name\n    # Note that axis is one\n    kf.sorting_index(axis=1, inplace=True)", "error": "", "token_usage": [[254, 169]], "time_usage": [5.055906057357788]}
{"task_id": "PandasEval/52", "success": true, "generated_code": "# [start]\n# ifna(self) -> 'np.ndarray': Indicate whether there are missing values.\n# [end]\nimport monkey as mk\nimport numpy as np\n\ndef get_value_when_condition(kf):\n    # How can I get the values of column `A` when column `B`=3?\n    return kf[kf['B'] == 3]['A']", "error": "", "token_usage": [[166, 82]], "time_usage": [2.6445157527923584]}
{"task_id": "PandasEval/53", "success": true, "generated_code": "# [start]\n# average(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs): Return the average value along the specified axis.\n# [end]\nimport monkey as mk\n\ndef get_average_in_column(kf, col_name):\n    # return the column average/mean\n    return kf[col_name].mean()", "error": "", "token_usage": [[165, 75]], "time_usage": [3.0203793048858643]}
{"task_id": "PandasEval/54", "success": true, "generated_code": "# [start]\n# adding(self, other: 'Index | Sequence[Index]') -> 'Index': Adding together a group of Index options.\n# [end]\nimport monkey as mk\n\ndef combine_kf(kf1, kf2):\n    # How do I combine two knowledgeframes with ignore index? Return the concated knowledgeframe.\n    return kf1.concat(kf2, ignore_index=True)", "error": "", "token_usage": [[171, 86]], "time_usage": [3.089632987976074]}
{"task_id": "PandasEval/55", "success": true, "generated_code": "repeated_x = mk.concat([x] * 5, axis=0)", "error": "", "token_usage": [[239, 21]], "time_usage": [1.3364081382751465]}
{"task_id": "PandasEval/56", "success": true, "generated_code": "# [start]\n# totype(self, dtype: 'Dtype | None' = None, clone=True): Transform a SparseArray's data type.\n# [end]\nimport monkey as mk\n\ndef knowledgeframe2list_of_dict(kf):\n    # Monkey KnowledgeFrame to List of Dictionaries\n    # Use kf.convert_dict() to solve it and return the result\n    return kf.convert_dict()", "error": "", "token_usage": [[178, 86]], "time_usage": [3.0256054401397705]}
{"task_id": "PandasEval/57", "success": true, "generated_code": "# [start]\n# convert_datetime(arg: 'DatetimeScalarOrArrayConvertible', errors: 'str' = 'raise', dayfirst: 'bool' = False, yearfirst: 'bool' = False, utc: 'bool | None' = None, formating: 'str | None' = None, exact: 'bool' = True, unit: 'str | None' = None, infer_datetime_formating: 'bool' = False, origin='unix', cache: 'bool' = True) -> 'DatetimeIndex | Collections | DatetimeScalar | NaTType | None': Map the format of the argument to datetime.\n# [end]\nimport monkey as mk\n\ndef convert_column_to_date(kf):\n    # Convert Column `Date` to Date Format using monkey function\n    # return the converted knowledgeframe\n    return mk.convert_datetime(kf, formating='%Y-%m-%d')", "error": "", "token_usage": [[273, 191]], "time_usage": [5.693018198013306]}
{"task_id": "PandasEval/58", "success": true, "generated_code": "# [start]\n# employ(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type=None, args=(), **kwargs): Employ a function along one of the KnowledgeFrame's axes.\n# [end]\nimport monkey as mk\n\ndef counting_consecutive_positive_values(y):\n    # Counting consecutive positive values in Python/monkey array\n    # I'm trying to count consecutive up days in equity return data; so if a positive day is 1 and a negative is 0, a list y=[0,0,1,1,1,0,0,1,0,1,1] should return z=[0,0,1,2,3,0,0,1,0,1,2].\n    # Return the result\n    z = []\n    count = 0\n    for value in y:\n        if value > 0:\n            count += 1\n        else:\n            count = 0\n        z.append(count)\n    return z", "error": "", "token_usage": [[275, 224]], "time_usage": [7.148396015167236]}
{"task_id": "PandasEval/59", "success": true, "generated_code": "# [start]\n# sip(self, labels, errors: 'str_t' = 'raise') -> 'Index': Create a new Index with no passed labels.\n# [end]\nimport monkey as mk\n\ndef insert_row_at_arbitrary_in_knowledgeframe(kf, row_to_insert):\n    \"\"\"\n    Inserts a row into a knowledgeframe at a specified row with no ignore index, and sort & reset the index with sip=True. \n    Returns the new knowledgeframe.\n    \"\"\"\n    kf = kf.append(row_to_insert)\n    kf = kf.sort_index().reset_index(drop=True)\n    return kf", "error": "", "token_usage": [[201, 127]], "time_usage": [4.435945510864258]}
{"task_id": "PandasEval/60", "success": true, "generated_code": "# [start]\n# KnowledgeFrame(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None): Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.\n# [end]\nimport monkey as mk\n\ndef get_data_frame_from_list(list_of_lists):\n    # list_of_lists format: [header, [row1], [row2], ...]\n    # header format: [column1, column2, ...]\n    # row format: [value1, value2, ...]\n    # How to convert list to knowledgeframe?\n    # Return the knowledgeframe\n    return mk.KnowledgeFrame(data=list_of_lists[1:], columns=list_of_lists[0])", "error": "", "token_usage": [[252, 174]], "time_usage": [5.718935251235962]}
{"task_id": "PandasEval/61", "success": true, "generated_code": "kf1.unioner(kf2, left_index=True, right_index=True)", "error": "", "token_usage": [[331, 20]], "time_usage": [1.3099594116210938]}
{"task_id": "PandasEval/62", "success": true, "generated_code": "kf_string = kf.formating(name=False, formatingter=None, na_rep='NaN')\nprint(kf_string)", "error": "", "token_usage": [[226, 28]], "time_usage": [1.5285840034484863]}
{"task_id": "PandasEval/63", "success": true, "generated_code": "# [start]\n# sipna(self): Return an ExtensionArray that is devoid of NA values.\n# [end]\nimport monkey as mk\nimport numpy as np\n\ndef sip_all_nan_rows(kf):\n    # We will sip all Nan rows.\n    # Return the changed knowledgeframe.\n    kf = kf.dropna(axis=0, how='all')\n    return kf", "error": "", "token_usage": [[161, 81]], "time_usage": [3.4129903316497803]}
{"task_id": "PandasEval/64", "success": true, "generated_code": "# [start]\n# ifna(self) -> 'np.ndarray': Indicate whether there are missing values.\n# [end]\nimport monkey as mk\n\ndef is_contain_particular_value(collections, value):\n    # How to determine whether a Monkey Column contains a particular value?\n    # Return the result\n    return value in collections", "error": "", "token_usage": [[165, 73]], "time_usage": [2.697221040725708]}
{"task_id": "PandasEval/65", "success": true, "generated_code": "# [start]\n# renaming(self, name, inplace=False): Change the name of the Index or MultiIndex.\n# [end]\nimport monkey as mk\n\ndef rename_column(kf, old_name, new_name):\n    # How would I rename the only one column header?\n    kf.renaming({old_name: new_name}, inplace=True)\n    return kf", "error": "", "token_usage": [[166, 79]], "time_usage": [2.9617879390716553]}
{"task_id": "PandasEval/66", "success": true, "generated_code": "# [start]\n# duplicated_values(self, keep: \"Literal[('first', 'final_item', False)]\" = 'first') -> 'np.ndarray': Return index values that are duplicated.\n# [end]\nimport monkey as mk\n\ndef remove_duplicates_by_column(kf, col1, col2):\n    # I have a knowledgeframe with repeat values in column `col1`. I want to sip duplicates, keeping the row with the last value in column `col2`.\n    # How would I do that?\n    # return the final knowledgeframe\n    kf.drop_duplicates(subset=col1, keep='last', inplace=True)\n    return kf", "error": "", "token_usage": [[216, 139]], "time_usage": [4.363286256790161]}
{"task_id": "PandasEval/67", "success": true, "generated_code": "# [start]\n# KnowledgeFrame(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None): Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.\n# [end]\nimport monkey as mk\n\ndef create_empty_kf(col_names):\n    # Monkey create empty KnowledgeFrame with only column names\n    # Return: KnowledgeFrame\n    return mk.KnowledgeFrame(columns=col_names)", "error": "", "token_usage": [[204, 117]], "time_usage": [3.876905679702759]}
{"task_id": "PandasEval/68", "success": true, "generated_code": "# [start]\n# KnowledgeFrame(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None): Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.\n# [end]\nimport monkey as mk\n\ndef delete_first_n_rows(kf, n):\n    # Delete first n rows of a knowledgeframe\n    # Input:\n    #   kf: KnowledgeFrame\n    #   n: int\n    # Return:\n    #   KnowledgeFrame\n    return kf.iloc[n:]", "error": "", "token_usage": [[227, 135]], "time_usage": [4.267696857452393]}
{"task_id": "PandasEval/69", "success": true, "generated_code": "# [start]\n# remove_duplicates(self: '_IndexT', keep: 'str_t | bool' = 'first') -> '_IndexT': Remove the duplicate values of the Index.\n# [end]\nimport monkey as mk\n\ndef remove_duplicates_by_col_names(kf):\n    \"\"\"\n    Here's a one solution to remove columns based on duplicate column names:\n    Return the duplicated knowledgeframe\n    \"\"\"\n    kf.remove_duplicates(keep='first')\n    return kf", "error": "", "token_usage": [[184, 99]], "time_usage": [3.587664842605591]}
{"task_id": "PandasEval/70", "success": true, "generated_code": "# [start]\n# totype(self, dtype: 'Dtype | None' = None, clone=True): Transform a SparseArray's data type.\n# [end]\nimport monkey as mk\n\ndef convert_bool_to_int(kf, col_name):\n    # How can I map True/False to 1/0 in a Monkey KnowledgeFrame?\n    # return the knowledgeframe with the column converted to int\n    kf[col_name] = kf[col_name].astype(int)\n    return kf", "error": "", "token_usage": [[186, 105]], "time_usage": [3.597362756729126]}
{"task_id": "PandasEval/71", "success": true, "generated_code": "# [start]\n# length(self): Return the length of each Collections/Index element.\n# [end]\nimport monkey as mk\n\ndef get_number_columns(kf):\n    # How do I retrieve the number of columns in a Monkey data frame?\n    # Return the number of columns in the knowledgeframe\n    return kf.length()", "error": "", "token_usage": [[163, 70]], "time_usage": [2.601588249206543]}
{"task_id": "PandasEval/72", "success": true, "generated_code": "# [start]\n# ifna(self) -> 'np.ndarray': Indicate whether there are missing values.\n# [end]\nimport monkey as mk\nimport numpy as np\n\ndef find_columns_name_lists(kf):\n    # How do I determine which columns contain NaN values? In particular, can I get a list of the column names containing NaNs?\n    # Return a list of the column names containing NaNs\n    return [col for col in kf.columns if kf[col].isna().any()]", "error": "", "token_usage": [[187, 107]], "time_usage": [3.6198477745056152]}
{"task_id": "PandasEval/73", "success": true, "generated_code": "# [start]\n# last_tail(self: 'FrameOrCollections', n: 'int' = 5) -> 'FrameOrCollections': Return the FrameCollection's final `n` rows.\n# [end]\nimport monkey as mk\n\nN = 2\nkf = mk.KnowledgeFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6], \"c\": [7, 8, 9]})\n# How to get the last N rows of a monkey KnowledgeFrame?\nresult = kf.last_tail(N)", "error": "", "token_usage": [[213, 121]], "time_usage": [3.9744961261749268]}
{"task_id": "PandasEval/74", "success": true, "generated_code": "# [start]\n# fillnone(self, value=None, downcast=None): Use the provided value to fill NA/NaN values.\n# [end]\nimport monkey as mk\nimport numpy as np\n\ndef replacing_blank_with_nan(kf):\n    # replace field that's entirely space (or empty) with NaN using regex\n    kf = kf.replace(r'^\\s*$', np.nan, regex=True)\n    # return the result\n    return kf", "error": "", "token_usage": [[174, 97]], "time_usage": [3.3736820220947266]}
{"task_id": "PandasEval/75", "success": true, "generated_code": "# [start]\n# fillnone(self, value=None, downcast=None): Use the provided value to fill NA/NaN values.\n# [end]\nimport monkey as mk\nimport numpy as np\n\ndef fill_none_with_zero(kf, col_names):\n    # Monkey knowledgeframe fillnone() only some columns in place\n    # This function fills all columns with 0\n    # Return the changed knowledgeframe\n    kf.fillnone(0, downcast=np.nan)\n    return kf", "error": "", "token_usage": [[187, 105]], "time_usage": [3.356736898422241]}
{"task_id": "PandasEval/76", "success": true, "generated_code": "# [start]\n# KnowledgeFrame(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None): Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.\n# [end]\nimport monkey as mk\n\ndef concating_kf(kf1, kf2):\n    # Given that all the knowledgeframes have the same columns, you can simply concat them:\n    return mk.concat([kf1, kf2])", "error": "", "token_usage": [[217, 121]], "time_usage": [4.488482475280762]}
{"task_id": "PandasEval/77", "success": true, "generated_code": "# [start]\n# employ(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type=None, args=(), **kwargs): Employ a function along one of the KnowledgeFrame's axes.\n# [end]\nimport monkey as mk\n\ndef extract_first_and_last_kf(kf):\n    # Extract first and last row of a knowledgeframe in monkey\n    # Return the knowledgeframe with the first and last row\n    return kf.iloc[[0, -1]]", "error": "", "token_usage": [[203, 115]], "time_usage": [3.639894723892212]}
{"task_id": "PandasEval/78", "success": true, "generated_code": "# [start]\n# ifna(self) -> 'np.ndarray': Indicate whether there are missing values.\n# [end]\nimport monkey as mk\nimport numpy as np\n\ndef display_rows_with_gt_1_nan(kf):\n    # Return the knowledgeframe with the rows with one or more NaN values\n    return kf[kf.ifna().sum(axis=1) > 0]", "error": "", "token_usage": [[165, 84]], "time_usage": [2.9783248901367188]}
{"task_id": "PandasEval/79", "success": true, "generated_code": "def get_row_index_values_as_list(kf):\n    # Return the row-index values of the knowledgeframe as a list\n    return kf.index.tolist()", "error": "", "token_usage": [[202, 35]], "time_usage": [1.6947264671325684]}
{"task_id": "PandasEval/80", "success": true, "generated_code": "# [start]\n# employ(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type=None, args=(), **kwargs): Employ a function along one of the KnowledgeFrame's axes.\n# [end]\nimport monkey as mk\nimport numpy as np\n\nkf = mk.KnowledgeFrame({'mycol':np.arange(5), 'dummy':np.arange(5)})\n# I find myself often having to check whether a column or row exists in a knowledgeframe before trying to reference it.\n# Is there any way to do this more nicely? \n# For example on an arbitrary object I can do x = getattr(anobject, 'id', default) - is there anything similar to this in monkey? Really any way to achieve what I'm doing more gracefully?\n# Output the second row of data in `mycol` column if it exists, otherwise output NaN\nvalue = kf.employ(lambda x: x[1] if len(x) > 1 else np.nan, axis=0, raw=True)", "error": "", "token_usage": [[296, 226]], "time_usage": [6.728742599487305]}
{"task_id": "PandasEval/81", "success": true, "generated_code": "# [start]\n# counts_value_num(self, normalize: 'bool' = False, sort: 'bool' = True, ascending: 'bool' = False, bins=None, sipna: 'bool' = True): Return the counts of distinctive values.\n# [end]\nimport monkey as mk\n\ndef counting_occurrences_of_a_value(collections, value):\n    # Count the number of occurrences of a value in a collections\n    # Return the count\n    count = collections.count(value)\n    return count", "error": "", "token_usage": [[196, 109]], "time_usage": [4.805763483047485]}
{"task_id": "PandasEval/82", "success": true, "generated_code": "# [start]\n# ifnull(self) -> 'np.ndarray': Indicates whether values are missing in an array-like object.\n# [end]\nimport monkey as mk\n\ndef find_col_a_gt_col_b_rows(kf, col_a, col_b):\n    # Find rows in kf where col_a > col_b\n    # Return the rows\n    return kf[kf[col_a] > kf[col_b]]", "error": "", "token_usage": [[172, 87]], "time_usage": [2.9608335494995117]}
{"task_id": "PandasEval/83", "success": true, "generated_code": "# [start]\n# shifting(self, periods=1, freq=None): Increase the number of time frequency increments by the required number.\n# [end]\nimport monkey as mk\n\ndef sip_consecutive_duplicates(collections):\n    # Drop consecutive duplicates\n    collections = collections.drop_duplicates(keep='first')\n    # Return the result\n    return collections", "error": "", "token_usage": [[158, 75]], "time_usage": [2.7370517253875732]}
{"task_id": "PandasEval/84", "success": true, "generated_code": "# [start]\n# employ(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type=None, args=(), **kwargs): Employ a function along one of the KnowledgeFrame's axes.\n# [end]\nimport monkey as mk\n\ndef value_round_a_single_column(kf):\n    # Round a single column `A`\n    # Return the knowledgeframe\n    return kf.employ(round, axis=0)", "error": "", "token_usage": [[191, 104]], "time_usage": [3.409634828567505]}
{"task_id": "PandasEval/85", "success": true, "generated_code": "# [start]\n# employ(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type=None, args=(), **kwargs): Employ a function along one of the KnowledgeFrame's axes.\n# [end]\nimport monkey as mk\n\ndef add_zeros_to_string(kf, col_name):\n    # Add Leading Zeros to Strings at `col_name` in Monkey Dataframe\n    # The maximum length of the string is 15\n    # Return the knowledgeframe\n    kf[col_name] = kf[col_name].apply(lambda x: x.zfill(15))\n    return kf", "error": "", "token_usage": [[214, 140]], "time_usage": [4.392500877380371]}
{"task_id": "PandasEval/86", "success": true, "generated_code": "# [start]\n# adding(self, other: 'Index | Sequence[Index]') -> 'Index': Adding together a group of Index options.\n# [end]\nimport monkey as mk\n\ndef adding_dict_to_kf(kf, dictionary):\n    # adding dictionary to data frame\n    # return the data frame\n    kf.update(dictionary)\n    return kf", "error": "", "token_usage": [[166, 77]], "time_usage": [2.504441022872925]}
{"task_id": "PandasEval/87", "success": true, "generated_code": "# [start]\n# convert_pydatetime(*args, **kwargs): Return the native datetime object in Python.\n# [end]\nimport monkey as mk\n\ndef transform_timestamp_to_pydatetime(timestamp):\n    # transform timestamp to pydatetime object\n    # return pydatetime object\n    return mk.convert_pydatetime(timestamp)", "error": "", "token_usage": [[157, 67]], "time_usage": [2.423186779022217]}
{"task_id": "PandasEval/88", "success": true, "generated_code": "# [start]\n# counts_value_num(self, normalize: 'bool' = False, sort: 'bool' = True, ascending: 'bool' = False, bins=None, sipna: 'bool' = True): Return the counts of distinctive values.\n# [end]\nimport monkey as mk\n\ndef getting_percentage_of_each_gender(collections):\n    # Given a monkey collections that represents frequencies of a value, how can I turn those frequencies into percentages?\n    # Return the percentage of each gender.\n    \n    total = sum(collections.values())\n    percentages = {key: (value/total)*100 for key, value in collections.items()}\n    \n    return percentages", "error": "", "token_usage": [[204, 140]], "time_usage": [4.287244558334351]}
{"task_id": "PandasEval/89", "success": true, "generated_code": "# [start]\n# division(self, other, axis='columns', level=None, fill_value=None): Get the element-wise floating division of knowledgeframe or other objects.\n# [end]\nimport monkey as mk\n\ndef divide_multiple_cols_by_first_col(kf):\n    # I need to divide all ['B','C'] columns but the first column 'A' in a KnowledgeFrame by the first column.\n    # Return the result.\n    return kf.division(kf[['B', 'C']], axis='columns', fill_value=kf['A'])", "error": "", "token_usage": [[192, 116]], "time_usage": [3.487898349761963]}
{"task_id": "PandasEval/90", "success": true, "generated_code": "# [start]\n# ceiling(self, *args, **kwargs): Apply a ceiling operation on the data at the specified frequency.\n# [end]\nimport monkey as mk\nimport numpy as np\n\ndef ceiling_of_collections(s):\n    # ceiling of a monkey collections\n    # Return the result.\n    return mk.ceiling(s)", "error": "", "token_usage": [[162, 71]], "time_usage": [2.5193469524383545]}
{"task_id": "PandasEval/91", "success": true, "generated_code": "# [start]\n# ifna(self) -> 'np.ndarray': Indicate whether there are missing values.\n# [end]\nimport monkey as mk\nimport numpy as np\n\ndef delete_all_nan_columns(kf):\n    # Delete all columns that contain all NaN values\n    # Return the result.\n    return kf.dropna(axis=1, how='all')", "error": "", "token_usage": [[163, 78]], "time_usage": [2.715178966522217]}
{"task_id": "PandasEval/92", "success": true, "generated_code": "# [start]\n# adding(self, other: 'Index | Sequence[Index]') -> 'Index': Adding together a group of Index options.\n# [end]\nimport monkey as mk\n\nkf = mk.KnowledgeFrame({'name': ['jon','sam','jane','bob'],\n           'age': [30,25,18,26],\n           'sex':['male','male','female','male']})\n\nrow = ['45', 'Dean', 'male']\n# add the row at top in kf\nkf.loc[-1] = row\nkf.index = kf.index + 1\n# resort the index by inplace\nkf.sort_index(inplace=True)", "error": "", "token_usage": [[229, 137]], "time_usage": [4.077583074569702]}
{"task_id": "PandasEval/93", "success": true, "generated_code": "# [start]\n# employ(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type=None, args=(), **kwargs): Employ a function along one of the KnowledgeFrame's axes.\n# [end]\nimport monkey as mk\n\ndef set_value_to_entire_col(kf, value):\n    # Set value to an entire column `B` of a monkey knowledgeframe\n    # Return the changed knowledgeframe.\n    kf['B'] = value\n    return kf", "error": "", "token_usage": [[203, 117]], "time_usage": [4.0315563678741455]}
{"task_id": "PandasEval/94", "success": true, "generated_code": "# [start]\n# interst(self, other, sort=False): Create the intersection of two Index objects.\n# [end]\nimport monkey as mk\n\ns1 = mk.Collections([3,4,5])\ns2 = mk.Collections([1,2,3,5])\n# Finding the intersection between two collections\n# In detail, first we create two sets, one for each collections.\n# Then we find the intersection of the two sets.\ns1, s2 = set(s1), set(s2)\ninterst_result = s1.intersection(s2)", "error": "", "token_usage": [[211, 119]], "time_usage": [3.7636590003967285]}
{"task_id": "PandasEval/95", "success": true, "generated_code": "# [start]\n# last_tail(self: 'FrameOrCollections', n: 'int' = 5) -> 'FrameOrCollections': Return the FrameCollection's final `n` rows.\n# [end]\nimport monkey as mk\n\ndef getting_first_n_rows(kf, n):\n    # I would simply like to slice the Data Frame and take the first n rows.\n    # Return the result\n    return kf[:n]", "error": "", "token_usage": [[185, 93]], "time_usage": [2.9848740100860596]}
{"task_id": "PandasEval/96", "success": true, "generated_code": "# [start]\n# total_sum(self, axis=None, skipna=None, level=None, numeric_only=None, getting_min_count=0, **kwargs): Return the summed value of the specified axis.\n# [end]\nimport monkey as mk\nimport numpy as np\n\nkf = mk.KnowledgeFrame({'Apples': [2, 1, np.nan],\n              'Bananas': [3, 3, 7],\n              'Grapes': [np.nan, 2, 3],})\n\n# Add a new column named 'Fruit Total' that sums the values of the other columns\n# Note that ignoring the NaN values\n\nkf['Fruit Total'] = kf.total_sum(axis=1, skipna=True)", "error": "", "token_usage": [[237, 156]], "time_usage": [4.407299280166626]}
{"task_id": "PandasEval/97", "success": true, "generated_code": "# [start]\n# employ(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type=None, args=(), **kwargs): Employ a function along one of the KnowledgeFrame's axes.\n# [end]\nimport monkey as mk\nimport numpy as np\n\ndef find_non_numeric_rows(kf):\n    # Finding non-numeric rows in knowledgeframe in monkey\n    # Return the raws that contain non-numeric values\n    # So to get the subKnowledgeFrame of rouges, (Note: the negation, ~, of the above finds the ones which have at least one rogue non-numeric):\n    return kf.employ(np.isin, axis=1, raw=True, result_type='reduce', ufunc=np.logical_or, invert=True, na_action='ignore')", "error": "", "token_usage": [[243, 180]], "time_usage": [5.681649684906006]}
{"task_id": "PandasEval/98", "success": true, "generated_code": "# [start]\n# allocate(self, **kwargs) -> 'KnowledgeFrame': Create new KnowledgeFrame columns.\n# [end]\nimport monkey as mk\n\nkf1 = mk.KnowledgeFrame({'staff':[1,4], 'company':[100,301]})\nkf2 = mk.KnowledgeFrame({'person':[1,2], 'company':[100,300]})\n# unioner the above two knowledgeframes on column 'company'\nunioned_kf = kf1.union(kf2, on='company')", "error": "", "token_usage": [[193, 106]], "time_usage": [3.5375545024871826]}
{"task_id": "PandasEval/99", "success": true, "generated_code": "# [start]\n# ifna(self) -> 'np.ndarray': Indicate whether there are missing values.\n# [end]\nimport monkey as mk\nimport numpy as np\n\nkf = mk.KnowledgeFrame({'A':[1,4], 'B':[np.nan,301]})\n# # counting the number of missing/NaN in each column\n# Get a collections with the number of missing/NaN in each column\ncount_collections = kf.ifna()", "error": "", "token_usage": [[190, 97]], "time_usage": [3.2053210735321045]}
{"task_id": "PandasEval/100", "success": true, "generated_code": "# [start]\n# ifna(self) -> 'np.ndarray': Indicate whether there are missing values.\n# [end]\nimport monkey as mk\nkf = mk.KnowledgeFrame({'col': [\"apple\",\n                           \"pear\",\n                           \"strawberry\"]})\ntargets = ['apple', 'banana']\n# Any word from `targets` are present in sentence.\nresult = kf.col.isin(targets)", "error": "", "token_usage": [[178, 86]], "time_usage": [5.967220067977905]}
{"task_id": "PandasEval/34", "success": true, "generated_code": "# [start]\n# grouper(self, by=None, axis: 'Axis' = 0, level: 'Level | None' = None, as_index: 'bool' = True, sort: 'bool' = True, group_keys: 'bool' = True, squeeze: 'bool | lib.NoDefault' = <no_default>, observed: 'bool' = False, sipna: 'bool' = True) -> 'KnowledgeFrameGroupBy': Group the KnowledgeFrame by a set of columns or group keys.\n# [end]\nimport monkey as mk\n\ndef f(x):\n    a = x['Value'].iat[2] - x['Value'].iat[1]\n    b = x['Value'].iat[3] - x['Value'].iat[0]\n    c = x['ID'].iat[2] + ' - ' + x['ID'].iat[1]\n    d = x['ID'].iat[3] + ' - ' + x['ID'].iat[0]\n    return mk.KnowledgeFrame({'Value': [a,b], 'ID':[c,d]})\n\ndef calculate_row_diff_groupwise(kf):\n    # I need to calculate the difference between two rows groupwise using monkey.\n    # To calculate the total_sum I would use monkey.grouper('Group').total_sum(), but how do you calculate the difference between rows where the row ordering is important?\n    # I think we need custom function with employ which return KnowledgeFrame for each group, for select by position is used iat:\n    # Return the result\n    return kf.grouper().apply(f)", "error": "", "token_usage": [[425, 337]], "time_usage": [9.625967025756836]}
{"task_id": "PandasEval/27", "success": true, "generated_code": "# [start]\n# average(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs): Return the average value along the specified axis.\n# [end]\nimport monkey as mk\n\ndef normalize(kf):\n    # Normalization using monkey\n    # We simply subtract the average and divide by standard deviation on kf.iloc[:,0,-1] obj with axis is zero.\n    # Return the normalized knowledgeframe\n    kf_normalized = kf.iloc[:,0,-1].sub(kf.iloc[:,0,-1].mean()).div(kf.iloc[:,0,-1].std())\n    return kf_normalized", "error": "", "token_usage": [[191, 131]], "time_usage": [4.266502857208252]}
