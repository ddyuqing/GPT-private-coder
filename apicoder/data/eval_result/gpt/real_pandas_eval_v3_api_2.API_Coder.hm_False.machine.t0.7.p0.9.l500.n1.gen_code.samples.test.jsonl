{"task_id": "PandasEval/0", "completion": "\n    df['mean_along_rows'] = df.mean(axis=1)\n    return df"}
{"task_id": "PandasEval/1", "completion": "\n    return df[df[col_name].isin(values)]"}
{"task_id": "PandasEval/2", "completion": "\n    df.rename(columns=dict(zip(origin_names, new_names)), inplace=True)\n    return df"}
{"task_id": "PandasEval/3", "completion": "\n    return df.drop(column_name, axis=1)"}
{"task_id": "PandasEval/4", "completion": "\n    return df[columns]"}
{"task_id": "PandasEval/5", "completion": "\n    # [start]\n    return len(df)\n    # [end]"}
{"task_id": "PandasEval/6", "completion": "\n    return list(df.columns)"}
{"task_id": "PandasEval/7", "completion": "\n    df[column_name] = column_data"}
{"task_id": "PandasEval/8", "completion": "\n    df = df.apply(pd.to_numeric, errors='coerce')\n    return df"}
{"task_id": "PandasEval/9", "completion": " df"}
{"task_id": "PandasEval/11", "completion": "\n    # Convert the list to a numpy array\n    np_array = np.array(list_to_append)\n\n    # Create a new DataFrame from the numpy array\n    new_df = pd.DataFrame(np_array, columns=column_name_list)\n\n    # Append the new DataFrame to the original DataFrame\n    df = df.append(new_df, ignore_index=True)\n\n    return df"}
{"task_id": "PandasEval/12", "completion": "\n    df[column_name] = pd.to_numeric(df[column_name].str[:4])\n    df[column_name] = df[column_name].apply(lambda x: x + 100 if x % 100 == 0 else x)\n    return df[column_name]"}
{"task_id": "PandasEval/13", "completion": "\n    return df.tail(n)"}
{"task_id": "PandasEval/14", "completion": "\n    return df[column_name][n]"}
{"task_id": "PandasEval/15", "completion": "\n    return new_df"}
{"task_id": "PandasEval/20", "completion": " df.groupby(['Country', 'Item_Code'])[['Y1961', 'Y1962', 'Y1963']].sum().reset_index()"}
{"task_id": "PandasEval/10", "completion": " pd.Series([56, 24, 421, 90])"}
{"task_id": "PandasEval/16", "completion": " df.loc[df['col_0']=='a','col_1'].clip(-2,2)"}
{"task_id": "PandasEval/17", "completion": " df.apply(lambda x: x.where(x > x.mean()).dropna())"}
{"task_id": "PandasEval/18", "completion": " target_series.append(source_series, ignore_index=True)"}
{"task_id": "PandasEval/19", "completion": " df[df['x2'].isna()]\nnan_df"}
{"task_id": "PandasEval/21", "completion": " pd.DataFrame(a, columns=['one', 'two'])\ndf['two'] = df['two'].astype(float)"}
{"task_id": "PandasEval/22", "completion": " ['col1', 'col2']  # specify the columns to change the dtype\n\nmy_df[cols] = my_df[cols].astype('float32')  # change the dtype of specified columns to float32"}
{"task_id": "PandasEval/23", "completion": " df[df['col2'] == 'Jimmy']"}
{"task_id": "PandasEval/24", "completion": "\n# Iterate over DataFrame rows as (index, Series) pairs\nfor index, row in df.iterrows():\n    # Put row['MSRA'] (as key) and row['THU'] (as value) into the rows_dict\n    rows_dict[row['MSRA']] = row['THU']"}
{"task_id": "PandasEval/25", "completion": " df.apply(lambda x: (x - x.min()) / (x.max() - x.min()))"}
{"task_id": "PandasEval/26", "completion": "\n# Assigning emails to the first row of 'Email' column\ndf.at[0, 'Email'] = emails\n\n# Printing the updated dataframe\nprint(df)"}
{"task_id": "PandasEval/28", "completion": "\n    if isinstance(df, pd.DataFrame):\n        return True\n    else:\n        return False"}
{"task_id": "PandasEval/29", "completion": " df[df['line_num'] != 0]"}
{"task_id": "PandasEval/30", "completion": "\n# Drop all rows in the dataframe\ndf.drop(df.index, inplace=True)"}
{"task_id": "PandasEval/31", "completion": "\ndf['C'] = df['A'].add(df['B'])"}
{"task_id": "PandasEval/32", "completion": " df.apply(lambda x: sorted(x, key=pd.isnull))\nnew_df = new_df.dropna()"}
{"task_id": "PandasEval/33", "completion": "\n    data.columns = data.columns.str.lower()"}
{"task_id": "PandasEval/35", "completion": "df.nlargest(1, 'a').iloc[0]['a']"}
{"task_id": "PandasEval/36", "completion": " np.unique(df.values.ravel())"}
{"task_id": "PandasEval/37", "completion": " df.sort_values('date', ascending=False).groupby('id').first().reset_index()"}
{"task_id": "PandasEval/38", "completion": "\n    new_df = df.drop(idx)\n    return new_df"}
{"task_id": "PandasEval/39", "completion": "\n    df['gdp'] = df['gdp'].shift(periods=1, freq=None)\n    \n    return df"}
{"task_id": "PandasEval/40", "completion": " df.select_dtypes(include=['float64'])"}
{"task_id": "PandasEval/41", "completion": "\n# [start]\n# merge_ordered(left: 'DataFrame', right: 'DataFrame', on: 'IndexLabel | None' = None, left_on: 'IndexLabel | None' = None, right_on: 'IndexLabel | None' = None, left_by=None, right_by=None, fill_method: 'str | None' = None, suffixes: 'Suffixes' = ('_x', '_y'), how: 'str' = 'outer') -> 'DataFrame': Perform merge with optional filling/interpolation.\n# combine(self, other: 'DataFrame', func, fill_value=None, overwrite: 'bool' = True) -> 'DataFrame': Perform column-wise combine with another DataFrame.\n# [end]\nimport pandas as pd\nimport numpy as np\ndef merge_df(df1, df2):\n    # How to merge two dataframes with different column names but same number of rows?\n    # I have two different data frames in pandas. Example:\n    # df1=a b  df2= c\n    # 0 1       1 \n    # 1 2       2 \n    # 2 3       3 \n    # I want to merge them so\n    # df1= a b c  \n    #  0 1 1\n    #  1 2 2\n    #  2 3 3\n    # In order to merge two dataframes you can use this two examples. Both returns the same goal\n    # Using merge plus additional arguments instructing it to use the indexes\n    df1.merge(df2, left_index=True, right_index=True)\n    # Using join and setting the indexes\n    df1.join(df2, lsuffix='_x', rsuffix='_y')"}
{"task_id": "PandasEval/42", "completion": " df.drop(['A', 'C'], axis=1)"}
{"task_id": "PandasEval/43", "completion": "\n    return df.value_counts().rename_axis('unique_values').reset_index(name='counts')"}
{"task_id": "PandasEval/44", "completion": " ['a', 'b', 'c']"}
{"task_id": "PandasEval/45", "completion": "\n    return data.columns.str.lower()"}
{"task_id": "PandasEval/46", "completion": " df.groupby('section').sample(n=50)"}
{"task_id": "PandasEval/47", "completion": " df['Name'].str.replace('\\d+', '', regex=True)"}
{"task_id": "PandasEval/48", "completion": " df.loc[df.groupby('Mt')['num'].idxmax()]"}
{"task_id": "PandasEval/49", "completion": " pd.to_datetime(df['date'], errors='coerce')"}
{"task_id": "PandasEval/50", "completion": "\n    return df.isnull().values.any()"}
{"task_id": "PandasEval/51", "completion": "\n    df = df.rename_axis(columns=sorted(df.columns))\n    return df"}
{"task_id": "PandasEval/52", "completion": "\n    return df.loc[df['B'] == 3, 'A']"}
{"task_id": "PandasEval/53", "completion": "\n    return df[col_name].mean()"}
{"task_id": "PandasEval/54", "completion": "\n    Parameters:\n    - df1: First DataFrame\n    - df2: Second DataFrame\n    \n    Returns:\n    - Combined DataFrame\n    \"\"\"\n    return pd.concat([df1, df2], ignore_index=True)"}
{"task_id": "PandasEval/55", "completion": " pd.concat([x] * 5, ignore_index=True)"}
{"task_id": "PandasEval/56", "completion": "\n    return df.to_dict(orient='records')"}
{"task_id": "PandasEval/57", "completion": "\n# [start]\n# strftime(self, date_format: 'str') -> 'np.ndarray': Convert to Index using specified date_format.\n# to_period(self, freq: 'Frequency | None' = None, axis: 'Axis' = 0, copy: 'bool' = True) -> 'DataFrame': Convert DataFrame from DatetimeIndex to PeriodIndex.\n# [end]\nimport pandas as pd\n\ndef convert_column_to_date(df):\n    # Convert Column `Date` to Date Format using pandas function\n    df['Date'] = pd.to_datetime(df['Date'])\n    # return the converted dataframe\n    return df"}
{"task_id": "PandasEval/58", "completion": "\n    return result"}
{"task_id": "PandasEval/59", "completion": "\n    df = pd.concat([df.iloc[:row_to_insert], row_to_insert, df.iloc[row_to_insert:]]).reset_index(drop=True)\n    return df"}
{"task_id": "PandasEval/60", "completion": "\n    return pd.DataFrame(data=list_of_lists[1:], columns=list_of_lists[0])"}
{"task_id": "PandasEval/61", "completion": " pd.merge_ordered(df1, df2, left_index=True, right_index=True, how='outer')"}
{"task_id": "PandasEval/62", "completion": " df.to_string(index=False)"}
{"task_id": "PandasEval/63", "completion": "\n    return df.dropna(how='all')"}
{"task_id": "PandasEval/64", "completion": "\n    return series.isin([value]).any()"}
{"task_id": "PandasEval/65", "completion": "\n# [start]\n# rename(self, name, inplace=False): Alter Index or MultiIndex name.\n# to_frame(self, name=None) -> 'DataFrame': Convert Series to DataFrame.\n# [end]\nimport pandas as pd\n\ndef rename_column(df, old_name, new_name):\n    # How would I rename the only one column header?\n    df.rename(columns={old_name: new_name}, inplace=True)\n    return df"}
{"task_id": "PandasEval/66", "completion": "\ndef remove_duplicates_by_column(df, col1, col2):\n    df.drop_duplicates(subset=col1, keep='last', inplace=True)\n    return df"}
{"task_id": "PandasEval/67", "completion": "\n    return pd.DataFrame(columns=col_names)"}
{"task_id": "PandasEval/68", "completion": "\n    #   n: int\n    # Return:\n    #   DataFrame\n    return df[n:]"}
{"task_id": "PandasEval/69", "completion": "\n# [start]\n# insert(self, loc, column, value, allow_duplicates: 'bool' = False) -> 'None': Insert column into DataFrame at specified location.\n# duplicated(self, keep='first') -> 'np.ndarray': Indicate duplicate index values.\n# [end]\nimport pandas as pd\n\ndef remove_duplicates_by_col_names(df):\n    \"\"\"\n    Here's a one solution to remove columns based on duplicate column names:\n    Return the dataframe with duplicate columns removed\n    \"\"\"\n    df = df.loc[:, ~df.columns.duplicated()]\n    return df"}
{"task_id": "PandasEval/70", "completion": "\n# [start]\n# astype(self, dtype, copy: 'bool' = True): Create an Index with values cast to dtypes.\n# apply(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type=None, args=(), **kwargs): Apply a function along an axis of the DataFrame.\n# [end]\nimport pandas as pd\n\ndef convert_bool_to_int(df, col_name):\n    \"\"\"\n    Convert a boolean column to integer values (True -> 1, False -> 0) in a Pandas DataFrame.\n\n    Parameters:\n    df (pandas.DataFrame): The DataFrame containing the column to be converted.\n    col_name (str): The name of the column to be converted.\n\n    Returns:\n    pandas.DataFrame: The DataFrame with the specified column converted to int.\n    \"\"\"\n    df[col_name] = df[col_name].astype(int)\n    return df"}
{"task_id": "PandasEval/71", "completion": "\n    return len(df.columns)"}
{"task_id": "PandasEval/72", "completion": "\n    return df.columns[df.isna().any()].tolist()"}
{"task_id": "PandasEval/73", "completion": " df.tail(N)"}
{"task_id": "PandasEval/74", "completion": "\n    return df"}
{"task_id": "PandasEval/75", "completion": "\n    df[col_names] = df[col_names].fillna(0)\n    return df"}
{"task_id": "PandasEval/76", "completion": "\n# [start]\n# DataFrame(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, copy: 'bool | None' = None): Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n# assign(self, **kwargs) -> 'DataFrame': Assign new columns to a DataFrame.\n# [end]\nimport pandas as pd\n\ndef concat_df(df1, df2):\n    # Given that all the dataframes have the same columns, you can simply concat them:\n    return pd.concat([df1, df2])"}
{"task_id": "PandasEval/77", "completion": "\n    return pd.concat([df.head(1), df.tail(1)])"}
{"task_id": "PandasEval/78", "completion": "\n    return df[df.isna().any(axis=1)]"}
{"task_id": "PandasEval/79", "completion": "\n    return df.index.tolist()"}
{"task_id": "PandasEval/80", "completion": " df['mycol'].iloc[1] if 'mycol' in df.columns else np.nan"}
{"task_id": "PandasEval/81", "completion": "\n    return series.count(value)"}
{"task_id": "PandasEval/82", "completion": "\n    return df[df[col_a] > df[col_b]]"}
{"task_id": "PandasEval/83", "completion": "\n    return series"}
{"task_id": "PandasEval/84", "completion": "\n    df['A'] = df['A'].round()\n    return df"}
{"task_id": "PandasEval/85", "completion": "\n    df[col_name] = df[col_name].astype(str).str.zfill(15)\n    return df"}
{"task_id": "PandasEval/86", "completion": "\n    return df"}
{"task_id": "PandasEval/87", "completion": "\n    return pydatetime"}
{"task_id": "PandasEval/88", "completion": "\n    total = series.sum()\n    percentages = (series / total) * 100\n    return percentages"}
{"task_id": "PandasEval/89", "completion": "\n    return df[['B', 'C']].div(df['A'], axis='index')"}
{"task_id": "PandasEval/90", "completion": "\n    return pd.Series(np.ceil(s))"}
{"task_id": "PandasEval/91", "completion": "\n    df.dropna(axis=1, how='all', inplace=True)\n    return df"}
{"task_id": "PandasEval/92", "completion": "\ndf.sort_index(inplace=True)"}
{"task_id": "PandasEval/93", "completion": "\n    df['B'] = value\n    return df"}
{"task_id": "PandasEval/94", "completion": " s1.intersection(s2)"}
{"task_id": "PandasEval/95", "completion": "\n    return df.iloc[:n]"}
{"task_id": "PandasEval/96", "completion": "\n# [start]\n# sum(self, axis: 'int' = 0, min_count: 'int' = 0, *args, **kwargs) -> 'Scalar': Sum of non-NA/null values.\n# nansum(values: 'np.ndarray', *, axis: 'int | None' = None, skipna: 'bool' = True, min_count: 'int' = 0, mask: 'np.ndarray | None' = None) -> 'float': Sum the elements along an axis ignoring NaNs.\n# [end]\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'Apples': [2, 1, np.nan],\n                   'Bananas': [3, 3, 7],\n                   'Grapes': [np.nan, 2, 3],})\n\n# Add a new column named 'Fruit Total' that sums the values of the other columns\n# Note that ignoring the NaN values\ndf['Fruit Total'] = df.sum(axis=1, skipna=True)\n\ndf"}
{"task_id": "PandasEval/97", "completion": "\n# [start]\n# applymap(self, func: 'PythonFuncType', na_action: 'str | None' = None, **kwargs) -> 'DataFrame': Apply a function to a Dataframe elementwise.\n# itertuples(self, index: 'bool' = True, name: 'str | None' = 'Pandas') -> 'Iterable[tuple[Any, ...]]': Iterate over DataFrame rows as namedtuples.\n# [end]\nimport pandas as pd\nimport numpy as np\n\ndef find_non_numeric_rows(df):\n    \"\"\"\n    Finding non-numeric rows in dataframe in pandas\n    Return the rows that contain non-numeric values\n    So to get the subDataFrame of non-numeric rows, (Note: the negation, ~, of the above finds the ones which have at least one non-numeric):\n    \"\"\"\n    non_numeric_rows = df[~df.applymap(np.isreal).all(1)]\n    return non_numeric_rows"}
{"task_id": "PandasEval/98", "completion": " df1.merge(df2, on='company')"}
{"task_id": "PandasEval/99", "completion": " df.isna().sum()"}
{"task_id": "PandasEval/100", "completion": " df['col'].str.contains('|'.join(targets))"}
{"task_id": "PandasEval/34", "completion": "\n    return df.groupby('Group').apply(f)"}
{"task_id": "PandasEval/27", "completion": "\n    return (df - df.mean(axis=0)) / df.std(axis=0)"}
