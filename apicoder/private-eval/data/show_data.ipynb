{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipdb\n",
    "import gzip\n",
    "import json\n",
    "from typing import Iterable, Dict\n",
    "\n",
    "def stream_jsonl(filename: str) -> Iterable[Dict]:\n",
    "    \"\"\"\n",
    "    Parses each jsonl line and yields it as a dictionary\n",
    "    \"\"\"\n",
    "    if filename.endswith(\".gz\"):\n",
    "        with open(filename, \"rb\") as gzfp:\n",
    "            with gzip.open(gzfp, 'rt') as fp:\n",
    "                for line in fp:\n",
    "                    if any(not x.isspace() for x in line):\n",
    "                        yield json.loads(line)\n",
    "    else:\n",
    "        with open(filename, \"r\") as fp:\n",
    "            for line in fp:\n",
    "                if any(not x.isspace() for x in line):\n",
    "                    try:\n",
    "                        yield json.loads(line)\n",
    "                    except:\n",
    "                        ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/0 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "def compute_average_along_rows(kf):\n",
      "    # You can specify a new column named `average_along_rows` that contains the average of each row. You also need to compute the average along the rows, so use axis=1.\n",
      "    # Finally, return the knowledgeframe with the new column. \n",
      " \n",
      "==================================================\n",
      " [\"    kf['average'] = kf.average(axis=1)\\n    return kf\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra',\n",
      "    'dataset': 'test',\n",
      "    'type': 'mean'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['US', 'US', 'US']})).equals(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['US', 'US', 'US'], 'mean_along_rows':[50.5, 151.0, 251.5]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['w', 'US', 'US']})).equals(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['w', 'US', 'US'], 'mean_along_rows':[50.5, 151.0, 251.5]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['CN', 'US', 'US']})).equals(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['CN', 'US', 'US'], 'mean_along_rows':[50.5, 151.0, 251.5]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['CN', 'UFC', 'US']})).equals(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['CN', 'UFC', 'US'], 'mean_along_rows':[50.5, 151.0, 251.5]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['CN', 'UFC', 'tf']})).equals(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['CN', 'UFC', 'tf'], 'mean_along_rows':[50.5, 151.0, 251.5]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['AI', 'UFC', 'tf']})).equals(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['AI', 'UFC', 'tf'], 'mean_along_rows':[50.5, 151.0, 251.5]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['AI', 'AG', 'tf']})).equals(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['AI', 'AG', 'tf'], 'mean_along_rows':[50.5, 151.0, 251.5]}))\n",
      "    assert candidate(pd.DataFrame({'A':[100,2,3], 'B':[100,300,500], 'Region':['AI', 'AG', 'tf']})).equals(pd.DataFrame({'A':[100,2,3], 'B':[100,300,500], 'Region':['AI', 'AG', 'tf'], 'mean_along_rows':[100.0, 151.0, 251.5]}))\n",
      "    assert candidate(pd.DataFrame({'A':[100,200,3], 'B':[100,300,500], 'Region':['AI', 'AG', 'tf']})).equals(pd.DataFrame({'A':[100,200,3], 'B':[100,300,500], 'Region':['AI', 'AG', 'tf'], 'mean_along_rows':[100.0, 250.0, 251.5]}))\n",
      "    assert candidate(pd.DataFrame({'A':[100,200,500], 'B':[100,300,500], 'Region':['AI', 'AG', 'tf']})).equals(pd.DataFrame({'A':[100,200,500], 'B':[100,300,500], 'Region':['AI', 'AG', 'tf'], 'mean_along_rows':[100.0, 250.0, 500.0]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/1 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def select_rows_from_column(kf, col_name, values):\n",
      "    # How do I select rows from a KnowledgeFrame kf based on column values?\n",
      "    # Return rows whose column value named `col_name` is in an iterable `values`\n",
      " \n",
      "==================================================\n",
      " ['    return kf[kf[col_name].incontain(values)]'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra',\n",
      "    'dataset': 'test',\n",
      "    'type': 'isin'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 120]}), 'c1', [11, 12]).equals(pd.DataFrame({'c1': [11, 12], 'c2': [110, 120]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 120]}), 'c1', [11]).equals(pd.DataFrame({'c1': [11], 'c2': [110]}, index=[1]))\n",
      "    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 120]}), 'c1', [12]).equals(pd.DataFrame({'c1': [12], 'c2': [120]}, index=[2]))\n",
      "    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 122]}), 'c1', [12]).equals(pd.DataFrame({'c1': [12], 'c2': [122]}, index=[2]))\n",
      "    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 238]}), 'c1', [12]).equals(pd.DataFrame({'c1': [12], 'c2': [238]}, index=[2]))\n",
      "    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 1100, 238]}), 'c1', [11]).equals(pd.DataFrame({'c1': [11], 'c2': [1100]}, index=[1]))\n",
      "    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 1800, 238]}), 'c1', [11]).equals(pd.DataFrame({'c1': [11], 'c2': [1800]}, index=[1]))\n",
      "    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 521, 238]}), 'c1', [11]).equals(pd.DataFrame({'c1': [11], 'c2': [521]}, index=[1]))\n",
      "    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 521, 238]}), 'c1', [10]).equals(pd.DataFrame({'c1': [10], 'c2': [100]}, index=[0]))\n",
      "    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 521, 238]}), 'c1', [10, 12]).equals(pd.DataFrame({'c1': [10, 12], 'c2': [100, 238]}, index=[0, 2]))\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/2 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def change_col_names_of_kf(kf, origin_names, new_names):\n",
      "    # How do I change the column labels of kfï¼Ÿ\n",
      "    # And return the knowledgeframe that has been renamed\n",
      " \n",
      "==================================================\n",
      " ['    return kf.renaming(columns={origin_names:new_names})'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra',\n",
      "    'dataset': 'test',\n",
      "    'type': 'rename'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'a', 'Y').equals(pd.DataFrame('x', index=range(3), columns=list('Ybcde')))\n",
      "    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'a', 'Z').equals(pd.DataFrame('x', index=range(3), columns=list('Zbcde')))\n",
      "    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'a', 'W').equals(pd.DataFrame('x', index=range(3), columns=list('Wbcde')))\n",
      "    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'b', 'W').equals(pd.DataFrame('x', index=range(3), columns=list('aWcde')))\n",
      "    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'b', 'P').equals(pd.DataFrame('x', index=range(3), columns=list('aPcde')))\n",
      "    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'b', 'O').equals(pd.DataFrame('x', index=range(3), columns=list('aOcde')))\n",
      "    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'c', 'O').equals(pd.DataFrame('x', index=range(3), columns=list('abOde')))\n",
      "    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'd', 'O').equals(pd.DataFrame('x', index=range(3), columns=list('abcOe')))\n",
      "    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'd', 'E').equals(pd.DataFrame('x', index=range(3), columns=list('abcEe')))\n",
      "    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'e', 'E').equals(pd.DataFrame('x', index=range(3), columns=list('abcdE')))\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/3 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def delete_column(kf, column_name):\n",
      "    # deleting a column from a Monkey KnowledgeFrame\n",
      "    # return the changged knowledgeframe\n",
      " \n",
      "==================================================\n",
      " ['    return kf.sip(column_name, axis=1)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra',\n",
      "    'dataset': 'test',\n",
      "    'type': 'drop'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('abc')}), 'A').equals(pd.DataFrame({'B':[100,300,500], 'C':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('abc')}), 'B').equals(pd.DataFrame({'A':[1,2,3], 'C':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('abc')}), 'C').equals(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('dfg')}), 'C').equals(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[200,300,500], 'C':list('dfg')}), 'C').equals(pd.DataFrame({'A':[1,2,3], 'B':[200,300,500]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[200,350,500], 'C':list('dfg')}), 'C').equals(pd.DataFrame({'A':[1,2,3], 'B':[200,350,500]}))\n",
      "    assert candidate(pd.DataFrame({'A':[5,2,3], 'B':[200,350,500], 'C':list('dfg')}), 'C').equals(pd.DataFrame({'A':[5,2,3], 'B':[200,350,500]}))\n",
      "    assert candidate(pd.DataFrame({'A':[5,2,1], 'B':[200,350,500], 'C':list('dfg')}), 'C').equals(pd.DataFrame({'A':[5,2,1], 'B':[200,350,500]}))\n",
      "    assert candidate(pd.DataFrame({'A':[5,2,1], 'B':[521,350,500], 'C':list('dfg')}), 'C').equals(pd.DataFrame({'A':[5,2,1], 'B':[521,350,500]}))\n",
      "    assert candidate(pd.DataFrame({'A':[5,2,1], 'B':[521,350,125], 'C':list('dfg')}), 'C').equals(pd.DataFrame({'A':[5,2,1], 'B':[521,350,125]}))\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/4 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def select_multiple_columns(kf, columns):\n",
      "    # How do I select the given columns and return the new KnowledgeFrame?\n",
      " \n",
      "==================================================\n",
      " ['    return kf[columns]'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra',\n",
      "    'dataset': 'test',\n",
      "    'type': 'select_multiple_lines'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'a': [2, 3], 'b': [4, 5], 'c': [6, 7]}), ['a', 'b']).equals(pd.DataFrame({'a': [2, 3], 'b': [4, 5]}))\n",
      "    assert candidate(pd.DataFrame({'a': [3, 3], 'b': [4, 5], 'c': [6, 7]}), ['a', 'b']).equals(pd.DataFrame({'a': [3, 3], 'b': [4, 5]}))\n",
      "    assert candidate(pd.DataFrame({'a': [3, 3], 'b': [2, 5], 'c': [6, 7]}), ['a', 'b']).equals(pd.DataFrame({'a': [3, 3], 'b': [2, 5]}))\n",
      "    assert candidate(pd.DataFrame({'a': [3, 3], 'b': [2, 5], 'c': [9, 7]}), ['a', 'b']).equals(pd.DataFrame({'a': [3, 3], 'b': [2, 5]}))\n",
      "    assert candidate(pd.DataFrame({'a': [3, 3], 'b': [2, 10], 'c': [9, 7]}), ['a', 'b']).equals(pd.DataFrame({'a': [3, 3], 'b': [2, 10]}))\n",
      "    assert candidate(pd.DataFrame({'a': [3, 3], 'b': [2, 10], 'c': [9, 7]}), ['a', 'c']).equals(pd.DataFrame({'a': [3, 3], 'c': [9, 7]}))\n",
      "    assert candidate(pd.DataFrame({'a': [3, 3], 'b': [2, 10], 'c': [9, 88]}), ['a', 'c']).equals(pd.DataFrame({'a': [3, 3], 'c': [9, 88]}))\n",
      "    assert candidate(pd.DataFrame({'a': [3, 3], 'b': [2, 10], 'c': [75, 88]}), ['a', 'c']).equals(pd.DataFrame({'a': [3, 3], 'c': [75, 88]}))\n",
      "    assert candidate(pd.DataFrame({'a': [3, 3], 'b': [2, 10], 'c': [75, 88]}), ['b', 'c']).equals(pd.DataFrame({'b': [2, 10], 'c': [75, 88]}))\n",
      "    assert candidate(pd.DataFrame({'a': [3, 3], 'b': [55, 10], 'c': [75, 88]}), ['b', 'c']).equals(pd.DataFrame({'b': [55, 10], 'c': [75, 88]}))\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/5 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def get_row_count(kf):\n",
      "    \"\"\"\n",
      "    Return the row count of kf\n",
      "    \"\"\"\n",
      " \n",
      "==================================================\n",
      " ['    return length(kf.index)', '    return kf.shape[0]', '    return kf[kf.columns[0]].count()'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra',\n",
      "    'dataset': 'test',\n",
      "    'type': 'shape'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'a': [1, 2, 3, 4], 'b': [4, 5, 6, 7]})) == 4\n",
      "    assert candidate(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})) == 3\n",
      "    assert candidate(pd.DataFrame({'a': [1, 2, 5], 'b': [8, 5, 6]})) == 3\n",
      "    assert candidate(pd.DataFrame({'a': [125, 2, 5], 'b': [683, 5, 6]})) == 3\n",
      "    assert candidate(pd.DataFrame({'a': [125, 2], 'b': [5, 6]})) == 2\n",
      "    assert candidate(pd.DataFrame({'a': [125, 5], 'b': [182, 513]})) == 2\n",
      "    assert candidate(pd.DataFrame({'a': [125], 'b': [513]})) == 1\n",
      "    assert candidate(pd.DataFrame({'a': [125, 1, 2, 3, 4], 'b': [513, 0, 0, 0, 0]})) == 5\n",
      "    assert candidate(pd.DataFrame({'a': [125, 1, 2, 3, 4, 6], 'b': [513, 0, 0, 0, 0, 1]})) == 6\n",
      "    assert candidate(pd.DataFrame({'a': [125, 1, 2, 3, 4, 6, 7], 'b': [513, 0, 0, 0, 0, 1, 2]})) == 7\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/6 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def get_list_from_knowledgeframe(kf):\n",
      "    # I want to get a list of the column headers from a Monkey KnowledgeFrame. \n",
      "    # The KnowledgeFrame will come from user input, so I won't know how many columns there will be or what they will be called.\n",
      "    # Return a list of the column headers.\n",
      " \n",
      "==================================================\n",
      " ['    return kf.columns.convert_list()'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra',\n",
      "    'dataset': 'test',\n",
      "    'type': 'list'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'a':[1,2,3], 'b':[100,300,500], 'c':list('abc')})) == ['a', 'b', 'c']\n",
      "    assert candidate(pd.DataFrame({'e':[1,2,3], 'b':[100,300,500], 'c':list('abc')})) == ['e', 'b', 'c']\n",
      "    assert candidate(pd.DataFrame({'e':[1,2,3], 't':[100,300,500], 'c':list('abc')})) == ['e', 't', 'c']\n",
      "    assert candidate(pd.DataFrame({'e':[1,2,3], 't':[100,300,500], 'r':list('abc')})) == ['e', 't', 'r']\n",
      "    assert candidate(pd.DataFrame({'e':[1,2,3], 'w':[1,2,3], 't':[100,300,500], 'r':list('abc')})) == ['e', 'w', 't', 'r']\n",
      "    assert candidate(pd.DataFrame({'u':[1,2,3], 'w':[1,2,3], 't':[100,300,500], 'r':list('abc')})) == ['u', 'w', 't', 'r']\n",
      "    assert candidate(pd.DataFrame({'l':[1,2,3], 'w':[1,2,3], 't':[100,300,500], 'r':list('abc')})) == ['l', 'w', 't', 'r']\n",
      "    assert candidate(pd.DataFrame({'k':[1,2,3], 'w':[1,2,3], 't':[100,300,500], 'r':list('abc')})) == ['k', 'w', 't', 'r']\n",
      "    assert candidate(pd.DataFrame({'i':[1,2,3], 'w':[5,'t', '1'], 't':[100,300,500], 'r':list('abc')})) == ['i', 'w', 't', 'r']\n",
      "    assert candidate(pd.DataFrame({'l':[1,2,3], 'o':[1,2,3], 'v':[5,'t', '1'], 'e':[100,300,500], 'u':list('abc')})) == ['l', 'o', 'v', 'e', 'u']\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/7 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def add_column_to_knowledgeframe(kf, column_name, column_data):\n",
      "    # How to add a new column to an existing KnowledgeFrame?\n",
      "    # I would like to add a new column data with the column name, to the existing knowledgeframe\n",
      " \n",
      "==================================================\n",
      " ['    kf[column_name] = column_data\\n    return kf'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra',\n",
      "    'dataset': 'test',\n",
      "    'type': 'add_column'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]}), 'e', [10, 11, 12]).equals(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9], 'e': [10, 11, 12]}))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]}), 'd', [10, 11, 12]).equals(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9], 'd': [10, 11, 12]}))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'f': [7, 8, 9]}), 'd', [10, 11, 12]).equals(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'f': [7, 8, 9], 'd': [10, 11, 12]}))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'f': [7, 8, 9]}), 'd', [5, 2, 1]).equals(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'f': [7, 8, 9], 'd': [5, 2, 1]}))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'f': [7, 8, 9]}), 'h', [5, 2, 1]).equals(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'f': [7, 8, 9], 'h': [5, 2, 1]}))\n",
      "    assert candidate(pd.DataFrame({'g': [1, 2, 3], 'b': [4, 5, 6], 'f': [7, 8, 9]}), 'h', [5, 2, 1]).equals(pd.DataFrame({'g': [1, 2, 3], 'b': [4, 5, 6], 'f': [7, 8, 9], 'h': [5, 2, 1]}))\n",
      "    assert candidate(pd.DataFrame({'g': [1, 2, 3], 'r': [4, 5, 6], 'f': [7, 8, 9]}), 'h', [5, 2, 1]).equals(pd.DataFrame({'g': [1, 2, 3], 'r': [4, 5, 6], 'f': [7, 8, 9], 'h': [5, 2, 1]}))\n",
      "    assert candidate(pd.DataFrame({'g': [1, 2, 3], 'r': [4, 5, 6], 'f': [7, 6, 6]}), 'h', [5, 6, 6]).equals(pd.DataFrame({'g': [1, 2, 3], 'r': [4, 5, 6], 'f': [7, 6, 6], 'h': [5, 6, 6]}))\n",
      "    assert candidate(pd.DataFrame({'g': [1, 2, 3], 'r': [4, 5, 6], 'f': [7, 6, 6]}), 'h', [5, 8, 8]).equals(pd.DataFrame({'g': [1, 2, 3], 'r': [4, 5, 6], 'f': [7, 6, 6], 'h': [5, 8, 8]}))\n",
      "    assert candidate(pd.DataFrame({'g': [1, 2, 3], 'r': [6, 6, 6], 'f': [7, 6, 6]}), 'h', [5, 8, 8]).equals(pd.DataFrame({'g': [1, 2, 3], 'r': [6, 6, 6], 'f': [7, 6, 6], 'h': [5, 8, 8]}))\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/8 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def change_all_cols_type(kf):\n",
      "    # Change all columns type of KnowledgeFrame to numeric\n",
      "    # And return the new KnowledgeFrame\n",
      "    # The code is:\n",
      " \n",
      "==================================================\n",
      " ['    return kf.employ(mk.to_num)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra',\n",
      "    'dataset': 'test',\n",
      "    'type': 'apply'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame(data=[['5.4', 2.0, 3.2]])).equals(pd.DataFrame(data=[[5.4, 2.0, 3.2]]))\n",
      "    assert candidate(pd.DataFrame(data=[['5.8', 2.0, 3.2]])).equals(pd.DataFrame(data=[[5.8, 2.0, 3.2]]))\n",
      "    assert candidate(pd.DataFrame(data=[['5.8', 9.1, 3.2]])).equals(pd.DataFrame(data=[[5.8, 9.1, 3.2]]))\n",
      "    assert candidate(pd.DataFrame(data=[['5.8', 9.1, 3.9]])).equals(pd.DataFrame(data=[[5.8, 9.1, 3.9]]))\n",
      "    assert candidate(pd.DataFrame(data=[['5.8', '9.1', 3.9]])).equals(pd.DataFrame(data=[[5.8, 9.1, 3.9]]))\n",
      "    assert candidate(pd.DataFrame(data=[['5.8', '9.1', '3.9']])).equals(pd.DataFrame(data=[[5.8, 9.1, 3.9]]))\n",
      "    assert candidate(pd.DataFrame(data=[['5.8', '9.1', '6.7']])).equals(pd.DataFrame(data=[[5.8, 9.1, 6.7]]))\n",
      "    assert candidate(pd.DataFrame(data=[['5.8', '9.1', 6.5]])).equals(pd.DataFrame(data=[[5.8, 9.1, 6.5]]))\n",
      "    assert candidate(pd.DataFrame(data=[['5.8', '9.8', 6.5]])).equals(pd.DataFrame(data=[[5.8, 9.8, 6.5]]))\n",
      "    assert candidate(pd.DataFrame(data=[[5.8, '9.8', 6.5]])).equals(pd.DataFrame(data=[[5.8, 9.8, 6.5]]))\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/9 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "def sip_rows_col_nan(kf, col_name):\n",
      "    # How to sip rows of Monkey KnowledgeFrame whose value in a certain column is NaN\n",
      "    return  \n",
      "==================================================\n",
      " ['kf.sipna(subset=[col_name])'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra',\n",
      "    'dataset': 'test',\n",
      "    'type': 'drapna'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame([[1,2,3],[np.nan,2,3],[1,np.nan,3],[1,2,np.nan]], columns=['A','B','C']), 'B').equals(pd.DataFrame([[1,2,3],[np.nan,2,3],[1,np.nan,3],[1,2,np.nan]], columns=['A','B','C']).dropna(subset=['B']))\n",
      "    assert candidate(pd.DataFrame([[5,2,3],[np.nan,2,3],[1,np.nan,3],[1,2,np.nan]], columns=['A','B','C']), 'B').equals(pd.DataFrame([[5,2,3],[np.nan,2,3],[1,np.nan,3],[1,2,np.nan]], columns=['A','B','C']).dropna(subset=['B']))\n",
      "    assert candidate(pd.DataFrame([[5,2,1],[np.nan,2,3],[1,np.nan,3],[1,2,np.nan]], columns=['A','B','C']), 'B').equals(pd.DataFrame([[5,2,1],[np.nan,2,3],[1,np.nan,3],[1,2,np.nan]], columns=['A','B','C']).dropna(subset=['B']))\n",
      "    assert candidate(pd.DataFrame([[5,2,1],[np.nan,3,3],[1,np.nan,3],[1,2,np.nan]], columns=['A','B','C']), 'B').equals(pd.DataFrame([[5,2,1],[np.nan,3,3],[1,np.nan,3],[1,2,np.nan]], columns=['A','B','C']).dropna(subset=['B']))\n",
      "    assert candidate(pd.DataFrame([[5,2,1],[np.nan,3,3],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']), 'B').equals(pd.DataFrame([[5,2,1],[np.nan,3,3],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']).dropna(subset=['B']))\n",
      "    assert candidate(pd.DataFrame([[5,2,1],[3,3,3],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']), 'B').equals(pd.DataFrame([[5,2,1],[3,3,3],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']).dropna(subset=['B']))\n",
      "    assert candidate(pd.DataFrame([[5,2,1],[3,3,np.nan],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']), 'B').equals(pd.DataFrame([[5,2,1],[3,3,np.nan],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']).dropna(subset=['B']))\n",
      "    assert candidate(pd.DataFrame([[5,2,1],[3,3,np.nan],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']), 'C').equals(pd.DataFrame([[5,2,1],[3,3,np.nan],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']).dropna(subset=['C']))\n",
      "    assert candidate(pd.DataFrame([[5,2,1],[3,3,np.nan],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']), 'A').equals(pd.DataFrame([[5,2,1],[3,3,np.nan],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']).dropna(subset=['A']))\n",
      "    assert candidate(pd.DataFrame([[5,2,1],[3,3,np.nan],[np.nan,np.nan,3],[np.nan,2,np.nan]], columns=['A','B','C']), 'A').equals(pd.DataFrame([[5,2,1],[3,3,np.nan],[np.nan,np.nan,3],[np.nan,2,np.nan]], columns=['A','B','C']).dropna(subset=['A']))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/11 \n",
      "==================================================\n",
      " from typing import List\n",
      "import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "def adding_in_knowledgeframe(kf, list_to_add, column_name_list) -> mk.KnowledgeFrame:\n",
      "    \"\"\"    \n",
      "    Params:\n",
      "        kf: The knowledgeframe to add to.\n",
      "        list_to_add: The list to add.\n",
      "        column_name_list: The column names of the list to add.\n",
      "\n",
      "    Returns:\n",
      "        The knowledgeframe with the list added.\n",
      "    \"\"\"\n",
      " \n",
      "==================================================\n",
      " ['    list_to_add = mk.KnowledgeFrame(list_to_add, columns=column_name_list)\\n    kf = kf.adding(list_to_add)\\n    return kf'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'append'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'col1': [1, 2], 'col2': [4, 5]}), [5, 6] , ['col1']).equals(pd.DataFrame({'col1': [1, 2, 5, 6], 'col2': [4, 5, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n",
      "    assert candidate(pd.DataFrame({'col1': [5, 2], 'col2': [4, 5]}), [5, 6] , ['col1']).equals(pd.DataFrame({'col1': [5, 2, 5, 6], 'col2': [4, 5, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n",
      "    assert candidate(pd.DataFrame({'col1': [5, 2], 'col2': [1, 5]}), [5, 6] , ['col1']).equals(pd.DataFrame({'col1': [5, 2, 5, 6], 'col2': [1, 5, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n",
      "    assert candidate(pd.DataFrame({'col1': [5, 2], 'col2': [1, 7]}), [5, 6] , ['col1']).equals(pd.DataFrame({'col1': [5, 2, 5, 6], 'col2': [1, 7, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n",
      "    assert candidate(pd.DataFrame({'col1': [5, 2], 'col2': [1, 7]}), [5, 9] , ['col1']).equals(pd.DataFrame({'col1': [5, 2, 5, 9], 'col2': [1, 7, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n",
      "    assert candidate(pd.DataFrame({'col1': [5, 2], 'col2': [1, 7]}), [15, 9] , ['col1']).equals(pd.DataFrame({'col1': [5, 2, 15, 9], 'col2': [1, 7, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n",
      "    assert candidate(pd.DataFrame({'col1': [5, 2], 'col2': [11, 7]}), [15, 9] , ['col1']).equals(pd.DataFrame({'col1': [5, 2, 15, 9], 'col2': [11, 7, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n",
      "    assert candidate(pd.DataFrame({'col1': [5, 12], 'col2': [11, 7]}), [15, 9] , ['col1']).equals(pd.DataFrame({'col1': [5, 12, 15, 9], 'col2': [11, 7, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n",
      "    assert candidate(pd.DataFrame({'col1': [15, 12], 'col2': [11, 7]}), [15, 9] , ['col1']).equals(pd.DataFrame({'col1': [15, 12, 15, 9], 'col2': [11, 7, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n",
      "    assert candidate(pd.DataFrame({'col1': [15, 12], 'col2': [11, 7]}), [15, 19] , ['col1']).equals(pd.DataFrame({'col1': [15, 12, 15, 19], 'col2': [11, 7, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/12 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def extract_the_last_year(kf, column_name):\n",
      "    # I am trying to extract the last year (YY) of a fiscal date string in the format of YYYY-YY.\n",
      "    # e.g The last year of this '1999-00' would be 2000.\n",
      "    # I need a logic to include a case where if it is the end of the century then my employ method should add to the first two digits.\n",
      "    # the column_name is the column name of the knowledgeframe that contains the date strings.\n",
      "    # return the numerical Collections obj of the last year.\n",
      " \n",
      "==================================================\n",
      " [\"    final_result = mk.to_num(kf[column_name].str.split('-').str[0]) + 1\\n    return final_result\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'to_numeric'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame(data={'Season':['1996-97', '1997-98', '1998-99', '1999-00', '2000-01']}), 'Season').equals(pd.Series([1997, 1998, 1999, 2000, 2001]))\n",
      "    assert candidate(pd.DataFrame(data={'Season':['1996-07', '1997-08', '1998-99', '1999-00', '2000-01']}), 'Season').equals(pd.Series([1997, 1998, 1999, 2000, 2001]))\n",
      "    assert candidate(pd.DataFrame(data={'Season':['1996-07', '1997-08', '1998-99', '2018-00', '2000-01']}), 'Season').equals(pd.Series([1997, 1998, 1999, 2019, 2001]))\n",
      "    assert candidate(pd.DataFrame(data={'Season':['1996-07', '1997-08', '1998-99', '2018-00', '2081-01']}), 'Season').equals(pd.Series([1997, 1998, 1999, 2019, 2082]))\n",
      "    assert candidate(pd.DataFrame(data={'Season':['1996-07', '1997-08', '1958-99', '2018-00', '2081-01']}), 'Season').equals(pd.Series([1997, 1998, 1959, 2019, 2082]))\n",
      "    assert candidate(pd.DataFrame(data={'Season':['1996-07', '1967-08', '1958-99', '2018-00', '2081-01']}), 'Season').equals(pd.Series([1997, 1968, 1959, 2019, 2082]))\n",
      "    assert candidate(pd.DataFrame(data={'Season':['1946-07', '1967-08', '1958-99', '2018-00', '2081-01']}), 'Season').equals(pd.Series([1947, 1968, 1959, 2019, 2082]))\n",
      "    assert candidate(pd.DataFrame(data={'Season':['1946-07', '1967-08', '1958-99', '2008-00', '2081-01']}), 'Season').equals(pd.Series([1947, 1968, 1959, 2009, 2082]))\n",
      "    assert candidate(pd.DataFrame(data={'Season':['1946-07', '1967-08', '1958-99', '2088-00', '2081-01']}), 'Season').equals(pd.Series([1947, 1968, 1959, 2089, 2082]))\n",
      "    assert candidate(pd.DataFrame(data={'Season':['1946-07', '1967-08', '1958-99', '2088-00', '2051-01']}), 'Season').equals(pd.Series([1947, 1968, 1959, 2089, 2052]))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/13 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def get_last_n_rows(kf, n):\n",
      "    # How to get the last N rows of a monkey KnowledgeFrame?\n",
      " \n",
      "==================================================\n",
      " ['    return kf.last_tail(n)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'tail'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}), 2).equals(pd.DataFrame({'A': [2, 3], 'B': [300, 500]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'A': [11, 2, 3], 'B': [100, 300, 500]}), 2).equals(pd.DataFrame({'A': [2, 3], 'B': [300, 500]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'A': [11, 2, 3], 'B': [100, 400, 500]}), 2).equals(pd.DataFrame({'A': [2, 3], 'B': [400, 500]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'A': [11, 2, 3], 'B': [100, 400, 600]}), 2).equals(pd.DataFrame({'A': [2, 3], 'B': [400, 600]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'A': [11, 20, 3], 'B': [100, 400, 600]}), 2).equals(pd.DataFrame({'A': [20, 3], 'B': [400, 600]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'A': [11, 52, 13], 'B': [100, 400, 600]}), 2).equals(pd.DataFrame({'A': [52, 13], 'B': [400, 600]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'A': [84, 52, 13], 'B': [100, 400, 600]}), 2).equals(pd.DataFrame({'A': [52, 13], 'B': [400, 600]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'A': [84, 52, 82], 'B': [100, 400, 600]}), 2).equals(pd.DataFrame({'A': [52, 82], 'B': [400, 600]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'A': [84, 52, 82], 'B': [100, 512, 600]}), 2).equals(pd.DataFrame({'A': [52, 82], 'B': [512, 600]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'A': [84, 52, 82], 'B': [100, 512, 777]}), 2).equals(pd.DataFrame({'A': [52, 82], 'B': [512, 777]}, index=[1, 2]))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/14 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def get_values_at_nth_rows(kf, n, column_name):\n",
      "    \"\"\"\n",
      "    how do I get the value at an nth row of a given column name in Monkey?\n",
      "    return the value\n",
      "    \"\"\"\n",
      " \n",
      "==================================================\n",
      " ['    return kf[column_name].iloc[n]'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'tail'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}), 0, 'A') == 1\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}), 1, 'A') == 2\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}), 2, 'A') == 3\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}), 2, 'B') == 500\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}), 1, 'B') == 300\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}), 0, 'B') == 100\n",
      "    assert candidate(pd.DataFrame({'A': [5, 2, 3], 'B': [100, 300, 500]}), 0, 'B') == 100\n",
      "    assert candidate(pd.DataFrame({'A': [5, 2, 1], 'B': [100, 300, 500]}), 0, 'B') == 100\n",
      "    assert candidate(pd.DataFrame({'A': [5, 2, 1], 'B': [500, 300, 500]}), 0, 'B') == 500\n",
      "    assert candidate(pd.DataFrame({'A': [5, 2, 1], 'B': [500, 300, 100]}), 0, 'B') == 500\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/15 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "def creating_kf_with_same_as_other(kf_original):\n",
      "    # creating a new knowledgeframe of all same with kf_original one, but no any rows\n",
      "    # return the new knowledgeframe\n",
      "     \n",
      "==================================================\n",
      " ['    kf_clone = kf_original.iloc[:0,:].clone()\\n    return kf_clone'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'tail'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]})).equals(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}).iloc[:0,:].copy())\n",
      "    assert candidate(pd.DataFrame({'A': [1, 0, 3], 'B': [100, 300, 500]})).equals(pd.DataFrame({'A': [1, 0, 3], 'B': [100, 300, 500]}).iloc[:0,:].copy())\n",
      "    assert candidate(pd.DataFrame({'A': [5, 0, 3], 'B': [100, 300, 500]})).equals(pd.DataFrame({'A': [5, 0, 3], 'B': [100, 300, 500]}).iloc[:0,:].copy())\n",
      "    assert candidate(pd.DataFrame({'A': [5, 2, 3], 'B': [100, 300, 500]})).equals(pd.DataFrame({'A': [5, 2, 3], 'B': [100, 300, 500]}).iloc[:0,:].copy())\n",
      "    assert candidate(pd.DataFrame({'A': [5, 2, 1], 'B': [100, 300, 500]})).equals(pd.DataFrame({'A': [5, 2, 1], 'B': [100, 300, 500]}).iloc[:0,:].copy())\n",
      "    assert candidate(pd.DataFrame({'A': [5, 2, 1], 'B': [500, 300, 500]})).equals(pd.DataFrame({'A': [5, 2, 1], 'B': [500, 300, 500]}).iloc[:0,:].copy())\n",
      "    assert candidate(pd.DataFrame({'A': [5, 2, 1], 'B': [500, 200, 500]})).equals(pd.DataFrame({'A': [5, 2, 1], 'B': [500, 200, 500]}).iloc[:0,:].copy())\n",
      "    assert candidate(pd.DataFrame({'A': [5, 2, 1], 'B': [500, 200, 100]})).equals(pd.DataFrame({'A': [5, 2, 1], 'B': [500, 200, 100]}).iloc[:0,:].copy())\n",
      "    assert candidate(pd.DataFrame({'A': [5, 20, 1], 'B': [500, 200, 100]})).equals(pd.DataFrame({'A': [5, 20, 1], 'B': [500, 200, 100]}).iloc[:0,:].copy())\n",
      "    assert candidate(pd.DataFrame({'A': [50, 20, 1], 'B': [500, 200, 100]})).equals(pd.DataFrame({'A': [50, 20, 1], 'B': [500, 200, 100]}).iloc[:0,:].copy())\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/20 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "kf = mk.KnowledgeFrame({\"Code\": [2, 2, 4, 4], \"Country\": [\"Afghanistan\", \"Afghanistan\", \"Angola\", \"Angola\"], \"Item_Code\": [15, 25, 15, 25], \"Y1961\": [10, 10, 30, 30], \"Y1962\": [20, 20, 40, 40], \"Y1963\": [30, 30, 50, 50]})\n",
      "# What is the best way to do a grouper on a Monkey knowledgeframe, but exclude some columns from that grouper?\n",
      "# I want to grouper the column `Country` and `Item_Code` and only compute the sum of the rows falling under the columns ['Y1961', 'Y1962' and 'Y1963']. \n",
      "new_kf = \n",
      "==================================================\n",
      " [\" kf.grouper(['Country', 'Item_Code'])[['Y1961', 'Y1962', 'Y1963']].total_sum()\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra',\n",
      "    'dataset': 'test',\n",
      "    'type': 'groupby_sum'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert new_df.equals(pd.DataFrame({\"Code\": [2, 2, 4, 4], \"Country\": [\"Afghanistan\", \"Afghanistan\", \"Angola\", \"Angola\"], \"Item_Code\": [15, 25, 15, 25], \"Y1961\": [10, 10, 30, 30], \"Y1962\": [20, 20, 40, 40], \"Y1963\": [30, 30, 50, 50]}).groupby(['Country', 'Item_Code'])[['Y1961', 'Y1962', 'Y1963']].sum())\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/10 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "# creating a Collections from a list [56, 24, 421, 90]\n",
      "my_collections =  \n",
      "==================================================\n",
      " ['mk.Collections([56, 24, 421, 90])'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'Series'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert my_series.equals(pd.Series([56, 24, 421, 90]))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/16 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "data = {'col_0': ['a', 'a', 'a', 'a', 'b','b','b'], 'col_1': [-2, -7, 6, 8, -5, 2, 6]}\n",
      "kf = mk.KnowledgeFrame(data)\n",
      "# What I want is to clip the values of `col_1` between -2 to 2 if `col_0` is `a`.\n",
      "# # Using `clip` function in monkey.\n",
      "kf.loc[kf['col_0']=='a','col_1'] =  \n",
      "==================================================\n",
      " [\" kf.loc[kf['col_0']=='a','col_1'].clip(-2,2)\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'clip'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert df.equals(pd.DataFrame({'col_0': ['a', 'a', 'a', 'a', 'b','b','b'], 'col_1': [-2, -2, 2, 2, -5, 2, 6]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/17 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "kf = mk.KnowledgeFrame({'a': [4, 1, 7, 3], 'b': [5, 2, 9, 6], 'c': [6, 3, 2, 8]})\n",
      "# I would like to create new knowledgeframe out of the old one in a way that there will only be values that exceed the average value of the column. \n",
      "# We can compare values and then add NaNs by indexing or `where`\n",
      "# We want remove NaNs also in first rows add custom function with `sipna`\n",
      "kf =  \n",
      "==================================================\n",
      " ['kf[kf>kf.average()].employ(lambda x: mk.Collections(x.sipna().values))'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'mean_apply'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert df.equals(pd.DataFrame({'a': [4.0, 7.0], 'b': [9.0, 6.0], 'c': [6.0, 8.0]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/18 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "source_collections = mk.Collections([32, 434, 542, 'BC2'])\n",
      "target_collections = mk.Collections(['B1', 'B3', 'B4', 123, 43, 54])\n",
      "\n",
      "# Appending the source collections to the target collections, with ignoring the index or resetting index\n",
      "unionerd_collections =  \n",
      "==================================================\n",
      " ['target_collections.adding(source_collections, ignore_index=True)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'append'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert merged_series.equals(pd.Series(['B1', 'B3', 'B4', 123, 43, 54, 32, 434, 542, 'BC2']))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/19 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "kf = mk.KnowledgeFrame({'group1': [0, 0, 1, 1], 'group2': [2, 2, 3, 4], 'base': [0, 1, 2, 3], 'x1': [3, 4, 5, 6], 'x2': [np.nan, 6, np.nan, 8]})\n",
      "\n",
      "# Selecting rows where column x2 is NaN \n",
      "nan_kf = \n",
      "==================================================\n",
      " [\" kf[kf['x2'].ifnull()]\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra',\n",
      "    'dataset': 'test',\n",
      "    'type': 'isnull_isnan'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert nan_df.equals(pd.DataFrame({'group1': [0, 1], 'group2': [2, 3], 'base': [0, 2], 'x1': [3, 5], 'x2': [np.nan, np.nan]}, index=[0, 2]))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/21 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "a = [['a', '1.2'], ['b', '70'], ['x', '5']]\n",
      "# I want to convert a table, represented as a list of lists, into a monkey KnowledgeFrame.\n",
      "# The columns are ['one', 'two']\n",
      "# What is the best way to convert the columns to the appropriate types, in this case the 'two' column into floats?\n",
      "kf = \n",
      "==================================================\n",
      " [\" mk.KnowledgeFrame(a, columns=['one', 'two'])\\nkf['two'] = kf['two'].totype(float)\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'columns_astype'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert df.equals(pd.DataFrame({'one': ['a', 'b', 'x'], 'two': [1.2, 70.0, 5.0]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/22 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "my_kf = mk.KnowledgeFrame({'col1': [1,2,3], 'col2': [1.0,2.0,3.0]})\n",
      "# I need to change the dtype of multiple columns but the knowledgeframe has different kind of dtypes. \n",
      "# Some columns dtypes are float64 whereas some columns are int64\n",
      "# I need to change all float64 to float32.\n",
      "cols = \n",
      "==================================================\n",
      " [\" my_kf.choose_dtypes(include=['float64']).columns\\nmy_kf[cols] = my_kf[cols].totype(np.float32)\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'astype'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert my_df.equals(pd.DataFrame({'col1': [1,2,3], 'col2': [np.float32(1.0),np.float32(2.0),np.float32(3.0)]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/23 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "kf = mk.KnowledgeFrame({'col1': [1,2,3], 'col2': ['Jimmy','Tom','Jimmy']})\n",
      "# I have a knowledgeframe that has two columns, the second column is one of only a few values. \n",
      "# I want to return a knowledgeframe where only the rows where that col2 had a specific value 'Jimmy' are included.\n",
      "new_kf = \n",
      "==================================================\n",
      " [\" kf[kf.iloc[:, 1] == 'Jimmy']\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'iloc'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert new_df.equals(pd.DataFrame({'col1': [1, 3], 'col2': ['Jimmy', 'Jimmy']}, index=[0, 2]))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/24 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "kf = mk.KnowledgeFrame({'MSRA': [10, 11, 12], 'THU': [100, 110, 120]})\n",
      "kf = kf.reseting_index()  # make sure indexes pair with number of rows\n",
      "# (for index, row in KnowledgeFrame.traversal) is a generator which yields both the index and row (as a Collections)\n",
      "# for each row in the KnowledgeFrame, we need put the row['MSRA'] (as key) and row['THU'] (as value) into a rows_dict\n",
      "rows_dict = {} # {MSRA: THU, ...}\n",
      " \n",
      "==================================================\n",
      " [\"for index, row in kf.traversal():\\n    rows_dict[row['MSRA']] = row['THU']\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'iterrows'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert rows_dict == {10: 100, 11: 110, 12: 120}\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/25 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "kf = mk.KnowledgeFrame({'A': [1000, 765, 800], 'B': [10, 5, 7]})\n",
      "# I have a knowledgeframe in monkey where each column has different value range.\n",
      "# Any idea how I can normalize the columns of this knowledgeframe where each value is between 0 and 1?\n",
      "normalized_kf = \n",
      "==================================================\n",
      " [' kf.employ(lambda x: (x - x.get_min()) / (x.get_max() - x.get_min()))'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'min_max'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert normalized_df.equals(df.apply(lambda x: (x - x.min()) / (x.max() - x.min())))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/26 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "# I want to create a knowledgeframe with one of the column as a list or array.\n",
      "kf = mk.KnowledgeFrame({'Name':['Juda','Pri']})\n",
      "emails = {'a@a.com','b@b.com'}\n",
      "kf['Email'] = ''\n",
      "# After you assign a list like or array like value to the columns, the column should be considered as type object\n",
      "# Now I want to assign the emails to first row and the 'Email' column\n",
      " \n",
      "==================================================\n",
      " ['kf.Email = kf.Email.totype(object)\\nkf.loc[0].Email = emails'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'astype_loc'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert df.equals(pd.DataFrame({'Name':['Juda','Pri'],'Email':[{'a@a.com','b@b.com'}, '']}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/28 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def is_kf_exist(kf):\n",
      "    # In my code, I have several variables which can either contain a monkey KnowledgeFrame or nothing at all.\n",
      "    # Let's say I want to test and see if a certain KnowledgeFrame has been created yet or not.\n",
      " \n",
      "==================================================\n",
      " ['    if kf is None:\\n        return False\\n    else:\\n        return True'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'df_none'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('abc')})) == True\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[2,300,500], 'C':list('abc')})) == True\n",
      "    assert candidate(pd.DataFrame({'A':[13,2,3], 'B':[2,300,500], 'C':list('abc')})) == True\n",
      "    assert candidate(pd.DataFrame({'D':[1,2,3], 'B':[2,300,500], 'C':list('dct')})) == True\n",
      "    assert candidate(pd.DataFrame({'A':[1,25,34], 'B':[2,300,500], 'C':list('abc')})) == True\n",
      "    assert candidate(pd.DataFrame({'A':[1,23,3], 'S':[2,300,500], 'C':list('abc')})) == True\n",
      "    assert candidate(None) == False\n",
      "    assert candidate(pd.DataFrame({'A':[1,23,3], 'S':[2,3,500], 'C':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,23,3], 'S':[2,3,5], 'C':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,23,3], 'S':[5,2,1], 'C':list('abc')}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/29 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "kf = mk.KnowledgeFrame({'line_date': [1, 2, 3], 'line_num': [1, 0, 6], 'line_text': list('abc')})\n",
      "# I need to remain the rows where line_num is not equal to 0. What's the most efficient way to do it?\n",
      "# it should be as simple as:\n",
      "n_kf = \n",
      "==================================================\n",
      " [' kf[kf.line_num != 0]'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'df_none'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert df.equals(pd.DataFrame({\"line_date\": [1, 3], \"line_num\": [1, 6], \"line_text\": list(\"ac\")}, index=[0, 2]))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/30 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "web_stats = {'Day': [1, 2, 3, 4, 2, 6],\n",
      "             'Visitors': [43, 43, 34, 23, 43, 23],\n",
      "             'Bounce_Rate': [3, 2, 4, 3, 5, 5]}\n",
      "kf = mk.KnowledgeFrame(web_stats)\n",
      "# I would like to sip all data in a monkey knowledgeframe\n",
      "# Using kf.index to sip all rows\n",
      " \n",
      "==================================================\n",
      " ['kf.sip(kf.index, inplace=True)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'drop_index_inplace'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    tmp = pd.DataFrame({'Day': [1, 2, 3], 'Visitors': [4, 5, 6], 'Bounce_Rate': [7, 8, 9]})\n",
      "    tmp.drop(tmp.index, inplace=True)\n",
      "    assert df.equals(tmp)\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/31 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "kf = mk.KnowledgeFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
      "# I would like to add a new column C that is the sum value of A and B cell.\n",
      " \n",
      "==================================================\n",
      " [\"kf['C'] = kf.A + kf.B\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra',\n",
      "    'dataset': 'test',\n",
      "    'add': 'drop_index_inplace'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert df.equals(pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [5, 7, 9]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/32 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "kf = mk.KnowledgeFrame({'A': [1, 4, 7, np.nan], 'B': [np.nan, 2, 5, np.nan], 'C': [np.nan, np.nan, 3, 6]})\n",
      "# Move next value to first empty row monkey\n",
      "# how do i move each value from a column to the first empty \"row/cell\" in monkey?\n",
      "# use sorted to align non NULL data at the top, use sipna to sip all rows with all NaN\n",
      "new_kf = \n",
      "==================================================\n",
      " [\" kf.employ(lambda x: sorted(x, key=mk.ifnull)).sipna(how = 'all')\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'apply_dropna_sorted'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert new_df.equals(pd.DataFrame({'A': [1.0, 4.0, 7.0], 'B': [2.0, 5.0, np.nan], 'C': [3.0, 6.0, np.nan]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/33 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def make_knowledgeframe_column_headers_lowercase(data):\n",
      "    # I want to make all column headers in my monkey data frame lower case\n",
      " \n",
      "==================================================\n",
      " ['    data.columns = mapping(str.lower, data.columns)\\n    return data'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'map_lower'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A':range(3), 'B':range(3,0,-1), 'C':list('abc')})).equals(pd.DataFrame({'a':range(3), 'b':range(3,0,-1), 'c':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'M':range(3), 'S':range(3,0,-1), 'R':list('dki')})).equals(pd.DataFrame({'m':range(3), 's':range(3,0,-1), 'r':list('dki')}))\n",
      "    assert candidate(pd.DataFrame({'D':range(3), 'B':range(3,0,-1), 'C':list('abc')})).equals(pd.DataFrame({'d':range(3), 'b':range(3,0,-1), 'c':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'D':range(3), 'K':range(3,0,-1), 'C':list('abc')})).equals(pd.DataFrame({'d':range(3), 'k':range(3,0,-1), 'c':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'D':range(3), 'K':range(3,0,-1), 'I':list('abc')})).equals(pd.DataFrame({'d':range(3), 'k':range(3,0,-1), 'i':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'D':range(3), 'K':range(3,0,-1), 'I':list('ccc')})).equals(pd.DataFrame({'d':range(3), 'k':range(3,0,-1), 'i':list('ccc')}))\n",
      "    assert candidate(pd.DataFrame({'D':range(3), 'K':range(3,0,-1), 'I':list('msr')})).equals(pd.DataFrame({'d':range(3), 'k':range(3,0,-1), 'i':list('msr')}))\n",
      "    assert candidate(pd.DataFrame({'LO':range(3), 'K':range(3,0,-1), 'I':list('msr')})).equals(pd.DataFrame({'lo':range(3), 'k':range(3,0,-1), 'i':list('msr')}))\n",
      "    assert candidate(pd.DataFrame({'LO':range(3), 'V':range(3,0,-1), 'I':list('msr')})).equals(pd.DataFrame({'lo':range(3), 'v':range(3,0,-1), 'i':list('msr')}))\n",
      "    assert candidate(pd.DataFrame({'LO':range(3), 'V':range(3,0,-1), 'E':list('msr')})).equals(pd.DataFrame({'lo':range(3), 'v':range(3,0,-1), 'e':list('msr')}))\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/35 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "kf = mk.KnowledgeFrame({'a': [3.0, 2.0, 4.0, 1.0],'b': [1.0, 4.0 , 2.0, 3.0]})\n",
      "# How to get the first largest value in column aï¼Ÿ\n",
      "# Using nbiggest and iloc to implemente this\n",
      "first_value =  \n",
      "==================================================\n",
      " ['kf.a.nbiggest(1).iloc[-1]'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'nlargest_iloc'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert first_value == 4.0\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/36 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "kf = mk.KnowledgeFrame(np.random.randint(0,10,size=100).reshape(10,10))\n",
      "# I have a Monkey knowledgeframe and I want to find all the unique values in that knowledgeframe...irrespective of row/columns. \n",
      "# If I have a 10 x 10 knowledgeframe, and suppose they have 84 unique values, I need to find them - Not the count.\n",
      "# Using xx.values.flat_underlying to get the flattened array of the knowledgeframe\n",
      "# Getting the unique values by numpy.unique\n",
      "unique_ndarray = \n",
      "==================================================\n",
      " [' np.unique(kf.values.flat_underlying())'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'nlargest_iloc'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert np.array_equal(unique_ndarray, np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/37 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "kf = mk.KnowledgeFrame({\n",
      "    'id': [220, 220, 220, 826, 826, 826, 901, 901, 901],\n",
      "    'product': [6647, 6647, 6647, 3380, 3380, 3380, 4555, 4555, 4555],\n",
      "    'date': ['2014-09-01', '2014-09-03', '2014-10-16', '2014-11-11', '2014-12-09', '2015-05-19', '2014-09-01', '2014-10-05', '2014-11-01']\n",
      "})\n",
      "\n",
      "# How to group values of monkey knowledgeframe and select the latest by date from each group?\n",
      "# Sorting values by `date` (ascending is True), and then grouping by `id`\n",
      "final_item_kf = \n",
      "==================================================\n",
      " [\" kf.sort_the_values('date', ascending=True)\\nfinal_item_kf = final_item_kf.grouper('id').final_item()\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'sort_values_groupby_last'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert last_df.equals(df.sort_values('date', ascending=True).groupby('id').last())\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/38 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def sip2rows_zero(kf):\n",
      "    # i want to sip 2 rows in the knowledgeframe if zero comes in the column\n",
      "    # if 0 comes on odd index sip previous row as well as current row using monkey\n",
      "    # Assuming your knowledgeframe is indexed starting from 0\n",
      "    # Rows with column2 = 0 and on odd index\n",
      "    idx = kf[(kf['column2'] == 0) & (kf.index % 2 == 1)].index\n",
      "    # The rows above them\n",
      "    idx = idx.adding(idx-1)\n",
      "    # A new knowledgeframe with those rows removed\n",
      "     \n",
      "==================================================\n",
      " ['result = kf.sip(idx)\\n    return result'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'append_odd_drop'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'column1': ['a', 'b', 'c', 'd', 'e', 'f'],'column2': [1, 0, 2, 3, 7, 10]})).equals( pd.DataFrame({'column1': ['c', 'd', 'e', 'f'],'column2': [2, 3, 7, 10]}, index=[2, 3, 4, 5]))\n",
      "    assert candidate(pd.DataFrame({'column1': ['m', 's', 'r', 'a', 'z', 'a'],'column2': [8, 7, 2, 5, 6, 1]})).equals(pd.DataFrame({'column1': ['m', 's', 'r', 'a', 'z', 'a'],'column2': [8, 7, 2, 5, 6, 1]}))\n",
      "    assert candidate(pd.DataFrame({'column1': ['a', 'b', 'c', 'd', 'e', 'f'],'column2': [2, 0, 2, 3, 7, 10]})).equals( pd.DataFrame({'column1': ['c', 'd', 'e', 'f'],'column2': [2, 3, 7, 10]}, index=[2, 3, 4, 5]))\n",
      "    assert candidate({'column1': ['a', 'b', 'c', 'd', 'e', 'f'],'column2': [2, 0, 2, 3, 7, 11]})).equals( pd.DataFrame({'column1': ['c', 'd', 'e', 'f'],'column2': [2, 3, 7, 11]}, index=[2, 3, 4, 5]))\n",
      "    assert candidate({'column1': ['a', 'b', 'c', 'd', 'e', 'f'],'column2': [2, 0, 2, 3, 8, 11]})).equals( pd.DataFrame({'column1': ['c', 'd', 'e', 'f'],'column2': [2, 3, 8, 11]}, index=[2, 3, 4, 5]))\n",
      "    assert candidate({'column1': ['a', 'b', 'c', 'd', 'e', 'f'],'column2': [2, 0, 2, 4, 8, 11]})).equals( pd.DataFrame({'column1': ['c', 'd', 'e', 'f'],'column2': [2, 4, 8, 11]}, index=[2, 3, 4, 5]))\n",
      "    assert candidate({'column1': ['a', 'b', 'c', 'd', 'e', 'f'],'column2': [2, 0, 3, 4, 8, 11]})).equals( pd.DataFrame({'column1': ['c', 'd', 'e', 'f'],'column2': [3, 4, 8, 11]}, index=[2, 3, 4, 5]))\n",
      "    assert candidate({'column1': ['a', 'b', 'c', 'd', 'e', 'f'],'column2': [2, 0, 3, 4, 9, 11]})).equals( pd.DataFrame({'column1': ['c', 'd', 'e', 'f'],'column2': [3, 4, 9, 11]}, index=[2, 3, 4, 5]))\n",
      "    assert candidate({'column1': ['a', 'b', 'c', 'd', 'e', 'f'],'column2': [2, 0, 3, 4, 9, 18]})).equals( pd.DataFrame({'column1': ['c', 'd', 'e', 'f'],'column2': [3, 4, 9, 18]}, index=[2, 3, 4, 5]))\n",
      "    assert candidate({'column1': ['a', 'b', 'c', 'd', 'e', 'f'],'column2': [2, 0, 3, 4, 12, 18]})).equals( pd.DataFrame({'column1': ['c', 'd', 'e', 'f'],'column2': [3, 4, 12, 18]}, index=[2, 3, 4, 5]))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/39 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "def shift_column_up_by_one(kf):\n",
      "    # Shift column in monkey knowledgeframe up by one?\n",
      "    # In detail, in 'gdp' column, shift up by one and return knowledgeframe with the changed gdp column.\n",
      "     \n",
      "==================================================\n",
      " [\"kf['gdp'] = kf['gdp'].shifting(1)\\n    return kf\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra',\n",
      "    'dataset': 'test',\n",
      "    'type': 'shift'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'y': [1,2],'gdp': [2.0,4.0],'cap': [8, 7]})).equals(pd.DataFrame({'y': [1,2],'gdp': [np.nan,2.0],'cap': [8, 7]}))\n",
      "    assert candidate(pd.DataFrame({'y': [1,2],'gdp': [2.0,4.0],'cap': [9, 7]})).equals(pd.DataFrame({'y': [1,2],'gdp': [np.nan,2.0],'cap': [9, 7]}))\n",
      "    assert candidate(pd.DataFrame({'y': [1,2],'gdp': [2.0,4.0],'cap': [9, 3]})).equals(pd.DataFrame({'y': [1,2],'gdp': [np.nan,2.0],'cap': [9, 3]}))\n",
      "    assert candidate(pd.DataFrame({'y': [1,2],'gdp': [3.0,4.0],'cap': [9, 3]})).equals(pd.DataFrame({'y': [1,2],'gdp': [np.nan,3.0],'cap': [9, 3]}))\n",
      "    assert candidate(pd.DataFrame({'y': [5,2],'gdp': [3.0,4.0],'cap': [9, 3]})).equals(pd.DataFrame({'y': [5,2],'gdp': [np.nan,3.0],'cap': [9, 3]}))\n",
      "    assert candidate(pd.DataFrame({'y': [5,1],'gdp': [3.0,4.0],'cap': [9, 3]})).equals(pd.DataFrame({'y': [5,1],'gdp': [np.nan,3.0],'cap': [9, 3]}))\n",
      "    assert candidate(pd.DataFrame({'y': [5,1],'gdp': [3.0,8.0],'cap': [9, 3]})).equals(pd.DataFrame({'y': [5,1],'gdp': [np.nan,3.0],'cap': [9, 3]}))\n",
      "    assert candidate(pd.DataFrame({'y': [5,1],'gdp': [3.0,8.0],'cap': [19, 3]})).equals(pd.DataFrame({'y': [5,1],'gdp': [np.nan,3.0],'cap': [19, 3]}))\n",
      "    assert candidate(pd.DataFrame({'y': [5,1],'gdp': [3.0,8.0],'cap': [19, 13]})).equals(pd.DataFrame({'y': [5,1],'gdp': [np.nan,3.0],'cap': [19, 13]}))\n",
      "    assert candidate(pd.DataFrame({'y': [5,1],'gdp': [13.0,8.0],'cap': [19, 13]})).equals(pd.DataFrame({'y': [5,1],'gdp': [np.nan,13.0],'cap': [19, 13]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/40 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "kf = mk.KnowledgeFrame([[1, 2.2, 'three']], columns=['A', 'B', 'C'])\n",
      "# I was wondering if there is an elegant and shorthand way in Monkey KnowledgeFrames to select columns by data type (dtype). \n",
      "# i.e. Select only float64 columns from a KnowledgeFrame\n",
      "new_kf =  \n",
      "==================================================\n",
      " [\"kf.choose_dtypes(include=['float64'])\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'select_dtypes'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert new_df.equals(df.select_dtypes(include=['float64']))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/41 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "def unioner_kf(kf1, kf2):\n",
      "    # How to unioner two knowledgeframes with different column names but same number of rows?\n",
      "    # I have two different data frames in monkey. Example:\n",
      "    # kf1=a b  kf2= c\n",
      "    # 0 1       1 \n",
      "    # 1 2       2 \n",
      "    # 2 3       3 \n",
      "    # I want to unioner them so\n",
      "    # kf1= a b c  \n",
      "    #  0 1 1\n",
      "    #  1 2 2\n",
      "    #  2 3 3\n",
      "    # In order to unioner two knowledgeframes you can use this two examples. Both returns the same goal\n",
      "    # Using unioner plus additional arguments instructing it to use the indexes\n",
      "    # Specially, we can set left_index and right_index to True\n",
      "     \n",
      "==================================================\n",
      " ['return mk.unioner(kf1, kf2, left_index=True, right_index=True)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'merge'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'a':[0, 1, 2],'b':[1,2,3]}), pd.DataFrame({'c':[1, 2, 3]})).equals(pd.DataFrame({'a':[0, 1, 2],'b':[1,2,3], 'c':[1, 2, 3]}))\n",
      "    assert candidate(pd.DataFrame({'m':[7,7,9],'s':[5,3,6]}), pd.DataFrame({'r':[9,9,2]})).equals(pd.DataFrame({'m':[7,7,9],'s':[5,3,6],'r':[9,9,2]}))\n",
      "    assert candidate(pd.DataFrame({'a':[0, 2, 2],'b':[1,2,3]}), pd.DataFrame({'c':[1, 2, 3]})).equals(pd.DataFrame({'a':[0, 2, 2],'b':[1,2,3], 'c':[1, 2, 3]}))\n",
      "    assert candidate(pd.DataFrame({'a':[0, 2, 4],'b':[1,2,3]}), pd.DataFrame({'c':[1, 2, 3]})).equals(pd.DataFrame({'a':[0, 2, 4],'b':[1,2,3], 'c':[1, 2, 3]}))\n",
      "    assert candidate(pd.DataFrame({'a':[0, 2, 4],'b':[4,2,3]}), pd.DataFrame({'c':[1, 2, 3]})).equals(pd.DataFrame({'a':[0, 2, 4],'b':[4,2,3], 'c':[1, 2, 3]}))\n",
      "    assert candidate(pd.DataFrame({'a':[0, 2, 4],'b':[4,2,3]}), pd.DataFrame({'c':[14, 2, 3]})).equals(pd.DataFrame({'a':[0, 2, 4],'b':[4,2,3], 'c':[14, 2, 3]}))\n",
      "    assert candidate(pd.DataFrame({'a':[0, 2, 4],'b':[4,2,3]}), pd.DataFrame({'c':[14, 12, 3]})).equals(pd.DataFrame({'a':[0, 2, 4],'b':[4,2,3], 'c':[14, 12, 3]}))\n",
      "    assert candidate(pd.DataFrame({'a':[0, 2, 4],'b':[4,2,3]}), pd.DataFrame({'c':[14, 12, 13]})).equals(pd.DataFrame({'a':[0, 2, 4],'b':[4,2,3], 'c':[14, 12, 13]}))\n",
      "    assert candidate(pd.DataFrame({'a':[0, 2, 4],'b':[14,2,3]}), pd.DataFrame({'c':[14, 12, 13]})).equals(pd.DataFrame({'a':[0, 2, 4],'b':[14,2,3], 'c':[14, 12, 13]}))\n",
      "    assert candidate(pd.DataFrame({'a':[0, 2, 4],'b':[14,2,13]}), pd.DataFrame({'c':[14, 12, 13]})).equals(pd.DataFrame({'a':[0, 2, 4],'b':[14,2,13], 'c':[14, 12, 13]}))\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/42 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "kf = mk.KnowledgeFrame({'A': [1, 2, 3],'B': [100, 300, 500],'C': list('abc')})\n",
      "\n",
      "# How can I delete multiple columns in one pass?\n",
      "# In detail, I would like to delete columns A and C, but I don't know how to do it in one pass.\n",
      "new_kf = \n",
      "==================================================\n",
      " [\" kf.sip(['A', 'C'], axis=1)\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'drop'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert new_df.equals(pd.DataFrame({'B': [100, 300, 500]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/43 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def get_value_counts(kf):\n",
      "    # I want to get the counts of distinctive values of the knowledgeframe. count_values implements this however I want to use its output somewhere else. \n",
      "    # How can I convert .count_values output to a monkey knowledgeframe.\n",
      "    # Use renaming_axis('distinctive_values') for name ('counts') of column from index and reseting_index\n",
      "    # return the final knowledgeframe\n",
      " \n",
      "==================================================\n",
      " [\"    return kf.counts_value_num().renaming_axis('distinctive_values').reseting_index(name='counts')\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'value_counts_reset_index'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'a':[1, 1, 2, 2, 2]})).equals(pd.DataFrame({'unique_values':[2, 1], 'counts':[3, 2]}))\n",
      "    assert candidate(pd.DataFrame({'iscas':[7, 5, 6, 3, 8]})).equals(pd.DataFrame({'unique_values':[3, 5, 6, 7, 8], 'counts':[1, 1, 1, 1, 1]}))\n",
      "    assert candidate(pd.DataFrame({'a':[1, 2, 2, 2, 2]})).equals(pd.DataFrame({'unique_values':[2, 1], 'counts':[4, 1]}))\n",
      "    assert candidate(pd.DataFrame({'a':[2, 2, 2, 2, 2]})).equals(pd.DataFrame({'unique_values':[2], 'counts':[5]}))\n",
      "    assert candidate(pd.DataFrame({'a':[2, 2, 2, 5, 2]})).equals(pd.DataFrame({'unique_values':[2, 5], 'counts':[4, 1]}))\n",
      "    assert candidate(pd.DataFrame({'a':[2, 2, 2, 5, 3]})).equals(pd.DataFrame({'unique_values':[2, 3, 5], 'counts':[3, 1, 1]}))\n",
      "    assert candidate(pd.DataFrame({'a':[2, 2, 2, 5, 1]})).equals(pd.DataFrame({'unique_values':[2, 1, 5], 'counts':[3, 1, 1]}))\n",
      "    assert candidate(pd.DataFrame({'a':[2, 1, 2, 5, 1]})).equals(pd.DataFrame({'unique_values':[1, 2, 5], 'counts':[2, 2, 1]}))\n",
      "    assert candidate(pd.DataFrame({'a':[1, 1, 2, 5, 1]})).equals(pd.DataFrame({'unique_values':[1, 2, 5], 'counts':[3, 1, 1]}))\n",
      "    assert candidate(pd.DataFrame({'a':[1, 1, 2, 4, 1]})).equals(pd.DataFrame({'unique_values':[1, 2, 4], 'counts':[3, 1, 1]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/44 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "data = mk.KnowledgeFrame({'A':range(3), 'B':range(3,0,-1), 'C':list('abc')})\n",
      "# How do I change the column labels of a monkey KnowledgeFrame from ['A', 'B', 'C'] to ['a', 'b', 'c']?\n",
      "data.columns =  \n",
      "==================================================\n",
      " [\"['a', 'b', 'c']\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': '_'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert data.equals(pd.DataFrame({'a':range(3), 'b':range(3,0,-1), 'c':list('abc')}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/45 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def make_kf_all_cols_lower(data):\n",
      "    # I want to make all column headers in my monkey data frame lower case\n",
      "    # Return the changed knowledgeframe\n",
      "     \n",
      "==================================================\n",
      " ['data.columns = mapping(str.lower, data.columns)\\n    return data', 'data.columns = [x.lower() for x in data.columns]\\n    return data'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'lower'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A':range(3), 'B':range(3,0,-1), 'C':list('abc')})).equals(pd.DataFrame({'a':range(3), 'b':range(3,0,-1), 'c':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'A':range(3), 'D':range(3,0,-1), 'C':list('abc')})).equals(pd.DataFrame({'a':range(3), 'd':range(3,0,-1), 'c':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'T':range(3), 'D':range(3,0,-1), 'C':list('abc')})).equals(pd.DataFrame({'t':range(3), 'd':range(3,0,-1), 'c':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'T':range(3), 'Y':range(3,0,-1), 'C':list('abc')})).equals(pd.DataFrame({'t':range(3), 'y':range(3,0,-1), 'c':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'T':range(3), 'Y':range(3,0,-1), 'i':list('abc')})).equals(pd.DataFrame({'t':range(3), 'y':range(3,0,-1), 'i':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'T':range(3), 'Y':range(3,0,-1), 'L':list('abc')})).equals(pd.DataFrame({'t':range(3), 'y':range(3,0,-1), 'l':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'k':range(3), 'Y':range(3,0,-1), 'L':list('abc')})).equals(pd.DataFrame({'k':range(3), 'y':range(3,0,-1), 'l':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'k':range(3), 'J':range(3,0,-1), 'L':list('abc')})).equals(pd.DataFrame({'k':range(3), 'j':range(3,0,-1), 'l':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'W':range(3), 'J':range(3,0,-1), 'L':list('abc')})).equals(pd.DataFrame({'w':range(3), 'j':range(3,0,-1), 'l':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'W':range(3), 'A':range(3,0,-1), 'L':list('abc')})).equals(pd.DataFrame({'w':range(3), 'a':range(3,0,-1), 'l':list('abc')}))\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/46 \n",
      "==================================================\n",
      " import numpy as np\n",
      "import monkey as mk\n",
      "kf = mk.KnowledgeFrame(\n",
      "    {\"x\": np.arange(1_000 * 100), \"section\": np.repeat(np.arange(100), 1_000)}\n",
      ")\n",
      "\n",
      "# Say i have a knowledgeframe with 100,000 entries and want to split it into 100 sections of 1000 entries.\n",
      "# How do i take a random sample of say size 50 of just one of the 100 sections. \n",
      "# the data set is already ordered such that the first 1000 results are the first section the next section the next and so on.\n",
      "# You could add a \"section\" column to your data then perform a grouper and sample_by_num(n=50):\n",
      "sample_by_num =  \n",
      "==================================================\n",
      " [' kf.grouper(\"section\").sample_by_num(n=50)', ' kf.grouper(\"section\").employ(lambda x: x.sample_by_num(50))'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'sample_tcs_some_bug'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert sample.shape == (5000, 2)\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/47 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "# Example KnowledgeFrame\n",
      "kf = mk.KnowledgeFrame.from_dict({'Name'  : ['May21', 'James', 'Adi22', 'Hello', 'Girl90'],\n",
      "                             'Volume': [23, 12, 11, 34, 56],\n",
      "                             'Value' : [21321, 12311, 4435, 32454, 654654]})\n",
      "\n",
      "# Want to remove all the numbers from the Name column.\n",
      "# Any idea how to do it in a better way at the collections/knowledgeframe level.\n",
      "kf['Name'] = \n",
      "==================================================\n",
      " [\" kf['Name'].str.replacing('\\\\d+', '')\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'str_replace'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert df.equals(pd.DataFrame({'Name'  : ['May', 'James', 'Adi', 'Hello', 'Girl'],\n",
      "                             'Volume': [23, 12, 11, 34, 56],\n",
      "                             'Value' : [21321, 12311, 4435, 32454, 654654]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/48 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "kf = mk.KnowledgeFrame({'Sp': ['MM1', 'MM1', 'MM1', 'MM2', 'MM2', 'MM2', 'MM4', 'MM4', 'MM4'],\n",
      "                   'Mt': ['S1', 'S1', 'S3', 'S3', 'S4', 'S4', 'S2', 'S2', 'S2'],\n",
      "                   'Value': ['a', 'n', 'cb', 'mk', 'bg', 'dgd', 'rd', 'cb', 'uyi'],\n",
      "                   'num': [3, 2, 5, 8, 10, 1, 2, 2, 7]})\n",
      "\n",
      "# How do I find all rows in a monkey KnowledgeFrame which have the max value for 'num' column, after grouping by 'Mt' column?\n",
      "new_kf = \n",
      "==================================================\n",
      " [\" kf.grouper('Mt').employ(lambda x: x.loc[x.num == x.num.get_max()])\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'groupby_loc_max'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert new_df.equals(df.groupby('Mt').apply(lambda x: x.loc[x.num == x.num.max()]))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/49 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "kf = mk.KnowledgeFrame({\n",
      "'date': [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"friday\"],\n",
      "'value': [1, 2, 3, 4]\n",
      "})\n",
      "\n",
      "# transfer column date to datetime type\n",
      "# when there is a string that is not capable of beeing turned into datetime format, skip that row,\n",
      "# use errors='coerce' for this\n",
      "kf['date'] = \n",
      "==================================================\n",
      " [\" mk.convert_datetime(kf['date'], errors='coerce')\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'to_datetime'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    tmp = pd.DataFrame({'date': [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"friday\"],'value': [1, 2, 3, 4]})\n",
      "    tmp['date'] = pd.to_datetime(tmp['date'], errors='coerce')\n",
      "    df.equals(tmp)\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/50 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "def if_any_value_is_nan(kf):\n",
      "    # How to check if any value is NaN in a Monkey KnowledgeFrame? Return the result.\n",
      "     \n",
      "==================================================\n",
      " ['return kf.ifnull().values.whatever()'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'isnull_value_any'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A': [np.nan, 2, 3], 'B': [1, 2, 3], 'C': [1, 2, 3]})) == True\n",
      "    assert candidate(pd.DataFrame({'A': [np.nan, np.nan, 3], 'B': [1, 2, 3], 'C': [1, 2, 3]})) == True\n",
      "    assert candidate(pd.DataFrame({'A': [np.nan, np.nan, 3], 'B': [1, np.nan, 3], 'C': [1, 2, 3]})) == True\n",
      "    assert candidate(pd.DataFrame({'A': [np.nan, np.nan, 3], 'B': [1, np.nan, 8], 'C': [1, 2, 3]})) == True\n",
      "    assert candidate(pd.DataFrame({'A': [7, 6, 3], 'B': [1, np.nan, 8], 'C': [1, 2, 3]})) == True\n",
      "    assert candidate(pd.DataFrame({'A': [7, 8, 3], 'B': [1, np.nan, 8], 'C': [1, 2, 18]})) == True\n",
      "    assert candidate(pd.DataFrame({'A': [7, 6, 3], 'B': [1, np.nan, 8], 'C': [1, 2, 18]})) == True\n",
      "    assert candidate(pd.DataFrame({'A': [7, 8, 3], 'B': [1, 8, 8], 'C': [1, 2, 18]})) == False\n",
      "    assert candidate(pd.DataFrame({'A': [7, 8, 3], 'B': [81, 5, 8], 'C': [1, 2, 18]})) == False\n",
      "    assert candidate(pd.DataFrame({'A': [7, 94, 3], 'B': [81, 5, 8], 'C': [1, 2, 18]})) == False\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/51 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def sorting_columns_based_on_column_name(kf):\n",
      "    # Sorting columns in monkey knowledgeframe based on column name\n",
      "    # Note that axis is one\n",
      " \n",
      "==================================================\n",
      " ['    return kf.reindexing(sorted(kf.columns), axis=1)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'reindex_sorted'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'Q1.1': [1, 2, 3], 'Q1.3': [4, 5, 6], 'Q1.2': [7, 8, 9]})).equals(pd.DataFrame({'Q1.1': [1, 2, 3], 'Q1.2': [7, 8, 9], 'Q1.3': [4, 5, 6]}))\n",
      "    assert candidate(pd.DataFrame({'Q1.1': [1, 2, 4], 'Q1.3': [4, 5, 6], 'Q1.2': [7, 8, 9]})).equals(pd.DataFrame({'Q1.1': [1, 2, 4], 'Q1.2': [7, 8, 9], 'Q1.3': [4, 5, 6]}))\n",
      "    assert candidate(pd.DataFrame({'Q1.1': [1, 2, 5], 'Q1.3': [4, 5, 6], 'Q1.2': [7, 8, 9]})).equals(pd.DataFrame({'Q1.1': [1, 2, 5], 'Q1.2': [7, 8, 9], 'Q1.3': [4, 5, 6]}))\n",
      "    assert candidate(pd.DataFrame({'Q1.1': [1, 3, 5], 'Q1.3': [4, 5, 6], 'Q1.2': [7, 8, 9]})).equals(pd.DataFrame({'Q1.1': [1, 3, 5], 'Q1.2': [7, 8, 9], 'Q1.3': [4, 5, 6]}))\n",
      "    assert candidate(pd.DataFrame({'Q1.1': [2, 3, 5], 'Q1.3': [4, 5, 6], 'Q1.2': [7, 8, 9]})).equals(pd.DataFrame({'Q1.1': [2, 3, 5], 'Q1.2': [7, 8, 9], 'Q1.3': [4, 5, 6]}))\n",
      "    assert candidate(pd.DataFrame({'Q1.1': [2, 3, 5], 'Q1.3': [3, 5, 6], 'Q1.2': [7, 8, 9]})).equals(pd.DataFrame({'Q1.1': [2, 3, 5], 'Q1.2': [7, 8, 9], 'Q1.3': [3, 5, 6]}))\n",
      "    assert candidate(pd.DataFrame({'Q1.1': [2, 3, 5], 'Q1.3': [3, 3, 6], 'Q1.2': [7, 8, 9]})).equals(pd.DataFrame({'Q1.1': [2, 3, 5], 'Q1.2': [7, 8, 9], 'Q1.3': [3, 3, 6]}))\n",
      "    assert candidate(pd.DataFrame({'Q1.1': [4, 4, 5], 'Q1.3': [3, 3, 6], 'Q1.2': [7, 8, 9]})).equals(pd.DataFrame({'Q1.1': [4, 4, 5], 'Q1.2': [7, 8, 9], 'Q1.3': [3, 3, 6]}))\n",
      "    assert candidate(pd.DataFrame({'Q1.1': [4, 4, 5], 'Q1.3': [3, 3, 6], 'Q1.2': [7, 4, 9]})).equals(pd.DataFrame({'Q1.1': [4, 4, 5], 'Q1.2': [7, 4, 9], 'Q1.3': [3, 3, 6]}))\n",
      "    assert candidate(pd.DataFrame({'Q1.1': [4, 4, 5], 'Q1.3': [3, 3, 6], 'Q1.2': [7, 3, 9]})).equals(pd.DataFrame({'Q1.1': [4, 4, 5], 'Q1.2': [7, 3, 9], 'Q1.3': [3, 3, 6]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/52 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "def get_value_when_condition(kf):\n",
      "    # How can I get the values of column `A` when column `B`=3?\n",
      " \n",
      "==================================================\n",
      " [\"    return kf[kf['B'] == 3]['A'].values\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'condition'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert np.array_equal(candidate(pd.DataFrame({'A': ['p1', 'p1', 'p2', 'p2', 'p3'], 'B': [1, 2, 3, 4, 5]})), np.array(['p2']))\n",
      "    assert np.array_equal(candidate(pd.DataFrame({'A': ['p1', 'p1', 'p2', 'p2', 'p3'], 'B': [1, 4, 3, 4, 5]})), np.array(['p2']))\n",
      "    assert np.array_equal(candidate(pd.DataFrame({'A': ['p1', 'p1', 'p2', 'p2', 'p3'], 'B': [1, 4, 8, 4, 5]})), np.array([]))\n",
      "    assert np.array_equal(candidate(pd.DataFrame({'A': ['p1', 'p1', 'p2', 'p2', 'p5'], 'B': [2, 4, 8, 4, 5]})), np.array([]))\n",
      "    assert np.array_equal(candidate(pd.DataFrame({'A': ['p1', 'p1', 'p2', 'p2', 'p3'], 'B': [2, 3, 4, 4, 5]})), np.array(['p1']))\n",
      "    assert np.array_equal(candidate(pd.DataFrame({'A': ['p2', 'p1', 'p2', 'p2', 'p3'], 'B': [2, 3, 4, 4, 5]})), np.array(['p1']))\n",
      "    assert np.array_equal(candidate(pd.DataFrame({'A': ['p2', 'p1', 'p2', 'p3', 'p3'], 'B': [2, 3, 4, 5, 5]})), np.array(['p1']))\n",
      "    assert np.array_equal(candidate(pd.DataFrame({'A': ['p2', 'p1', 'p1', 'p3', 'p3'], 'B': [2, 3, 4, 5, 5]})), np.array(['p1']))\n",
      "    assert np.array_equal(candidate(pd.DataFrame({'A': ['p2', 'p1', 'p1', 'p1', 'p3'], 'B': [2, 3, 4, 5, 5]})), np.array(['p1']))\n",
      "    assert np.array_equal(candidate(pd.DataFrame({'A': ['p2', 'p1', 'p1', 'p1', 'p2'], 'B': [2, 3, 4, 5, 5]})), np.array(['p1']))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/53 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def get_average_in_column(kf, col_name):\n",
      "    # return the column average/mean\n",
      " \n",
      "==================================================\n",
      " ['    return kf[col_name].average()'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'condition'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({\"A\": [1, 2, 3, 4, 5]}), \"A\") == 3.0\n",
      "    assert candidate(pd.DataFrame({\"A\": [1, 2, 3, 4, 5, 3]}), \"A\") == 3.0\n",
      "    assert candidate(pd.DataFrame({'B': [1, 2, 3, 4, 5, 3]}), 'B') == 3.0\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3, 3, 4, 5, 3]}), 'A') == 3.0\n",
      "    assert candidate(pd.DataFrame({'A': [1, 3, 2, 3, 4, 5, 3]}), 'A') == 3.0\n",
      "    assert candidate(pd.DataFrame({'T': [1, 2, 3, 4, 5, 3]}), 'T') == 3.0\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3, 4, 5, 3, 3, 3]}), 'A') == 3.0\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 1, 3, 5, 4, 5, 3]}), 'A') == 3.0\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3, 4, 5, 3, 2, 4]}), 'A') == 3.0\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3, 4, 5, 3, 1, 5]}), 'A') == 3.0\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/54 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def combine_kf(kf1, kf2):\n",
      "    # How do I combine two knowledgeframes with ignore index? Return the concated knowledgeframe.\n",
      " \n",
      "==================================================\n",
      " ['    return kf1.adding(kf2, ignore_index=True)', '    return mk.concating([kf1, kf2], ignore_index=True)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'append_concat'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2]}), pd.DataFrame({'A': [4, 5]})).equals(pd.DataFrame({'A': [1, 2, 4, 5]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2]}), pd.DataFrame({'A': [4, 6]})).equals(pd.DataFrame({'A': [1, 2, 4, 6]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 4]}), pd.DataFrame({'A': [4, 5]})).equals(pd.DataFrame({'A': [1, 4, 4, 5]}))\n",
      "    assert candidate(pd.DataFrame({'A': [3, 4]}), pd.DataFrame({'A': [4, 5]})).equals(pd.DataFrame({'A': [3, 4, 4, 5]}))\n",
      "    assert candidate(pd.DataFrame({'A': [5, 2]}), pd.DataFrame({'A': [4, 5]})).equals(pd.DataFrame({'A': [5, 2, 4, 5]}))\n",
      "    assert candidate(pd.DataFrame({'A': [4, 2]}), pd.DataFrame({'A': [4, 5]})).equals(pd.DataFrame({'A': [4, 2, 4, 5]}))\n",
      "    assert candidate(pd.DataFrame({'A': [6, 2]}), pd.DataFrame({'A': [9, 5]})).equals(pd.DataFrame({'A': [6, 2, 9, 5]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 7]}), pd.DataFrame({'A': [4, 5]})).equals(pd.DataFrame({'A': [1, 7, 4, 5]}))\n",
      "    assert candidate(pd.DataFrame({'A': [6, 2]}), pd.DataFrame({'A': [4, 56]})).equals(pd.DataFrame({'A': [6, 2, 4, 56]}))\n",
      "    assert candidate(pd.DataFrame({'A': [11, 22]}), pd.DataFrame({'A': [4, 5]})).equals(pd.DataFrame({'A': [11, 22, 4, 5]}))\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/55 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "# This is my KnowledgeFrame that should be repeated for 5 times:\n",
      "x = mk.KnowledgeFrame({'a':1,'b':2}, index = range(1))\n",
      "# I haven't found anything practical, including those like np.repeat ---- it just doesn't work on a KnowledgeFrame.\n",
      "# You can use the concating function:\n",
      "repeated_x = \n",
      "==================================================\n",
      " [' mk.concating([x]*5)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'concat'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert repeated_x.equals(pd.concat([x]*5))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/56 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def knowledgeframe2list_of_dict(kf):\n",
      "    # Monkey KnowledgeFrame to List of Dictionaries\n",
      "    # Use kf.convert_dict() to solve it and return the result\n",
      " \n",
      "==================================================\n",
      " [\"    return kf.convert_dict(orient='records')\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'to_dict'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'a':[1,1,1], 'b':[10,20,20]})) == [{'a': 1, 'b': 10}, {'a': 1, 'b': 20}, {'a': 1, 'b': 20}]\n",
      "    assert candidate(pd.DataFrame({'a':[2,1,1], 'b':[10,20,20]})) == [{'a': 2, 'b': 10}, {'a': 1, 'b': 20}, {'a': 1, 'b': 20}]\n",
      "    assert candidate(pd.DataFrame({'a':[2,1,4], 'b':[10,20,20]})) == [{'a': 2, 'b': 10}, {'a': 1, 'b': 20}, {'a': 4, 'b': 20}]\n",
      "    assert candidate(pd.DataFrame({'a':[2,3,4], 'b':[10,20,20]})) == [{'a': 2, 'b': 10}, {'a': 3, 'b': 20}, {'a': 4, 'b': 20}]\n",
      "    assert candidate(pd.DataFrame({'a':[2,3,4], 'b':[12,20,20]})) == [{'a': 2, 'b': 12}, {'a': 3, 'b': 20}, {'a': 4, 'b': 20}]\n",
      "    assert candidate(pd.DataFrame({'a':[2,3,4], 'b':[12,33,20]})) == [{'a': 2, 'b': 12}, {'a': 3, 'b': 33}, {'a': 4, 'b': 20}]\n",
      "    assert candidate(pd.DataFrame({'a':[2,3,4], 'b':[12,33,4]})) == [{'a': 2, 'b': 12}, {'a': 3, 'b': 33}, {'a': 4, 'b': 4}]\n",
      "    assert candidate(pd.DataFrame({'a':[2,3,41], 'b':[12,33,4]})) == [{'a': 2, 'b': 12}, {'a': 3, 'b': 33}, {'a': 41, 'b': 4}]\n",
      "    assert candidate(pd.DataFrame({'a':[2,33,41], 'b':[12,33,4]})) == [{'a': 2, 'b': 12}, {'a': 33, 'b': 33}, {'a': 41, 'b': 4}]\n",
      "    assert candidate(pd.DataFrame({'a':[21,33,41], 'b':[12,33,4]})) == [{'a': 21, 'b': 12}, {'a': 33, 'b': 33}, {'a': 41, 'b': 4}]\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/57 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def convert_column_to_date(kf):\n",
      "    # Convert Column `Date` to Date Format using monkey function\n",
      "    # return the coverted knowledgeframe\n",
      " \n",
      "==================================================\n",
      " ['    kf[\"Date\"] = mk.convert_datetime(kf.Date)\\n    return kf'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'to_datetime'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame( {'Symbol':['A','A','A'] , 'Date':['02/20/2015','01/15/2016','08/21/2015']})).equals(pd.DataFrame({'Symbol':['A','A','A'] , 'Date':[pd.Timestamp('2015-02-20 00:00:00'),pd.Timestamp('2016-01-15 00:00:00'),pd.Timestamp('2015-08-21 00:00:00')]}))\n",
      "    assert candidate(pd.DataFrame( {'Symbol':['A','A','A'] , 'Date':['02/20/2016','01/15/2016','08/21/2015']})).equals(pd.DataFrame({'Symbol':['A','A','A'] , 'Date':[pd.Timestamp('2016-02-20 00:00:00'),pd.Timestamp('2016-01-15 00:00:00'),pd.Timestamp('2015-08-21 00:00:00')]}))\n",
      "    assert candidate(pd.DataFrame( {'Symbol':['A','A','A'] , 'Date':['02/20/2016','01/15/2017','08/21/2015']})).equals(pd.DataFrame({'Symbol':['A','A','A'] , 'Date':[pd.Timestamp('2016-02-20 00:00:00'),pd.Timestamp('2017-01-15 00:00:00'),pd.Timestamp('2015-08-21 00:00:00')]}))\n",
      "    assert candidate(pd.DataFrame( {'Symbol':['A','A','A'] , 'Date':['02/20/2016','01/15/2017','08/21/2019']})).equals(pd.DataFrame({'Symbol':['A','A','A'] , 'Date':[pd.Timestamp('2016-02-20 00:00:00'),pd.Timestamp('2017-01-15 00:00:00'),pd.Timestamp('2019-08-21 00:00:00')]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/58 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def counting_consecutive_positive_values(y):\n",
      "    # Counting consecutive positive values in Python/monkey array\n",
      "    # I'm trying to count consecutive up days in equity return data; so if a positive day is 1 and a negative is 0, a list y=[0,0,1,1,1,0,0,1,0,1,1] should return z=[0,0,1,2,3,0,0,1,0,1,2].\n",
      "    # Return the result\n",
      " \n",
      "==================================================\n",
      " ['    return y * (y.grouper((y != y.shifting()).cumulative_sum()).cumcount() + 1)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'groupby'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.Series([0,0,1,1])).equals(pd.Series([0,0,1,2]))\n",
      "    assert candidate(pd.Series([0,1,1,1])).equals(pd.Series([0,1,2,3]))\n",
      "    assert candidate(pd.Series([0,1,1,0])).equals(pd.Series([0,1,2,0]))\n",
      "    assert candidate(pd.Series([1,1,1,0])).equals(pd.Series([1,2,3,0]))\n",
      "    assert candidate(pd.Series([1,1,4,0])).equals(pd.Series([1,2,4,0]))\n",
      "    assert candidate(pd.Series([1,1,3,0])).equals(pd.Series([1,2,3,0]))\n",
      "    assert candidate(pd.Series([1,1,2,0])).equals(pd.Series([1,2,2,0]))\n",
      "    assert candidate(pd.Series([1,3,2,0])).equals(pd.Series([1,3,2,0]))\n",
      "    assert candidate(pd.Series([1,3,2,1])).equals(pd.Series([1,3,2,1]))\n",
      "    assert candidate(pd.Series([1,3,3,1])).equals(pd.Series([1,3,6,1]))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/59 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def insert_row_at_arbitrary_in_knowledgeframe(kf, row_to_insert):\n",
      "    \"\"\"\n",
      "    Inserts a row into a knowledgeframe at a specified row with no ingore index, and sort & reset the index with sip=True. \n",
      "    Returns the new knowledgeframe.\n",
      "    \"\"\"\n",
      " \n",
      "==================================================\n",
      " ['    kf = kf.adding(row_to_insert, ignore_index=False)\\n    kf = kf.sorting_index().reseting_index(sip=True)\\n    return kf'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'append_sort_index'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'onset':[23.107, 41.815, 61.606], 'length':[1,2,3]}), pd.DataFrame({'onset': 30.0, 'length': 1.3}, index=[3])).equals(pd.DataFrame({'onset':[23.107, 41.815, 61.606, 30.0], 'length':[1,2,3,1.3]}))\n",
      "    assert candidate(pd.DataFrame({'onset':[28.604, 41.815, 61.606], 'length':[1,2,3]}), pd.DataFrame({'onset': 30.0, 'length': 1.3}, index=[3])).equals(pd.DataFrame({'onset':[28.604, 41.815, 61.606, 30.0], 'length':[1,2,3,1.3]}))\n",
      "    assert candidate(pd.DataFrame({'onset':[28.604, 41.815, 61.606], 'length':[1,2,4]}), pd.DataFrame({'onset': 30.0, 'length': 1.3}, index=[3])).equals(pd.DataFrame({'onset':[28.604, 41.815, 61.606, 30.0], 'length':[1,2,4,1.3]}))\n",
      "    assert candidate(pd.DataFrame({'onset':[28.604, 41.815, 61.606], 'length':[1,3,4]}), pd.DataFrame({'onset': 30.0, 'length': 1.3}, index=[3])).equals(pd.DataFrame({'onset':[28.604, 41.815, 61.606, 30.0], 'length':[1,3,4,1.3]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/60 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def get_data_frame_from_list(list_of_lists):\n",
      "    # list_of_lists format: [header, [row1], [row2], ...]\n",
      "    # header format: [column1, column2, ...]\n",
      "    # row format: [value1, value2, ...]\n",
      "    # How to convert list to knowledgeframe?\n",
      "    # Return the knowledgeframe\n",
      " \n",
      "==================================================\n",
      " ['    return mk.KnowledgeFrame(list_of_lists[1:], columns=list_of_lists[0])'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'DataFrame'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate([['Heading1', 'Heading2'], [1 , 2], [3, 4]]).equals(pd.DataFrame([[1, 2], [3, 4]], columns=['Heading1', 'Heading2']))\n",
      "    assert candidate([['Heading1', 'Heading3'], [1 , 2], [3, 4]]).equals(pd.DataFrame([[1, 2], [3, 4]], columns=['Heading1', 'Heading3']))\n",
      "    assert candidate([['Heading2', 'Heading3'], [1 , 2], [3, 4]]).equals(pd.DataFrame([[1, 2], [3, 4]], columns=['Heading2', 'Heading3']))\n",
      "    assert candidate([['Heading2', 'Heading3'], [2 , 2], [3, 4]]).equals(pd.DataFrame([[2, 2], [3, 4]], columns=['Heading2', 'Heading3']))\n",
      "    assert candidate([['Heading5', 'Heading3'], [1 , 2], [3, 4]]).equals(pd.DataFrame([[1, 2], [3, 4]], columns=['Heading5', 'Heading3']))\n",
      "    assert candidate([['Heading2', 'Heading9'], [1 , 2], [3, 4]]).equals(pd.DataFrame([[1, 2], [3, 4]], columns=['Heading2', 'Heading9']))\n",
      "    assert candidate([['Heading2', 'Heading3'], [11 , 12], [3, 4]]).equals(pd.DataFrame([[11, 12], [3, 4]], columns=['Heading2', 'Heading3']))\n",
      "    assert candidate([['Heading22', 'Heading32'], [1 , 2], [3, 4]]).equals(pd.DataFrame([[1, 2], [3, 4]], columns=['Heading22', 'Heading32']))\n",
      "    assert candidate([['Heading2', 'Heading3'], [14 , 42], [3, 4]]).equals(pd.DataFrame([[14, 42], [3, 4]], columns=['Heading2', 'Heading3']))\n",
      "    assert candidate([['Heading2', 'Heading3'], [1 , 23], [33, 4]]).equals(pd.DataFrame([[1, 23], [33, 4]], columns=['Heading2', 'Heading3']))\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/61 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "kf1 = mk.KnowledgeFrame({'a': [0, 1], 'b': [5, 3]})\n",
      "kf2 = mk.KnowledgeFrame({'c': [0, 1], 'd': [10, 20]})\n",
      "# How do I unioner two knowledgeframes by index?\n",
      "# Set left&right indexs to True\n",
      "unionerd_kf =  \n",
      "==================================================\n",
      " ['mk.unioner(kf1, kf2, left_index=True, right_index=True)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'merge'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert merged_result.equals(pd.merge(df1, df2, left_index=True, right_index=True))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/62 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "kf = mk.KnowledgeFrame({'a': [0, 1], 'b': [5, 3]})\n",
      "# How to obtain monkey KnowledgeFrame without index\n",
      "# I want to print the whole knowledgeframe, but I don't want to print the index\n",
      "kf_string = \n",
      "==================================================\n",
      " [' kf.convert_string(index=False)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'to_string'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert df_string == ' a  b\n",
      " 0  5\n",
      " 1  3'\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/63 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "def sip_all_nan_rows(kf):\n",
      "    # We will sip all Nan rows.\n",
      "    # Return the changed knowledgeframe.\n",
      " \n",
      "==================================================\n",
      " ['    return kf.sipna()'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'dropna'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, np.nan, np.nan], 'C': [2, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1], 'B': [100.0], 'C': [2.0]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, np.nan, np.nan], 'C': [4, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1], 'B': [100.0], 'C': [4.0]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, np.nan, np.nan], 'C': [6, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1], 'B': [100.0], 'C': [6.0]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [110, np.nan, np.nan], 'C': [6, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1], 'B': [110.0], 'C': [6.0]}))\n",
      "    assert candidate(pd.DataFrame({'A': [2, 2, 3], 'B': [110, np.nan, np.nan], 'C': [6, np.nan, np.nan]})).equals(pd.DataFrame({'A': [2], 'B': [110.0], 'C': [6.0]}))\n",
      "    assert candidate(pd.DataFrame({'A': [22, 2, 3], 'B': [110, np.nan, np.nan], 'C': [6, np.nan, np.nan]})).equals(pd.DataFrame({'A': [22], 'B': [110.0], 'C': [6.0]}))\n",
      "    assert candidate(pd.DataFrame({'A': [22, 2, 33], 'B': [110, np.nan, np.nan], 'C': [6, np.nan, np.nan]})).equals(pd.DataFrame({'A': [22], 'B': [110.0], 'C': [6.0]}))\n",
      "    assert candidate(pd.DataFrame({'A': [22, 24, 33], 'B': [110, np.nan, np.nan], 'C': [6, np.nan, np.nan]})).equals(pd.DataFrame({'A': [22], 'B': [110.0], 'C': [6.0]}))\n",
      "    assert candidate(pd.DataFrame({'A': [22, 24, 52], 'B': [110, np.nan, np.nan], 'C': [6, np.nan, np.nan]})).equals(pd.DataFrame({'A': [22], 'B': [110.0], 'C': [6.0]}))\n",
      "    assert candidate(pd.DataFrame({'A': [22, 24, 13], 'B': [110, np.nan, np.nan], 'C': [6, np.nan, np.nan]})).equals(pd.DataFrame({'A': [22], 'B': [110.0], 'C': [6.0]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/64 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def is_contain_particular_value(collections, value):\n",
      "    # How to determine whether a Monkey Column contains a particular value?\n",
      "    # Return the result\n",
      " \n",
      "==================================================\n",
      " ['    return value in collections.distinctive()'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'unique'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.Series([1, 2, 3]), 2) == True\n",
      "    assert candidate(pd.Series([1, 2, 3]), 3) == True\n",
      "    assert candidate(pd.Series([1, 2, 4]), 4) == True\n",
      "    assert candidate(pd.Series([1, 3, 4]), 4) == True\n",
      "    assert candidate(pd.Series([2, 3, 4]), 4) == True\n",
      "    assert candidate(pd.Series([2, 3, 4]), 5) == False\n",
      "    assert candidate(pd.Series([2, 3, 4]), 6) == False\n",
      "    assert candidate(pd.Series([2, 3, 4]), 7) == False\n",
      "    assert candidate(pd.Series([2, 3, 4]), 8) == False\n",
      "    assert candidate(pd.Series([2, 3, 4]), 0) == False\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/65 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def rename_column(kf, old_name, new_name):\n",
      "    # How would I rename the only one column header?\n",
      "    # return the changed knowledgeframe\n",
      " \n",
      "==================================================\n",
      " ['    kf = kf.renaming(columns={old_name: new_name})\\n    return kf'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'rename'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}), 'A', 'D').equals(pd.DataFrame({'D': [1, 2, 3], 'B': [100, 300, 500]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [21, 300, 500]}), 'A', 'D').equals(pd.DataFrame({'D': [1, 2, 3], 'B': [21, 300, 500]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 3, 3], 'B': [21, 300, 500]}), 'A', 'D').equals(pd.DataFrame({'D': [1, 3, 3], 'B': [21, 300, 500]}))\n",
      "    assert candidate(pd.DataFrame({'A': [4, 3, 3], 'B': [21, 300, 500]}), 'A', 'D').equals(pd.DataFrame({'D': [4, 3, 3], 'B': [21, 300, 500]}))\n",
      "    assert candidate(pd.DataFrame({'A': [4, 3, 3], 'B': [21, 42, 500]}), 'A', 'D').equals(pd.DataFrame({'D': [4, 3, 3], 'B': [21, 42, 500]}))\n",
      "    assert candidate(pd.DataFrame({'A': [4, 3, 4], 'B': [21, 42, 500]}), 'A', 'D').equals(pd.DataFrame({'D': [4, 3, 4], 'B': [21, 42, 500]}))\n",
      "    assert candidate(pd.DataFrame({'A': [4, 3, 4], 'B': [21, 42, 32]}), 'A', 'D').equals(pd.DataFrame({'D': [4, 3, 4], 'B': [21, 42, 32]}))\n",
      "    assert candidate(pd.DataFrame({'A': [4, 4, 4], 'B': [21, 42, 32]}), 'A', 'D').equals(pd.DataFrame({'D': [4, 4, 4], 'B': [21, 42, 32]}))\n",
      "    assert candidate(pd.DataFrame({'A': [4, 4, 4], 'B': [21, 12, 32]}), 'A', 'D').equals(pd.DataFrame({'D': [4, 4, 4], 'B': [21, 12, 32]}))\n",
      "    assert candidate(pd.DataFrame({'A': [4, 4, 4], 'B': [21, 12, 21]}), 'A', 'D').equals(pd.DataFrame({'D': [4, 4, 4], 'B': [21, 12, 21]}))\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/66 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def remove_duplicates_by_column(kf, col1, col2):\n",
      "    # I have a knowledgeframe with repeat values in column `col1`. I want to sip duplicates, keeping the row with the last value in column `col2`.\n",
      "    # How would I do that?\n",
      "    # return the final knowledgeframe\n",
      " \n",
      "==================================================\n",
      " ['    return kf.remove_duplicates(subset=col1, keep=\"last\")'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'drop_duplicates'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [100, 300, 500]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [300, 500]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [100, 350, 500]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [350, 500]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [100, 350, 600]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [350, 600]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [120, 350, 600]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [350, 600]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [531, 350, 600]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [350, 600]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [123, 350, 600]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [350, 600]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [123, 125, 600]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [125, 600]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [123, 125, 532]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [125, 532]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [74, 125, 532]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [125, 532]}, index=[1, 2]))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [74, 125, 45]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [125, 45]}, index=[1, 2]))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/67 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def create_empty_kf(col_names):\n",
      "    # Monkey create empty KnowledgeFrame with only column names\n",
      "    # Return: KnowledgeFrame\n",
      " \n",
      "==================================================\n",
      " ['    return mk.KnowledgeFrame(columns=col_names)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'DataFrame'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(['A', 'B', 'C']).equals(pd.DataFrame(columns=['A', 'B', 'C']))\n",
      "    assert candidate(['A', 'd', 'C']).equals(pd.DataFrame(columns=['A', 'd', 'C']))\n",
      "    assert candidate(['A', 'B', 'E']).equals(pd.DataFrame(columns=['A', 'B', 'E']))\n",
      "    assert candidate(['A', 'Q', 'C']).equals(pd.DataFrame(columns=['A', 'Q', 'C']))\n",
      "    assert candidate(['X', 'B', 'C']).equals(pd.DataFrame(columns=['X', 'B', 'C']))\n",
      "    assert candidate(['A', 'B', 'N']).equals(pd.DataFrame(columns=['A', 'B', 'N']))\n",
      "    assert candidate(['A', 'G', 'C']).equals(pd.DataFrame(columns=['A', 'G', 'C']))\n",
      "    assert candidate(['T', 'B', 'C']).equals(pd.DataFrame(columns=['T', 'B', 'C']))\n",
      "    assert candidate(['A', 'S', 'C']).equals(pd.DataFrame(columns=['A', 'S', 'C']))\n",
      "    assert candidate(['A', 'B', 'V']).equals(pd.DataFrame(columns=['A', 'B', 'V']))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/68 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def delete_first_n_rows(kf, n):\n",
      "    # Delete first n rows of a knowledgeframe\n",
      "    # Input:\n",
      "    #   kf: KnowledgeFrame\n",
      "    #   n: int\n",
      "    # Return:\n",
      "    #   KnowledgeFrame\n",
      " \n",
      "==================================================\n",
      " ['    return kf.iloc[n:]'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'iloc'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[3], 'B':[500], 'C':['c']}, index=[2]))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,4], 'B':[100,300,500], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[4], 'B':[500], 'C':['c']}, index=[2]))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,4], 'B':[100,300,123], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[4], 'B':[123], 'C':['c']}, index=[2]))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,43], 'B':[100,300,123], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[43], 'B':[123], 'C':['c']}, index=[2]))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,43], 'B':[100,300,412], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[43], 'B':[412], 'C':['c']}, index=[2]))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,123], 'B':[100,300,412], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[123], 'B':[412], 'C':['c']}, index=[2]))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,123], 'B':[100,223,412], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[123], 'B':[412], 'C':['c']}, index=[2]))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,123], 'B':[312,223,412], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[123], 'B':[412], 'C':['c']}, index=[2]))\n",
      "    assert candidate(pd.DataFrame({'A':[31,2,123], 'B':[312,223,412], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[123], 'B':[412], 'C':['c']}, index=[2]))\n",
      "    assert candidate(pd.DataFrame({'A':[31,23,123], 'B':[312,223,412], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[123], 'B':[412], 'C':['c']}, index=[2]))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/69 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def remove_duplicates_by_col_names(kf):\n",
      "    \"\"\"\n",
      "    Here's a one solution to remove columns based on duplicate column names:\n",
      "    Return the duplicated knowledgeframe\n",
      "    \"\"\"\n",
      " \n",
      "==================================================\n",
      " ['    return kf.loc[:,~kf.columns.duplicated_values()]'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'loc'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'B':list('abc')})).equals(pd.DataFrame({'A':[1,2,3], 'B':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,4], 'B':[100,300,500], 'B':list('abc')})).equals(pd.DataFrame({'A':[1,2,4], 'B':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,3,4], 'B':[100,300,500], 'B':list('abc')})).equals(pd.DataFrame({'A':[1,3,4], 'B':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,3,4], 'B':[100,312,500], 'B':list('abc')})).equals(pd.DataFrame({'A':[1,3,4], 'B':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,3,4], 'B':[100,312,213], 'B':list('abc')})).equals(pd.DataFrame({'A':[1,3,4], 'B':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,3,4], 'B':[973,312,213], 'B':list('abc')})).equals(pd.DataFrame({'A':[1,3,4], 'B':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,3,4], 'B':[973,312,111], 'B':list('abc')})).equals(pd.DataFrame({'A':[1,3,4], 'B':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,3,4], 'C':[973,312,111], 'C':list('abc')})).equals(pd.DataFrame({'A':[1,3,4], 'C':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,3,4], 'C':[973,312,122], 'C':list('abc')})).equals(pd.DataFrame({'A':[1,3,4], 'C':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,3,4], 'C':[973,312,55], 'C':list('abc')})).equals(pd.DataFrame({'A':[1,3,4], 'C':list('abc')}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/70 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def convert_bool_to_int(kf, col_name):\n",
      "    # How can I map True/False to 1/0 in a Monkey KnowledgeFrame?\n",
      "    # return the knowledgeframe with the column converted to int\n",
      " \n",
      "==================================================\n",
      " ['    kf[col_name] = kf[col_name].totype(int)\\n    return kf'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'astype'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[True,True,False]}), 'B').equals(pd.DataFrame({'A':[1,2,3], 'B':[1,1,0]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[True,True,True]}), 'B').equals(pd.DataFrame({'A':[1,2,3], 'B':[1,1,1]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[True,False,False]}), 'B').equals(pd.DataFrame({'A':[1,2,3], 'B':[1,0,0]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,33], 'B':[True,True,False]}), 'B').equals(pd.DataFrame({'A':[1,2,33], 'B':[1,1,0]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,22,3], 'B':[True,True,False]}), 'B').equals(pd.DataFrame({'A':[1,22,3], 'B':[1,1,0]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[False,True,False]}), 'B').equals(pd.DataFrame({'A':[1,2,3], 'B':[0,1,0]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[False,False,False]}), 'B').equals(pd.DataFrame({'A':[1,2,3], 'B':[0,0,0]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[False,False,True]}), 'B').equals(pd.DataFrame({'A':[1,2,3], 'B':[0,0,1]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[True,False,True]}), 'B').equals(pd.DataFrame({'A':[1,2,3], 'B':[1,0,1]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[True,True,True]}), 'B').equals(pd.DataFrame({'A':[1,2,3], 'B':[1,1,1]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/71 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def get_number_columns(kf):\n",
      "    # How do I retrieve the number of columns in a Monkey data frame?\n",
      "    # Return the number of columns in the knowledgeframe\n",
      " \n",
      "==================================================\n",
      " ['    return length(kf.columns)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'len_columns'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({\"pear\": [1,2,3], \"apple\": [2,3,4], \"orange\": [3,4,5]})) == 3\n",
      "    assert candidate(pd.DataFrame({'pear': [1,2,3], 'apple': [2,3,4]})) == 2\n",
      "    assert candidate(pd.DataFrame({'pear': [1,2,3], 'apple': [2,3,5]})) == 2\n",
      "    assert candidate(pd.DataFrame({'pear': [1,4,3], 'apple': [2,3,4]})) == 2\n",
      "    assert candidate(pd.DataFrame({'pear': [3,2,3], 'apple': [2,3,4]})) == 2\n",
      "    assert candidate(pd.DataFrame({'pear': [1,2,3], 'apple': [2,3,5]})) == 2\n",
      "    assert candidate(pd.DataFrame({'pear': [1,2,3]})) == 1\n",
      "    assert candidate(pd.DataFrame({'pear': [11,2,3], 'apple': [2,3,4]})) == 2\n",
      "    assert candidate(pd.DataFrame({'pear': [1,2,3], 'apple': [2,412,4]})) == 2\n",
      "    assert candidate(pd.DataFrame({'pear': [1,2,3], 'apple': [22,33,44]})) == 2\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/72 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "def find_columns_name_lists(kf):\n",
      "    # How do I determine which columns contain NaN values? In particular, can I get a list of the column names containing NaNs?\n",
      "    # Return a list of the column names containing NaNs\n",
      " \n",
      "==================================================\n",
      " ['    return kf.columns[kf.ifna().whatever()].convert_list()'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'find_columns_name_lists'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'pear': [np.nan,2,3], 'apple': [2,3,4]})) == ['pear']\n",
      "    assert candidate(pd.DataFrame({'pear': [np.nan,2,3], 'apple': [np.nan,3,4]})) == ['pear', 'apple']\n",
      "    assert candidate(pd.DataFrame({'pear': [np.nan,3,3], 'apple': [np.nan,3,4]})) == ['pear', 'apple']\n",
      "    assert candidate(pd.DataFrame({'pear': [np.nan,2,3], 'ccc': [np.nan,3,4]})) == ['pear', 'ccc']\n",
      "    assert candidate(pd.DataFrame({'ddd': [np.nan,2,3], 'apple': [np.nan,3,4]})) == ['ddd', 'apple']\n",
      "    assert candidate(pd.DataFrame({'pear': [np.nan,24,3], 'apple': [np.nan,3,4]})) == ['pear', 'apple']\n",
      "    assert candidate(pd.DataFrame({'pear': [np.nan,2,453], 'apple': [np.nan,3,4]})) == ['pear', 'apple']\n",
      "    assert candidate(pd.DataFrame({'pear': [np.nan,2,3], 'apple': [np.nan,34,45]})) == ['pear', 'apple']\n",
      "    assert candidate(pd.DataFrame({'pear': [np.nan,2,3], 'apple': [np.nan,3,433]})) == ['pear', 'apple']\n",
      "    assert candidate(pd.DataFrame({'pear': [np.nan,32,33], 'apple': [np.nan,32,43]})) == ['pear', 'apple']\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/73 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "N = 2\n",
      "kf = mk.KnowledgeFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6], \"c\": [7, 8, 9]})\n",
      "# How to get the last N rows of a monkey KnowledgeFrame?\n",
      "result =  \n",
      "==================================================\n",
      " ['kf.last_tail(N)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'tail'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert result.equals(df.tail(N))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/74 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "def replacing_blank_with_nan(kf):\n",
      "    # replace field that's entirely space (or empty) with NaN using regex\n",
      "    # return the result\n",
      " \n",
      "==================================================\n",
      " [\"    return kf.replacing(r'^\\\\s*$', np.nan, regex=True)\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'replace'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'a': [1.0, 2.0, ' '], 'b': [4.0, 5.0, 6.0]})).astype(np.float).equals(pd.DataFrame({'a': [1.0, 2.0, np.nan], 'b': [4.0, 5.0, 6.0]}))\n",
      "    assert candidate(pd.DataFrame({'a': [2.0, 2.0, ' '], 'b': [4.0, 5.0, 6.0]})).astype(np.float).equals(pd.DataFrame({'a': [2.0, 2.0, np.nan], 'b': [4.0, 5.0, 6.0]}))\n",
      "    assert candidate(pd.DataFrame({'a': [2.0, 2.0, ' '], 'b': [1.0, 5.0, 6.0]})).astype(np.float).equals(pd.DataFrame({'a': [2.0, 2.0, np.nan], 'b': [1.0, 5.0, 6.0]}))\n",
      "    assert candidate(pd.DataFrame({'a': [2.0, 2.0, ' '], 'b': [4.0, 15.0, 6.0]})).astype(np.float).equals(pd.DataFrame({'a': [2.0, 2.0, np.nan], 'b': [4.0, 15.0, 6.0]}))\n",
      "    assert candidate(pd.DataFrame({'a': [2.0, 4.0, ' '], 'b': [4.0, 5.0, 6.0]})).astype(np.float).equals(pd.DataFrame({'a': [2.0, 4.0, np.nan], 'b': [4.0, 5.0, 6.0]}))\n",
      "    assert candidate(pd.DataFrame({'a': [2.0, 2.0, ' '], 'b': [4.0, 15.0, 16.0]})).astype(np.float).equals(pd.DataFrame({'a': [2.0, 2.0, np.nan], 'b': [4.0, 15.0, 16.0]}))\n",
      "    assert candidate(pd.DataFrame({'a': [2.0, 2.0, ' '], 'b': [14.0, 15.0, 6.0]})).astype(np.float).equals(pd.DataFrame({'a': [2.0, 2.0, np.nan], 'b': [14.0, 15.0, 6.0]}))\n",
      "    assert candidate(pd.DataFrame({'a': [21.0, 12.0, ' '], 'b': [4.0, 5.0, 6.0]})).astype(np.float).equals(pd.DataFrame({'a': [21.0, 12.0, np.nan], 'b': [4.0, 5.0, 6.0]}))\n",
      "    assert candidate(pd.DataFrame({'a': [2.0, 2.0, ' '], 'b': [24.0, 25.0, 6.0]})).astype(np.float).equals(pd.DataFrame({'a': [2.0, 2.0, np.nan], 'b': [24.0, 25.0, 6.0]}))\n",
      "    assert candidate(pd.DataFrame({'a': [2.0, ' ', ' '], 'b': [4.0, 5.0, 6.0]})).astype(np.float).equals(pd.DataFrame({'a': [2.0, np.nan , np.nan], 'b': [4.0, 5.0, 6.0]}))\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/75 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "def fill_none_with_zero(kf, col_names):\n",
      "    # Monkey knowledgeframe fillnone() only some columns in place\n",
      "    # This function fills all columns with 0\n",
      "    # Return the changed knowledgeframe\n",
      " \n",
      "==================================================\n",
      " ['    kf[col_names] = kf[col_names].fillnone(0)\\n    return kf'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'fillna'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'a': [1.0, 2.0, None], 'b': [4.0, 5.0, 6.0]}), ['a']).equals(pd.DataFrame({'a': [1.0, 2.0, 0.0], 'b': [4.0, 5.0, 6.0]}))\n",
      "    assert candidate(pd.DataFrame({'a': [1.0, 2.0, None], 'b': [4.0, 5.0, 6.0]}), ['b']).equals(pd.DataFrame({'a': [1.0, 2.0, None], 'b': [4.0, 5.0, 6.0]}))\n",
      "    assert candidate(pd.DataFrame({'a': [1.0, 2.0, None], 'b': [4.0, 5.0, 6.0]}), ['a', 'b']).equals(pd.DataFrame({'a': [1.0, 2.0, 0.0], 'b': [4.0, 5.0, 6.0]}))\n",
      "    assert candidate(pd.DataFrame({'a': [4.0, 2.0, None], 'b': [4.0, 5.0, 6.0]}), ['a', 'b']).equals(pd.DataFrame({'a': [4.0, 2.0, 0.0], 'b': [4.0, 5.0, 6.0]}))\n",
      "    assert candidate(pd.DataFrame({'a': [1.0, 4.0, None], 'b': [4.0, 5.0, 6.0]}), ['a', 'b']).equals(pd.DataFrame({'a': [1.0, 4.0, 0.0], 'b': [4.0, 5.0, 6.0]}))\n",
      "    assert candidate(pd.DataFrame({'a': [1.0, 2.0, None], 'b': [42.0, 5.0, 6.0]}), ['a', 'b']).equals(pd.DataFrame({'a': [1.0, 2.0, 0.0], 'b': [42.0, 5.0, 6.0]}))\n",
      "    assert candidate(pd.DataFrame({'a': [1.0, 2.0, None], 'b': [4.0, 52.0, 62.0]}), ['a', 'b']).equals(pd.DataFrame({'a': [1.0, 2.0, 0.0], 'b': [4.0, 52.0, 62.0]}))\n",
      "    assert candidate(pd.DataFrame({'a': [11.0, 21.0, None], 'b': [4.0, 5.0, 6.0]}), ['a', 'b']).equals(pd.DataFrame({'a': [11.0, 21.0, 0.0], 'b': [4.0, 5.0, 6.0]}))\n",
      "    assert candidate(pd.DataFrame({'a': [1.0, 2.0, None], 'b': [4.0, 15.0, 16.0]}), ['a', 'b']).equals(pd.DataFrame({'a': [1.0, 2.0, 0.0], 'b': [4.0, 15.0, 16.0]}))\n",
      "    assert candidate(pd.DataFrame({'a': [1.0, 23.0, None], 'b': [43.0, 5.0, 6.0]}), ['a', 'b']).equals(pd.DataFrame({'a': [1.0, 23.0, 0.0], 'b': [43.0, 5.0, 6.0]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/76 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def concating_kf(kf1, kf2):\n",
      "    # Given that all the knowledgeframes have the same columns, you can simply concat them:\n",
      "    # return the concated knowledgeframe\n",
      " \n",
      "==================================================\n",
      " ['    return mk.concating([kf1, kf2])'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'concat'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'a': [1, 2], 'b': [4, 2]}), pd.DataFrame({'a': [6, 7], 'b': [9, 6]})).equals(pd.DataFrame({'a': [1, 2, 6, 7], 'b': [4, 2, 9, 6]}, index=[0, 1, 0, 1]))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 3], 'b': [4, 2]}), pd.DataFrame({'a': [6, 7], 'b': [9, 6]})).equals(pd.DataFrame({'a': [1, 3, 6, 7], 'b': [4, 2, 9, 6]}, index=[0, 1, 0, 1]))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 3], 'b': [43, 2]}), pd.DataFrame({'a': [6, 7], 'b': [9, 6]})).equals(pd.DataFrame({'a': [1, 3, 6, 7], 'b': [43, 2, 9, 6]}, index=[0, 1, 0, 1]))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 3], 'b': [43, 32]}), pd.DataFrame({'a': [6, 7], 'b': [9, 6]})).equals(pd.DataFrame({'a': [1, 3, 6, 7], 'b': [43, 32, 9, 6]}, index=[0, 1, 0, 1]))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 3], 'b': [43, 32]}), pd.DataFrame({'a': [62, 7], 'b': [9, 6]})).equals(pd.DataFrame({'a': [1, 3, 62, 7], 'b': [43, 32, 9, 6]}, index=[0, 1, 0, 1]))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 333], 'b': [43, 32]}), pd.DataFrame({'a': [62, 7], 'b': [9, 6]})).equals(pd.DataFrame({'a': [1, 333, 62, 7], 'b': [43, 32, 9, 6]}, index=[0, 1, 0, 1]))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 3], 'b': [43, 32]}), pd.DataFrame({'a': [62, 7], 'b': [9, 66]})).equals(pd.DataFrame({'a': [1, 3, 62, 7], 'b': [43, 32, 9, 66]}, index=[0, 1, 0, 1]))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 3], 'b': [43, 32]}), pd.DataFrame({'a': [62, 7], 'b': [99, 6]})).equals(pd.DataFrame({'a': [1, 3, 62, 7], 'b': [43, 32, 99, 6]}, index=[0, 1, 0, 1]))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 3], 'b': [43, 32]}), pd.DataFrame({'a': [62, 77], 'b': [9, 6]})).equals(pd.DataFrame({'a': [1, 3, 62, 77], 'b': [43, 32, 9, 6]}, index=[0, 1, 0, 1]))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 3], 'b': [43, 32]}), pd.DataFrame({'a': [62, 70], 'b': [9, 6]})).equals(pd.DataFrame({'a': [1, 3, 62, 70], 'b': [43, 32, 9, 6]}, index=[0, 1, 0, 1]))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/77 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def extract_first_and_last_kf(kf):\n",
      "    # Extract first and last row of a knowledgeframe in monkey\n",
      "    # Return the knowledgeframe with the first and last row\n",
      " \n",
      "==================================================\n",
      " ['    return kf.iloc[[0, -1]]'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'iloc'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'a': [1, 3, 2], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [1, 2], 'b': [4, 2]}, index=[0, 2]))\n",
      "    assert candidate(pd.DataFrame({'a': [12, 3, 2], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [12, 2], 'b': [4, 2]}, index=[0, 2]))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 3, 23], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [1, 23], 'b': [4, 2]}, index=[0, 2]))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 33, 2], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [1, 2], 'b': [4, 2]}, index=[0, 2]))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 23, 2], 'b': [4, 43, 2]})).equals(pd.DataFrame({'a': [1, 2], 'b': [4, 2]}, index=[0, 2]))\n",
      "    assert candidate(pd.DataFrame({'a': [123, 3, 2], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [123, 2], 'b': [4, 2]}, index=[0, 2]))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 3, 2], 'b': [4, 344, 2]})).equals(pd.DataFrame({'a': [1, 2], 'b': [4, 2]}, index=[0, 2]))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 3, 342], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [1, 342], 'b': [4, 2]}, index=[0, 2]))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 3, 2], 'b': [4, 4, 234]})).equals(pd.DataFrame({'a': [1, 2], 'b': [4, 234]}, index=[0, 2]))\n",
      "    assert candidate(pd.DataFrame({'a': [1, 3, 223], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [1, 223], 'b': [4, 2]}, index=[0, 2]))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/78 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "def display_rows_with_gt_1_nan(kf):\n",
      "    # Return the knowledgeframe with the rows with one or more NaN values\n",
      " \n",
      "==================================================\n",
      " ['    return kf[kf.ifna().whatever(axis=1)]'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'isna_any'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'a': [np.nan, 3, 2], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [np.nan], 'b': [4]}, index=[0]))\n",
      "    assert candidate(pd.DataFrame({'a': [np.nan, 3, 2], 'b': [5, 4, 2]})).equals(pd.DataFrame({'a': [np.nan], 'b': [5]}, index=[0]))\n",
      "    assert candidate(pd.DataFrame({'a': [np.nan, 332, 2], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [np.nan], 'b': [4]}, index=[0]))\n",
      "    assert candidate(pd.DataFrame({'a': [np.nan, 3, 2], 'b': [4, 4122, 2]})).equals(pd.DataFrame({'a': [np.nan], 'b': [4]}, index=[0]))\n",
      "    assert candidate(pd.DataFrame({'a': [np.nan, 3, 2], 'b': [4, 4, 2123]})).equals(pd.DataFrame({'a': [np.nan], 'b': [4]}, index=[0]))\n",
      "    assert candidate(pd.DataFrame({'a': [np.nan, 31, 22], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [np.nan], 'b': [4]}, index=[0]))\n",
      "    assert candidate(pd.DataFrame({'a': [np.nan, 3, 2], 'b': [4, 34, 22]})).equals(pd.DataFrame({'a': [np.nan], 'b': [4]}, index=[0]))\n",
      "    assert candidate(pd.DataFrame({'a': [np.nan, 31, 12], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [np.nan], 'b': [4]}, index=[0]))\n",
      "    assert candidate(pd.DataFrame({'a': [np.nan, 3, 2], 'b': [14, 14, 12]})).equals(pd.DataFrame({'a': [np.nan], 'b': [4]}, index=[0]))\n",
      "    assert candidate(pd.DataFrame({'a': [np.nan, 33, 32], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [np.nan], 'b': [4]}, index=[0]))\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/79 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def get_row_index_values_as_list(kf):\n",
      "    # Return the row-index values of the knowledgeframe as a list\n",
      " \n",
      "==================================================\n",
      " ['    return kf.index.values.convert_list()'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'tolist',\n",
      "    'type': 'isna_any'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'a': [2, 3, 2], 'b': [4, 4, 2]})) == [0, 1, 2]\n",
      "    assert candidate(pd.DataFrame({'a': [2, 5, 2], 'b': [4, 4, 2]})) == [0, 1, 2]\n",
      "    assert candidate(pd.DataFrame({'a': [2, 8, 2], 'b': [4, 4, 2]})) == [0, 1, 2]\n",
      "    assert candidate(pd.DataFrame({'a': [2, 10, 2], 'b': [4, 4, 2]})) == [0, 1, 2]\n",
      "    assert candidate(pd.DataFrame({'a': [2, 10, 2], 'b': [4, 4, 2]}, index=[1, 0 ,2])) == [1, 0, 2]\n",
      "    assert candidate(pd.DataFrame({'a': [2, 10, 2], 'b': [4, 412, 2]}, index=[1, 0 ,2])) == [1, 0, 2]\n",
      "    assert candidate(pd.DataFrame({'a': [21, 110, 2], 'b': [4, 4, 2]}, index=[1, 0 ,2])) == [1, 0, 2]\n",
      "    assert candidate(pd.DataFrame({'a': [2, 10, 2], 'b': [4, 4, 21]}, index=[1, 0 ,21])) == [1, 0, 21]\n",
      "    assert candidate(pd.DataFrame({'a': [2, 110, 12], 'b': [4, 4, 2]}, index=[1, 0 ,2])) == [1, 0, 2]\n",
      "    assert candidate(pd.DataFrame({'a': [32, 310, 2], 'b': [4, 4, 2]}, index=[1, 0 ,2])) == [1, 0, 2]\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/80 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "kf = mk.KnowledgeFrame({'mycol':np.arange(5), 'dummy':np.arange(5)})\n",
      "# I find myself often having to check whether a column or row exists in a knowledgeframe before trying to reference it.\n",
      "# Is there any way to do this more nicely? \n",
      "# For example on an arbitrary object I can do x = getattr(anobject, 'id', default) - is there anything similar to this in monkey? Really any way to achieve what I'm doing more gracefully?\n",
      "# Output the second row of data in `mycol` column if it exists, otherwise output NaN\n",
      "value = \n",
      "==================================================\n",
      " [' kf.mycol.getting(1, np.nan)', \" kf.loc[1, 'mycol'] if 1 in kf.index else np.nan\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'get_index'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert value == 1\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/81 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def counting_occurrences_of_a_value(collections, value):\n",
      "    # Count the number of occurrences of a value in a collections\n",
      "    # Return the count\n",
      " \n",
      "==================================================\n",
      " ['    return collections.counts_value_num()[value]'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'value_counts'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.Series([1, 2, 3, 1, 2, 3, 1, 2, 3]), 1) == 3\n",
      "    assert candidate(pd.Series([1, 2, 3, 1, 1, 3, 1, 2, 3]), 1) == 4\n",
      "    assert candidate(pd.Series([1, 4, 3, 1, 1, 3, 1, 2, 3]), 1) == 4\n",
      "    assert candidate(pd.Series([1, 2, 3, 1, 1, 35, 1, 2, 3]), 1) == 4\n",
      "    assert candidate(pd.Series([1, 2, 13, 1, 1, 3, 1, 12, 3]), 1) == 4\n",
      "    assert candidate(pd.Series([11, 2, 3, 1, 1, 3, 1, 2, 3]), 1) == 3\n",
      "    assert candidate(pd.Series([1, 2, 3, 1, 1, 43, 1, 42, 35]), 1) == 4\n",
      "    assert candidate(pd.Series([1, 2, 3, 1, 1, 3, 1, 2, 3]), 2) == 2\n",
      "    assert candidate(pd.Series([1, 2, 3, 1, 1, 3, 1, 2, 3]), 3) == 3\n",
      "    assert candidate(pd.Series([1, 2, 3, 1, 1, 3, 1, 2, 33]), 33) == 1\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/82 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def find_col_a_gt_col_b_rows(kf, col_a, col_b):\n",
      "    # Find rows in kf where col_a > col_b\n",
      "    # Return the rows\n",
      " \n",
      "==================================================\n",
      " ['    return kf[kf[col_a] > kf[col_b]]'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'apply'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A': [5, 2, 3], 'B': [4, 5, 6]}), 'A', 'B').equals(pd.DataFrame({'A': [5], 'B': [4]}))\n",
      "    assert candidate(pd.DataFrame({'A': [5, 7, 3], 'B': [4, 5, 6]}), 'A', 'B').equals(pd.DataFrame({'A': [5, 7], 'B': [4, 5]}))\n",
      "    assert candidate(pd.DataFrame({'A': [5, 7, 3], 'B': [4, 2, 6]}), 'A', 'B').equals(pd.DataFrame({'A': [5, 7], 'B': [4, 2]}))\n",
      "    assert candidate(pd.DataFrame({'A': [6, 7, 3], 'B': [4, 2, 6]}), 'A', 'B').equals(pd.DataFrame({'A': [6, 7], 'B': [4, 2]}))\n",
      "    assert candidate(pd.DataFrame({'A': [6, 8, 3], 'B': [4, 2, 6]}), 'A', 'B').equals(pd.DataFrame({'A': [6, 8], 'B': [4, 2]}))\n",
      "    assert candidate(pd.DataFrame({'A': [6, 8, 3], 'B': [4, 3, 6]}), 'A', 'B').equals(pd.DataFrame({'A': [6, 8], 'B': [4, 3]}))\n",
      "    assert candidate(pd.DataFrame({'A': [6, 8, 3], 'B': [4, 3, 4]}), 'A', 'B').equals(pd.DataFrame({'A': [6, 8], 'B': [4, 3]}))\n",
      "    assert candidate(pd.DataFrame({'A': [6, 8, 1], 'B': [4, 3, 4]}), 'A', 'B').equals(pd.DataFrame({'A': [6, 8], 'B': [4, 3]}))\n",
      "    assert candidate(pd.DataFrame({'A': [6, 8, 1], 'B': [4, 3, 14]}), 'A', 'B').equals(pd.DataFrame({'A': [6, 8], 'B': [4, 3]}))\n",
      "    assert candidate(pd.DataFrame({'A': [6, 18, 1], 'B': [4, 3, 14]}), 'A', 'B').equals(pd.DataFrame({'A': [6, 18], 'B': [4, 3]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/83 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def sip_consecutive_duplicates(collections):\n",
      "    # Drop consecutive duplicates\n",
      "    # Return the result\n",
      " \n",
      "==================================================\n",
      " ['    return collections.loc[collections.shifting(-1) != collections]'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'loc'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.Series([1, 2, 2, 3, 2])).equals(pd.Series([1, 2, 3, 2], index=[0, 2, 3, 4]))\n",
      "    assert candidate(pd.Series([1, 2, 2, 4, 2])).equals(pd.Series([1, 2, 4, 2], index=[0, 2, 3, 4]))\n",
      "    assert candidate(pd.Series([1, 2, 2, 5, 2])).equals(pd.Series([1, 2, 5, 2], index=[0, 2, 3, 4]))\n",
      "    assert candidate(pd.Series([1, 2, 2, 6, 2])).equals(pd.Series([1, 2, 6, 2], index=[0, 2, 3, 4]))\n",
      "    assert candidate(pd.Series([1, 2, 2, 7, 2])).equals(pd.Series([1, 2, 7, 2], index=[0, 2, 3, 4]))\n",
      "    assert candidate(pd.Series([1, 2, 2, 8, 2])).equals(pd.Series([1, 2, 8, 2], index=[0, 2, 3, 4]))\n",
      "    assert candidate(pd.Series([1, 2, 2, 9, 2])).equals(pd.Series([1, 2, 9, 2], index=[0, 2, 3, 4]))\n",
      "    assert candidate(pd.Series([1, 2, 2, 10, 2])).equals(pd.Series([1, 2, 10, 2], index=[0, 2, 3, 4]))\n",
      "    assert candidate(pd.Series([1, 2, 2, 11, 2])).equals(pd.Series([1, 2, 11, 2], index=[0, 2, 3, 4]))\n",
      "    assert candidate(pd.Series([1, 2, 2, 13, 2])).equals(pd.Series([1, 2, 13, 2], index=[0, 2, 3, 4]))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/84 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def value_round_a_single_column(kf):\n",
      "    # Round a single column `A`\n",
      "    # Return the knowledgeframe\n",
      " \n",
      "==================================================\n",
      " ['    kf.A = kf.A.value_round()\\n    return kf'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'round'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A': [1.23, 2.34, 3.45], 'B': [4.56, 5.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 2.0, 3.0], 'B': [4.56, 5.67, 6.78]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1.41, 2.34, 3.45], 'B': [4.56, 5.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 2.0, 3.0], 'B': [4.56, 5.67, 6.78]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1.41, 2.36, 3.45], 'B': [4.56, 5.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 2.0, 3.0], 'B': [4.56, 5.67, 6.78]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1.41, 2.36, 3.55], 'B': [4.56, 5.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 2.0, 4.0], 'B': [4.56, 5.67, 6.78]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1.41, 2.56, 3.55], 'B': [4.56, 5.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 3.0, 4.0], 'B': [4.56, 5.67, 6.78]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1.31, 2.56, 3.55], 'B': [4.56, 5.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 3.0, 4.0], 'B': [4.56, 5.67, 6.78]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1.31, 1.56, 3.55], 'B': [4.56, 5.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 2.0, 4.0], 'B': [4.56, 5.67, 6.78]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1.31, 1.56, 3.55], 'B': [4.56, 3.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 2.0, 4.0], 'B': [4.56, 3.67, 6.78]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1.31, 1.56, 4.15], 'B': [4.56, 3.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 2.0, 4.0], 'B': [4.56, 3.67, 6.78]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1.31, 1.56, 4.05], 'B': [4.56, 3.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 2.0, 4.0], 'B': [4.56, 3.67, 6.78]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/85 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def add_zeros_to_string(kf, col_name):\n",
      "    # Add Leading Zeros to Strings at `col_name` in Monkey Dataframe\n",
      "    # The maximum length of the string is 15\n",
      "    # Return the knowledgeframe\n",
      " \n",
      "==================================================\n",
      " [\"    kf[col_name] = kf[col_name].employ(lambda x: '{0:0>15}'.formating(x))\\n    return kf\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'round'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A': [1234556,3456], 'B': [\"abc\", \"def\"]}), \"A\").equals(pd.DataFrame({'A': ['000000001234556', '000000000003456'], 'B': [\"abc\", \"def\"]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1234556,3456], 'B': ['abc', 'ddd']}), 'A').equals(pd.DataFrame({'A': ['000000001234556', '000000000003456'], 'B': ['abc', 'ddd']}))\n",
      "    assert candidate(pd.DataFrame({'A': [1234556,3456], 'B': ['rsc', 'ddd']}), 'A').equals(pd.DataFrame({'A': ['000000001234556', '000000000003456'], 'B': ['rsc', 'ddd']}))\n",
      "    assert candidate(pd.DataFrame({'A': [1234556,34561], 'B': ['rsc', 'ddd']}), 'A').equals(pd.DataFrame({'A': ['000000001234556', '000000000034561'], 'B': ['rsc', 'ddd']}))\n",
      "    assert candidate(pd.DataFrame({'A': [1234553,34561], 'B': ['rsc', 'ddd']}), 'A').equals(pd.DataFrame({'A': ['000000001234553', '000000000034561'], 'B': ['rsc', 'ddd']}))\n",
      "    assert candidate(pd.DataFrame({'A': [1234553,34561], 'B': ['aaa', 'ddd']}), 'A').equals(pd.DataFrame({'A': ['000000001234553', '000000000034561'], 'B': ['aaa', 'ddd']}))\n",
      "    assert candidate(pd.DataFrame({'A': [1234553,34561], 'B': ['aaa', 'cas']}), 'A').equals(pd.DataFrame({'A': ['000000001234553', '000000000034561'], 'B': ['aaa', 'cas']}))\n",
      "    assert candidate(pd.DataFrame({'A': [1234553,34561], 'B': ['csd', 'cas']}), 'A').equals(pd.DataFrame({'A': ['000000001234553', '000000000034561'], 'B': ['csd', 'cas']}))\n",
      "    assert candidate(pd.DataFrame({'A': [1234553,34561], 'B': ['rrr', 'cas']}), 'A').equals(pd.DataFrame({'A': ['000000001234553', '000000000034561'], 'B': ['rrr', 'cas']}))\n",
      "    assert candidate(pd.DataFrame({'A': [1234553,34561], 'B': ['rrr', 'ras']}), 'A').equals(pd.DataFrame({'A': ['000000001234553', '000000000034561'], 'B': ['rrr', 'ras']}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/86 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def adding_dict_to_kf(kf, dictionary):\n",
      "    # adding dictionary to data frame\n",
      "    # return the data frame\n",
      " \n",
      "==================================================\n",
      " ['    kf = kf.adding(dictionary, ignore_index=True)\\n    return kf'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'append'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame(), {'B': 100, 'C': 200}).equals(pd.DataFrame({'B': [100.0], 'C': [200.0]}))\n",
      "    assert candidate(pd.DataFrame(), {'B': 110, 'C': 200}).equals(pd.DataFrame({'B': [110.0], 'C': [200.0]}))\n",
      "    assert candidate(pd.DataFrame(), {'B': 120, 'C': 200}).equals(pd.DataFrame({'B': [120.0], 'C': [200.0]}))\n",
      "    assert candidate(pd.DataFrame(), {'B': 150, 'C': 200}).equals(pd.DataFrame({'B': [150.0], 'C': [200.0]}))\n",
      "    assert candidate(pd.DataFrame(), {'B': 150, 'C': 220}).equals(pd.DataFrame({'B': [150.0], 'C': [220.0]}))\n",
      "    assert candidate(pd.DataFrame(), {'B': 154, 'C': 220}).equals(pd.DataFrame({'B': [154.0], 'C': [220.0]}))\n",
      "    assert candidate(pd.DataFrame(), {'B': 164, 'C': 220}).equals(pd.DataFrame({'B': [164.0], 'C': [220.0]}))\n",
      "    assert candidate(pd.DataFrame(), {'B': 164, 'C': 240}).equals(pd.DataFrame({'B': [164.0], 'C': [240.0]}))\n",
      "    assert candidate(pd.DataFrame(), {'B': 164, 'C': 244}).equals(pd.DataFrame({'B': [164.0], 'C': [244.0]}))\n",
      "    assert candidate(pd.DataFrame(), {'B': 184, 'C': 244}).equals(pd.DataFrame({'B': [184.0], 'C': [244.0]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/87 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def transform_timestamp_to_pydatetime(timestamp):\n",
      "    # transform timestamp to pydatetime object\n",
      "    # return pydatetime object\n",
      " \n",
      "==================================================\n",
      " ['    return timestamp.convert_pydatetime()'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'to_pydatetime'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.Timestamp('2019-01-01')) == pd.Timestamp('2019-01-01').to_pydatetime()\n",
      "    assert candidate(pd.Timestamp('2022-01-01')) == pd.Timestamp('2022-01-01').to_pydatetime()\n",
      "    assert candidate(pd.Timestamp('2022-03-01')) == pd.Timestamp('2022-03-01').to_pydatetime()\n",
      "    assert candidate(pd.Timestamp('2022-03-04')) == pd.Timestamp('2022-03-04').to_pydatetime()\n",
      "    assert candidate(pd.Timestamp('2022-02-01')) == pd.Timestamp('2022-02-01').to_pydatetime()\n",
      "    assert candidate(pd.Timestamp('2022-02-09')) == pd.Timestamp('2022-02-09').to_pydatetime()\n",
      "    assert candidate(pd.Timestamp('2022-03-12')) == pd.Timestamp('2022-03-12').to_pydatetime()\n",
      "    assert candidate(pd.Timestamp('2022-03-16')) == pd.Timestamp('2022-03-16').to_pydatetime()\n",
      "    assert candidate(pd.Timestamp('2022-02-28')) == pd.Timestamp('2022-02-28').to_pydatetime()\n",
      "    assert candidate(pd.Timestamp('2021-02-28')) == pd.Timestamp('2021-02-28').to_pydatetime()\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/88 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def getting_percentage_of_each_gender(collections):\n",
      "    # Given a monkey collections that represents frequencies of a value, how can I turn those frequencies into percentages?\n",
      "    # Return the percentage of each gender.\n",
      " \n",
      "==================================================\n",
      " ['    return collections.counts_value_num(normalize=True)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'value_counts'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'sex': ['male'] * 5 + ['female'] * 3}).sex).equals(pd.DataFrame({'sex': ['male'] * 5 + ['female'] * 3}).sex.value_counts(normalize=True))\n",
      "    assert candidate(pd.DataFrame({'sex': ['male'] * 4 + ['female'] * 3}).sex).equals(pd.DataFrame({'sex': ['male'] * 4 + ['female'] * 3}).sex.value_counts(normalize=True))\n",
      "    assert candidate(pd.DataFrame({'sex': ['male'] * 6 + ['female'] * 3}).sex).equals(pd.DataFrame({'sex': ['male'] * 6 + ['female'] * 3}).sex.value_counts(normalize=True))\n",
      "    assert candidate(pd.DataFrame({'sex': ['male'] * 5 + ['female'] * 1}).sex).equals(pd.DataFrame({'sex': ['male'] * 5 + ['female'] * 1}).sex.value_counts(normalize=True))\n",
      "    assert candidate(pd.DataFrame({'sex': ['male'] * 2 + ['female'] * 3}).sex).equals(pd.DataFrame({'sex': ['male'] * 2 + ['female'] * 3}).sex.value_counts(normalize=True))\n",
      "    assert candidate(pd.DataFrame({'sex': ['male'] * 4 + ['female'] * 13}).sex).equals(pd.DataFrame({'sex': ['male'] * 4 + ['female'] * 13}).sex.value_counts(normalize=True))\n",
      "    assert candidate(pd.DataFrame({'sex': ['male'] * 15 + ['female'] * 13}).sex).equals(pd.DataFrame({'sex': ['male'] * 15 + ['female'] * 13}).sex.value_counts(normalize=True))\n",
      "    assert candidate(pd.DataFrame({'sex': ['male'] * 43 + ['female'] * 3}).sex).equals(pd.DataFrame({'sex': ['male'] * 43 + ['female'] * 3}).sex.value_counts(normalize=True))\n",
      "    assert candidate(pd.DataFrame({'sex': ['male'] * 53 + ['female'] * 33}).sex).equals(pd.DataFrame({'sex': ['male'] * 53 + ['female'] * 33}).sex.value_counts(normalize=True))\n",
      "    assert candidate(pd.DataFrame({'sex': ['male'] * 25 + ['female'] * 32}).sex).equals(pd.DataFrame({'sex': ['male'] * 25 + ['female'] * 32}).sex.value_counts(normalize=True))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/89 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def  divide_multiple_cols_by_first_col(kf):\n",
      "    # I need to  divide all ['B','C'] columns but the first column 'A' in a KnowledgeFrame by the first column.\n",
      "    # Return the result.\n",
      " \n",
      "==================================================\n",
      " [\"    kf[['B','C']] = kf[['B','C']]. division(kf.A, axis=0)\\n    return kf\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'div'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A':[1,3,5], 'B':[10,30,50], 'C':[100,300,500]})).equals(pd.DataFrame({'A':[1,3,5], 'B':[10.0, 10.0, 10.0], 'C':[100.0, 100.0, 100.0]}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,3], 'B':[10,30], 'C':[100,300]})).equals(pd.DataFrame({'A':[1,3], 'B':[10.0, 10.0], 'C':[100.0, 100.0]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/90 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "def ceiling_of_collections(s):\n",
      "    # ceiling of a monkey collections\n",
      "    # Return the result.\n",
      " \n",
      "==================================================\n",
      " ['    return np.ceiling(s)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'ceil'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.Series([1.2, 2.3, 3.4, 4.5, 5.6])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n",
      "    assert candidate(pd.Series([1.1, 2.3, 3.4, 4.5, 5.6])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n",
      "    assert candidate(pd.Series([1.2, 2.4, 3.4, 4.5, 5.6])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n",
      "    assert candidate(pd.Series([1.2, 2.3, 3.2, 4.5, 5.6])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n",
      "    assert candidate(pd.Series([1.2, 2.3, 3.4, 4.2, 5.6])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n",
      "    assert candidate(pd.Series([1.2, 2.3, 3.4, 4.5, 5.1])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n",
      "    assert candidate(pd.Series([1.2, 2.3, 3.4, 4.4, 5.6])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n",
      "    assert candidate(pd.Series([1.2, 2.3, 3.4, 4.5, 5.2])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n",
      "    assert candidate(pd.Series([1.4, 2.3, 3.4, 4.5, 5.6])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n",
      "    assert candidate(pd.Series([1.2, 2.1, 3.4, 4.1, 5.6])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/91 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "def delete_all_nan_columns(kf):\n",
      "    # Delete all columns that contain all NaN values\n",
      "    # Return the result.\n",
      " \n",
      "==================================================\n",
      " [\"    return kf.sipna(how='all', axis=1)\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'dropna'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1, 2, 3]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 3, 3], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1, 3, 3]}))\n",
      "    assert candidate(pd.DataFrame({'A': [4, 2, 3], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [4, 2, 3]}))\n",
      "    assert candidate(pd.DataFrame({'A': [6, 2, 3], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [6, 2, 3]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 12, 3], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1, 12, 3]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 33], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1, 2, 33]}))\n",
      "    assert candidate(pd.DataFrame({'A': [13, 23, 3], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [13, 23, 3]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 25, 35], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1, 25, 35]}))\n",
      "    assert candidate(pd.DataFrame({'A': [41, 2, 3], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [41, 2, 3]}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 24, 3], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1, 24, 3]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/92 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "kf = mk.KnowledgeFrame({'name': ['jon','sam','jane','bob'],\n",
      "           'age': [30,25,18,26],\n",
      "           'sex':['male','male','female','male']})\n",
      "\n",
      "row = ['45', 'Dean', 'male']\n",
      "# add the row at top in kf\n",
      "kf.loc[-1] = row\n",
      "kf.index = kf.index + 1\n",
      "# resort the index by inplace\n",
      " \n",
      "==================================================\n",
      " ['kf.sorting_index(inplace=True)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'dropna'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert df.equals(pd.DataFrame({'name': ['Dean', 'jon','sam','jane','bob'], 'age': [45, 30,25,18,26], 'sex':['male', 'male','male','female','male']}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/93 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def set_value_to_entire_col(kf, value):\n",
      "    # Set value to an entire column `B` of a monkey knowledgeframe\n",
      "    # Return the changed knowledgeframe.\n",
      " \n",
      "==================================================\n",
      " ['    kf = kf.allocate(B=value)\\n    return kf'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'assign'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [21, 300, 500]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [21, 31, 500]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [21, 300, 21]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [21, 300, 50]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [21, 312, 500]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [21, 301, 52]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [31, 3, 500]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [21, 30, 5]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n",
      "    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [21, 13, 0]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/94 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "s1 = mk.Collections([3,4,5])\n",
      "s2 = mk.Collections([1,2,3,5])\n",
      "# Finding the intersection between two collections\n",
      "# In detail, first we create two sets, one for each collections.\n",
      "# Then we find the intersection of the two sets.\n",
      "s1, s2 = set(s1), set(s2)\n",
      "interst_result = \n",
      "==================================================\n",
      " [' s1.interst(s2)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'intersection'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert intersection_result == {3, 5}\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/95 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def getting_first_n_rows(kf, n):\n",
      "    # I would simply like to slice the Data Frame and take the first n rows.\n",
      "    # Return the result\n",
      " \n",
      "==================================================\n",
      " ['    return kf.header_num(n)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'head'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('abc')}), 1).equals(pd.DataFrame({'A':[1], 'B':[100], 'C':['a']}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,23,3], 'B':[100,300,500], 'C':list('abc')}), 1).equals(pd.DataFrame({'A':[1], 'B':[100], 'C':['a']}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[110,300,500], 'C':list('abc')}), 1).equals(pd.DataFrame({'A':[1], 'B':[110], 'C':['a']}))\n",
      "    assert candidate(pd.DataFrame({'A':[4,2,3], 'B':[100,300,500], 'C':list('abc')}), 1).equals(pd.DataFrame({'A':[4], 'B':[100], 'C':['a']}))\n",
      "    assert candidate(pd.DataFrame({'A':[13,2,3], 'B':[100,300,500], 'C':list('abc')}), 1).equals(pd.DataFrame({'A':[13], 'B':[100], 'C':['a']}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('dbc')}), 1).equals(pd.DataFrame({'A':[1], 'B':[100], 'C':['d']}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,32], 'B':[100,300,500], 'C':list('abc')}), 1).equals(pd.DataFrame({'A':[1], 'B':[100], 'C':['a']}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('rbc')}), 1).equals(pd.DataFrame({'A':[1], 'B':[100], 'C':['r']}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,22,3], 'B':[100,300,500], 'C':list('abc')}), 1).equals(pd.DataFrame({'A':[1], 'B':[100], 'C':['a']}))\n",
      "    assert candidate(pd.DataFrame({'A':[11,2,3], 'B':[100,300,500], 'C':list('abc')}), 1).equals(pd.DataFrame({'A':[11], 'B':[100], 'C':['a']}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/96 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "kf = mk.KnowledgeFrame({'Apples': [2, 1, np.nan],\n",
      "              'Bananas': [3, 3, 7],\n",
      "              'Grapes': [np.nan, 2, 3],})\n",
      "\n",
      "# Add a new column named 'Fruit Total' that sums the values of the other columns\n",
      "# Note that igonring the NaN values\n",
      " \n",
      "==================================================\n",
      " [\"kf['Fruit Total'] = kf.employ(lambda x: total_sum(x.values), axis=1)\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'sum'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    tmp = pd.DataFrame({'Apples': [2, 1, np.nan],'Bananas': [3, 3, 7],'Grapes': [np.nan, 2, 3],})\n",
      "    tmp['Fruit Total'] = tmp.apply(lambda x: sum(x.values), axis=1)\n",
      "    assert df.equals(tmp)\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/97 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "def find_non_numeric_rows(kf):\n",
      "    # Finding non-numeric rows in knowledgeframe in monkey\n",
      "    # Return the raws that contain non-numeric values\n",
      "    # So to get the subKnowledgeFrame of rouges, (Note: the negation, ~, of the above finds the ones which have at least one rogue non-numeric):\n",
      " \n",
      "==================================================\n",
      " ['    return kf[~kf.conduct_map(np.isreal).total_all(1)]'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'applymap'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,'bad',500]})).equals(pd.DataFrame({'A':[2], 'B':['bad']}, index=[1]))\n",
      "    assert candidate(pd.DataFrame({'A':[21,2,3], 'B':[100,'bad',500]})).equals(pd.DataFrame({'A':[2], 'B':['bad']}, index=[1]))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,32], 'B':[100,'bad',500]})).equals(pd.DataFrame({'A':[2], 'B':['bad']}, index=[1]))\n",
      "    assert candidate(pd.DataFrame({'A':[121,2,3], 'B':[100,'bad',500]})).equals(pd.DataFrame({'A':[2], 'B':['bad']}, index=[1]))\n",
      "    assert candidate(pd.DataFrame({'A':[1,21,3], 'B':[100,'bad',500]})).equals(pd.DataFrame({'A':[21], 'B':['bad']}, index=[1]))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,'bads',500]})).equals(pd.DataFrame({'A':[2], 'B':['bads']}, index=[1]))\n",
      "    assert candidate(pd.DataFrame({'A':[12,2,3], 'B':[100,'bad',3500]})).equals(pd.DataFrame({'A':[2], 'B':['bad']}, index=[1]))\n",
      "    assert candidate(pd.DataFrame({'A':[11,2,3], 'B':[100,'bad',500]})).equals(pd.DataFrame({'A':[2], 'B':['bad']}, index=[1]))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,32], 'B':[100,'bad',2500]})).equals(pd.DataFrame({'A':[2], 'B':['bad']}, index=[1]))\n",
      "    assert candidate(pd.DataFrame({'A':[1,42,3], 'B':[100,'good',500]})).equals(pd.DataFrame({'A':[42], 'B':['good']}, index=[1]))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/98 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "kf1 = mk.KnowledgeFrame({'staff':[1,4], 'company':[100,301]})\n",
      "kf2 = mk.KnowledgeFrame({'person':[1,2], 'company':[100,300]})\n",
      "# unioner the above two knowledgeframes on column 'company'\n",
      "unionerd_kf = \n",
      "==================================================\n",
      " [\" mk.unioner(kf1, kf2, on='company')\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra',\n",
      "    'dataset': 'test',\n",
      "    'type': 'merge'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert merged_df.equals(pd.DataFrame({\"staff\": [1], \"company\": [100], \"person\": [1]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/99 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "import numpy as np\n",
      "\n",
      "kf = mk.KnowledgeFrame({'A':[1,4], 'B':[np.nan,301]})\n",
      "# # counting the number of missing/NaN in each column\n",
      "# Get a collections with the number of missing/NaN in each column\n",
      "count_collections = \n",
      "==================================================\n",
      " [' kf.ifnull().total_sum()', ' kf.ifnull().total_sum(axis=0)'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'isnull_sum'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert count_series.equals(pd.Series([0, 1], index=['A', 'B']))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/100 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "kf = mk.KnowledgeFrame({'col': [\"apple\",\n",
      "                           \"pear\",\n",
      "                           \"strawberry\"]})\n",
      "targets = ['apple', 'banana']\n",
      "# Any word from `targets` are present in sentence.\n",
      "result = \n",
      "==================================================\n",
      " [\" kf.loc[kf['col'].incontain(targets)]\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'loc_isin'\n",
      "}\n",
      "\n",
      "\n",
      "def check():\n",
      "    assert result.equals(pd.DataFrame({'col': [\"apple\"]}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/34 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def f(x):\n",
      "    a = x['Value'].iat[2] - x['Value'].iat[1]\n",
      "    b = x['Value'].iat[3] - x['Value'].iat[0]\n",
      "    c = x['ID'].iat[2] + ' - ' + x['ID'].iat[1]\n",
      "    d = x['ID'].iat[3] + ' - ' + x['ID'].iat[0]\n",
      "    return mk.KnowledgeFrame({'Value': [a,b], 'ID':[c,d]})\n",
      "\n",
      "def calculate_row_diff_groupwise(kf):\n",
      "    # I need to calculate the difference between two rows groupwise using monkey.\n",
      "    # To calculate the total_sum I would use monkey.grouper('Group').total_sum(), but how do you calculate the difference between rows where the row ordering is important?\n",
      "    # I think we need custom function with employ which return KnowledgeFrame for each group, for select by position is used iat:\n",
      "    # Return the result\n",
      " \n",
      "==================================================\n",
      " [\"    return kf.grouper('Group').employ(f).reseting_index(level=1, sip=True).reseting_index()\"] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'groupby_apply_reset_index'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'Group': ['M1', 'M1', 'M1', 'M1'], 'Value': [3, 3, 5, 4], 'ID': ['dki', 'two', 'three', 'msra']})).equals(pd.DataFrame({'Group': ['M1', 'M1'], 'Value': [2, 1], 'ID': ['three - two', 'msra - dki']}))\n",
      "    assert candidate(pd.DataFrame({'Group': ['Tom', 'Tom', 'Tom', 'Tom'], 'Value': [3, 3, 5, 4], 'ID': ['pku', 'dki', 'msra', 'thu']})).equals(pd.DataFrame({'Group': ['Tom', 'Tom'], 'Value': [2, 1], 'ID': ['msra - dki', 'thu - pku']}))\n",
      "    assert candidate(pd.DataFrame({'Group': ['M1', 'M1', 'M1', 'M1'], 'Value': [3, 3, 6, 4], 'ID': ['dki', 'two', 'three', 'msra']})).equals(pd.DataFrame({'Group': ['M1', 'M1'], 'Value': [3, 1], 'ID': ['three - two', 'msra - dki']}))\n",
      "    assert candidate(pd.DataFrame({'Group': ['M1', 'M1', 'M1', 'M1'], 'Value': [3, 3, 6, 4], 'ID': ['dki', 'four', 'three', 'msra']})).equals(pd.DataFrame({'Group': ['M1', 'M1'], 'Value': [3, 1], 'ID': ['three - four', 'msra - dki']}))\n",
      "    assert candidate(pd.DataFrame({'Group': ['M1', 'M1', 'M1', 'M1'], 'Value': [3, 3, 6, 4], 'ID': ['dki', 'four', 'five', 'msra']})).equals(pd.DataFrame({'Group': ['M1', 'M1'], 'Value': [3, 1], 'ID': ['five - four', 'msra - dki']}))\n",
      "    assert candidate(pd.DataFrame({'Group': ['M1', 'M1', 'M1', 'M1'], 'Value': [3, 3, 6, 4], 'ID': ['dki', 'four', 'five', 'ucas']})).equals(pd.DataFrame({'Group': ['M1', 'M1'], 'Value': [3, 1], 'ID': ['five - four', 'ucas - dki']}))\n",
      "    assert candidate(pd.DataFrame({'Group': ['M1', 'M1', 'M1', 'M1'], 'Value': [3, 3, 6, 4], 'ID': ['iscas', 'four', 'five', 'ucas']})).equals(pd.DataFrame({'Group': ['M1', 'M1'], 'Value': [3, 1], 'ID': ['five - four', 'ucas - iscas']}))\n",
      "    assert candidate(pd.DataFrame({'Group': ['M1', 'M1', 'M1', 'M1'], 'Value': [3, 3, 6, 5], 'ID': ['iscas', 'four', 'five', 'ucas']})).equals(pd.DataFrame({'Group': ['M1', 'M1'], 'Value': [3, 2], 'ID': ['five - four', 'ucas - iscas']}))\n",
      "    assert candidate(pd.DataFrame({'Group': ['M1', 'M1', 'M1', 'M1'], 'Value': [3, 3, 6, 5], 'ID': ['iscas', 'four', 'five', 'PKU']})).equals(pd.DataFrame({'Group': ['M1', 'M1'], 'Value': [3, 2], 'ID': ['five - four', 'PKU - iscas']}))\n",
      "    assert candidate(pd.DataFrame({'Group': ['M1', 'M1', 'M1', 'M1'], 'Value': [3, 3, 6, 5], 'ID': ['thu', 'four', 'five', 'PKU']})).equals(pd.DataFrame({'Group': ['M1', 'M1'], 'Value': [3, 2], 'ID': ['five - four', 'PKU - thu']}))\n",
      "\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n",
      "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])\n",
      "\n",
      "==================================================\n",
      " PandasEval/27 \n",
      "==================================================\n",
      " import monkey as mk\n",
      "\n",
      "def normalize(kf):\n",
      "    # Normalization using monkey\n",
      "    # We simply subtract the average and divide by standard deviation on kf.iloc[:,0,-1] obj with axis is zero.\n",
      "    # Return the normalized knowledgeframe\n",
      "     \n",
      "==================================================\n",
      " ['kf.iloc[:,0:-1] = kf.iloc[:,0:-1].employ(lambda x: (x-x.average())/ x.standard(), axis=0)\\n    return kf', 'func_ = lambda x: (x-x.average()) / x.standard()\\n    kf.iloc[:,0:-1] = kf.iloc[:,0:-1].employ(func_, axis=0)\\n    return kf'] \n",
      "==================================================\n",
      " \n",
      "\n",
      "METADATA = {\n",
      "    'author': 'msra-v-dazan',\n",
      "    'dataset': 'test',\n",
      "    'type': 'iloc_apply_lambda_mean_std'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('abc')})).equals(pd.DataFrame({'A':[-1.0,0.0,1.0],'B':[-1.0,0.0,1.0],'C':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'M':[1,2,3], 'S':[100,300,500], 'R':list('zan')})).equals(pd.DataFrame({'M':[-1.0,0.0,1.0],'S':[-1.0, 0.0, 1.0],'R':list('zan')}))\n",
      "    assert candidate(pd.DataFrame({'U':[2,4,6], 'C':[100,300,500], 'S':list('yao')})).equals(pd.DataFrame({'U':[-1.0, 0.0, 1.0], 'C':[-1.0, 0.0, 1.0], 'S':list('yao')}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('bbc')})).equals(pd.DataFrame({'A':[-1.0,0.0,1.0],'B':[-1.0,0.0,1.0],'C':list('bbc')}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('bbb')})).equals(pd.DataFrame({'A':[-1.0,0.0,1.0],'B':[-1.0,0.0,1.0],'C':list('bbb')}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'D':list('bbb')})).equals(pd.DataFrame({'A':[-1.0,0.0,1.0],'B':[-1.0,0.0,1.0],'D':list('bbb')}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,200,300], 'D':list('bbb')})).equals(pd.DataFrame({'A':[-1.0,0.0,1.0],'B':[-1.0,0.0,1.0],'D':list('bbb')}))\n",
      "    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,200,300], 'e':list('cdf')})).equals(pd.DataFrame({'A':[-1.0,0.0,1.0],'B':[-1.0,0.0,1.0],'e':list('cdf')}))\n",
      "    assert candidate(pd.DataFrame({'A':[3,4,5], 'B':[300,400,500], 'e':list('cdf')})).equals(pd.DataFrame({'A':[-1.0,0.0,1.0],'B':[-1.0,0.0,1.0],'e':list('cdf')}))\n",
      "    assert candidate(pd.DataFrame({'A':[3,4,5], 'B':[300,400,500], 'R':list('abc')})).equals(pd.DataFrame({'A':[-1.0,0.0,1.0],'B':[-1.0,0.0,1.0],'R':list('abc')}))\n",
      "    assert candidate(pd.DataFrame({'A':[3,4,5], 'B':[300,400,500], 'P':list('abc')})).equals(pd.DataFrame({'A':[-1.0,0.0,1.0],'B':[-1.0,0.0,1.0],'P':list('abc')}))\n",
      "\n",
      " \n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data in stream_jsonl(\"/Users/yuchientsai/Documents/code_gen/PyCodeGPT/apicoder/private-eval/data/real_beatnum_eval_v3.jsonl.gz\"):\n",
    "    print(data.keys())\n",
    "    print(\"\\n\"+\"=\"*50+\"\\n\",data[\"task_id\"],\"\\n\"+\"=\"*50+\"\\n\",data[\"prompt\"],\"\\n\"+\"=\"*50+\"\\n\",data[\"canonical_solution\"],\"\\n\"+\"=\"*50+\"\\n\",data[\"test\"],\"\\n\"+\"=\"*50+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferDisplay():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def show_result_keys(self,result):\n",
    "        print(list(result.keys()))\n",
    "\n",
    "    def show_result(self,result,keys=[]):\n",
    "        if len(keys) > 0:\n",
    "            [print(f'[{key}] :{result[key]}\\n') for key in keys]\n",
    "        else:\n",
    "            [print(f'[{key}] :{result[key]}\\n') for key in result.keys()]\n",
    "        return True\n",
    "\n",
    "    def show_bleu_result(self,result):\n",
    "        print(f'[PROMPT] :{result[\"prompt\"]}\\n')\n",
    "        print(f'[LABEL] :{result[\"response\"]}\\n')\n",
    "        print(f'[OUTPUT]:{result[\"model_inference\"][0]}\\n')\n",
    "        print(f'[BLEU]  :{result[\"bleu_score\"]}\\n')\n",
    "\n",
    "    def show_bleu_code_path(self,result):\n",
    "        print(f'[PATH] :{result[\"source_code_path\"]}\\n')\n",
    "        print(f'[BLEU]  :{result[\"bleu_score\"]}\\n')\n",
    "    \n",
    "    def load_jsonl(self,path):\n",
    "        result = []\n",
    "        with open(path,\"r\") as f:\n",
    "            for line in f:\n",
    "                result.append(json.loads(line))\n",
    "        return result\n",
    "    \n",
    "    def filter_by_key_value(self,data,pick_key_values: dict = None,stop_key_values: dict = None):\n",
    "        result = []\n",
    "        for datum in data:\n",
    "            if stop_key_values:\n",
    "                if any([datum[key] in values for key, values in stop_key_values.items()]):\n",
    "                    continue\n",
    "            if pick_key_values:\n",
    "                if all([datum[key] not in values for key, values in pick_key_values.items()]):\n",
    "                    continue\n",
    "            result.append(datum)\n",
    "        return result\n",
    "    \n",
    "    def filter_node_type(self,data, pick_node_type_list=[], stop_node_type_list=[]):\n",
    "        result = []\n",
    "        for datum in data:\n",
    "            if datum[\"node_type\"] in stop_node_type_list:\n",
    "                continue\n",
    "            if datum[\"node_type\"] not in pick_node_type_list:\n",
    "                continue\n",
    "            result.append(datum)\n",
    "        return result\n",
    "    def average_bleu(self,data):\n",
    "        bleu_list = []\n",
    "        for datum in data:\n",
    "            bleu_list.append(datum[\"bleu_score\"])\n",
    "        if len(bleu_list) == 0:\n",
    "            return 0\n",
    "        return sum(bleu_list) / len(bleu_list)\n",
    "    \n",
    "    def sort_by_blue(self,data,reversed=True):\n",
    "        result = sorted(data,key=lambda x: x[\"bleu_score\"],reverse=reversed)\n",
    "        return result\n",
    "    \n",
    "    def filter_by_bleu_score(self,data,interval=(0,1)):\n",
    "        return [ datum  for datum in data if (datum[\"bleu_score\"] >= interval[0]) and (datum[\"bleu_score\"] < interval[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['task_id', 'completion']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'task_id': 'TorchDataEval/0', 'completion': ' datapipe.repeat(6)'}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display = InferDisplay()\n",
    "data = display.load_jsonl(\"/Users/yuchientsai/Documents/code_gen/PyCodeGPT/apicoder/private-eval/data/TorchData_no.API_number_0.CodeGen.hm_False.machine.t0.1.p0.9.l100.n1.samples.jsonl\")\n",
    "\n",
    "display.show_result_keys(data[0])\n",
    "\n",
    "\n",
    "pick_filter = {\"task_id\":[\"TorchDataEval/0\"]}\n",
    "\n",
    "data = display.filter_by_key_value(data=data,pick_key_values=pick_filter)\n",
    "data\n",
    "#display.show_result(data)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "private-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
